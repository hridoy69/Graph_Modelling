{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "204d7945-78f4-4334-9b97-25d7acb8ea7e",
   "metadata": {},
   "source": [
    "# Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c3a2e2-e3b4-4a67-9ba2-659a39f59d07",
   "metadata": {},
   "source": [
    "- Train/Test Split > Tuning > Cross Verification > Training > Testing > Model Saved\n",
    "- Traing Loss and Training AUC Plot and Test ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625ced2-4e60-4095-906f-d5dbb7aa173f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "[I 2025-04-08 16:28:44,212] A new study created in memory with name: no-name-af1d9809-4c91-41cb-8af0-4cce13b7d267\n",
      "[I 2025-04-08 16:28:45,018] Trial 0 finished with value: 0.6636619718309859 and parameters: {'hidden_channels': 91, 'num_layers': 3, 'dropout': 0.21850049005117797, 'lr': 0.0001133864921556087}. Best is trial 0 with value: 0.6636619718309859.\n",
      "[I 2025-04-08 16:28:46,087] Trial 1 finished with value: 0.6994366197183098 and parameters: {'hidden_channels': 106, 'num_layers': 4, 'dropout': 0.3174493809307106, 'lr': 0.0006392219171452821}. Best is trial 1 with value: 0.6994366197183098.\n",
      "[I 2025-04-08 16:28:46,897] Trial 2 finished with value: 0.7492957746478872 and parameters: {'hidden_channels': 117, 'num_layers': 3, 'dropout': 0.27362930422389686, 'lr': 0.00024066877547981283}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:47,411] Trial 3 finished with value: 0.5707042253521126 and parameters: {'hidden_channels': 81, 'num_layers': 2, 'dropout': 0.3857466905750494, 'lr': 0.00039254795905538636}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:47,964] Trial 4 finished with value: 0.6740845070422536 and parameters: {'hidden_channels': 106, 'num_layers': 2, 'dropout': 0.31707952188063215, 'lr': 0.0006466745270158981}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:48,602] Trial 5 finished with value: 0.5335211267605633 and parameters: {'hidden_channels': 38, 'num_layers': 3, 'dropout': 0.42510135587045284, 'lr': 0.00015708671101537745}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:49,361] Trial 6 finished with value: 0.7433802816901408 and parameters: {'hidden_channels': 40, 'num_layers': 4, 'dropout': 0.32227215522320596, 'lr': 0.0029376166454393605}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:49,943] Trial 7 finished with value: 0.620281690140845 and parameters: {'hidden_channels': 98, 'num_layers': 2, 'dropout': 0.14765206448170481, 'lr': 0.0002051118718568512}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:50,495] Trial 8 finished with value: 0.46478873239436613 and parameters: {'hidden_channels': 95, 'num_layers': 2, 'dropout': 0.2672145878860662, 'lr': 0.0005059128778456145}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:50,983] Trial 9 finished with value: 0.37408450704225354 and parameters: {'hidden_channels': 46, 'num_layers': 2, 'dropout': 0.41624136957383173, 'lr': 0.00010780659264878902}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:51,824] Trial 10 finished with value: 0.7450704225352113 and parameters: {'hidden_channels': 122, 'num_layers': 3, 'dropout': 0.12633681858423135, 'lr': 0.002029022173892534}. Best is trial 2 with value: 0.7492957746478872.\n",
      "[I 2025-04-08 16:28:52,744] Trial 11 finished with value: 0.7535211267605634 and parameters: {'hidden_channels': 126, 'num_layers': 3, 'dropout': 0.12068472221364124, 'lr': 0.00258473889762213}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:53,675] Trial 12 finished with value: 0.7185915492957746 and parameters: {'hidden_channels': 127, 'num_layers': 3, 'dropout': 0.2021430917099723, 'lr': 0.008860146654340508}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:54,545] Trial 13 finished with value: 0.7228169014084508 and parameters: {'hidden_channels': 58, 'num_layers': 4, 'dropout': 0.47246366495456943, 'lr': 0.0018501380384498283}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:55,396] Trial 14 finished with value: 0.7354929577464789 and parameters: {'hidden_channels': 118, 'num_layers': 3, 'dropout': 0.203241473553572, 'lr': 0.0047633176168918835}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:56,086] Trial 15 finished with value: 0.7270422535211267 and parameters: {'hidden_channels': 67, 'num_layers': 3, 'dropout': 0.10209953197779692, 'lr': 0.0011835123027784942}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:56,892] Trial 16 finished with value: 0.7397183098591549 and parameters: {'hidden_channels': 112, 'num_layers': 3, 'dropout': 0.2615034685401636, 'lr': 0.0003080764952560439}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:58,037] Trial 17 finished with value: 0.7154929577464789 and parameters: {'hidden_channels': 126, 'num_layers': 4, 'dropout': 0.15853774847345833, 'lr': 0.001124537598595353}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:58,938] Trial 18 finished with value: 0.744225352112676 and parameters: {'hidden_channels': 79, 'num_layers': 4, 'dropout': 0.24920279198329984, 'lr': 0.003845869432435194}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:28:59,766] Trial 19 finished with value: 0.7515492957746478 and parameters: {'hidden_channels': 114, 'num_layers': 3, 'dropout': 0.17394221997822518, 'lr': 0.009891451580792441}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:00,578] Trial 20 finished with value: 0.6659154929577464 and parameters: {'hidden_channels': 108, 'num_layers': 3, 'dropout': 0.1734185015697914, 'lr': 0.009691622410243923}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:01,423] Trial 21 finished with value: 0.7391549295774648 and parameters: {'hidden_channels': 115, 'num_layers': 3, 'dropout': 0.1072595612333985, 'lr': 0.006103221909359591}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:02,307] Trial 22 finished with value: 0.7242253521126761 and parameters: {'hidden_channels': 127, 'num_layers': 3, 'dropout': 0.18020567689118316, 'lr': 0.0022460250412171165}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:03,112] Trial 23 finished with value: 0.744225352112676 and parameters: {'hidden_channels': 100, 'num_layers': 3, 'dropout': 0.23955549090122696, 'lr': 0.005765828433301821}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:03,838] Trial 24 finished with value: 0.644225352112676 and parameters: {'hidden_channels': 86, 'num_layers': 3, 'dropout': 0.3555942697101534, 'lr': 0.0002461259610537314}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:04,666] Trial 25 finished with value: 0.7225352112676058 and parameters: {'hidden_channels': 118, 'num_layers': 3, 'dropout': 0.14227911244600575, 'lr': 0.0014544992113186437}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:05,749] Trial 26 finished with value: 0.711830985915493 and parameters: {'hidden_channels': 116, 'num_layers': 4, 'dropout': 0.28412282566508557, 'lr': 0.000898325204922218}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:06,300] Trial 27 finished with value: 0.7214084507042253 and parameters: {'hidden_channels': 103, 'num_layers': 2, 'dropout': 0.22821058006758113, 'lr': 0.0030858860390765375}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:06,998] Trial 28 finished with value: 0.7377464788732394 and parameters: {'hidden_channels': 70, 'num_layers': 3, 'dropout': 0.1885431878103749, 'lr': 0.0007522855476349829}. Best is trial 11 with value: 0.7535211267605634.\n",
      "[I 2025-04-08 16:29:07,814] Trial 29 finished with value: 0.7076056338028169 and parameters: {'hidden_channels': 87, 'num_layers': 3, 'dropout': 0.13137576642124743, 'lr': 0.006369122356758965}. Best is trial 11 with value: 0.7535211267605634.\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 10-Fold Cross-Validation Mean Metrics:\n",
      "AUC: 0.6874\n",
      "Accuracy: 0.6690\n",
      "MCC: 0.2340\n",
      "Precision: 0.6742\n",
      "F1: 0.7701\n",
      "Kappa: 0.1980\n",
      "Brier: 0.2104\n",
      "[Final Train] Epoch 1 | Loss: 0.7137 | AUC: 0.6120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Final Train] Epoch 2 | Loss: 0.6718 | AUC: 0.6177\n",
      "[Final Train] Epoch 3 | Loss: 0.6615 | AUC: 0.6307\n",
      "[Final Train] Epoch 4 | Loss: 0.6935 | AUC: 0.6241\n",
      "[Final Train] Epoch 5 | Loss: 0.6623 | AUC: 0.6267\n",
      "[Final Train] Epoch 6 | Loss: 0.6581 | AUC: 0.6387\n",
      "[Final Train] Epoch 7 | Loss: 0.6494 | AUC: 0.6419\n",
      "[Final Train] Epoch 8 | Loss: 0.6402 | AUC: 0.6465\n",
      "[Final Train] Epoch 9 | Loss: 0.6646 | AUC: 0.6394\n",
      "[Final Train] Epoch 10 | Loss: 0.6405 | AUC: 0.6571\n",
      "[Final Train] Epoch 11 | Loss: 0.6377 | AUC: 0.6641\n",
      "[Final Train] Epoch 12 | Loss: 0.6459 | AUC: 0.6533\n",
      "[Final Train] Epoch 13 | Loss: 0.6304 | AUC: 0.6661\n",
      "[Final Train] Epoch 14 | Loss: 0.6285 | AUC: 0.6742\n",
      "[Final Train] Epoch 15 | Loss: 0.6228 | AUC: 0.6807\n",
      "[Final Train] Epoch 16 | Loss: 0.6187 | AUC: 0.6769\n",
      "[Final Train] Epoch 17 | Loss: 0.6263 | AUC: 0.6848\n",
      "[Final Train] Epoch 18 | Loss: 0.6171 | AUC: 0.6954\n",
      "[Final Train] Epoch 19 | Loss: 0.6362 | AUC: 0.6978\n",
      "[Final Train] Epoch 20 | Loss: 0.6156 | AUC: 0.7002\n",
      "[Final Train] Epoch 21 | Loss: 0.6087 | AUC: 0.6863\n",
      "[Final Train] Epoch 22 | Loss: 0.6307 | AUC: 0.7035\n",
      "[Final Train] Epoch 23 | Loss: 0.6099 | AUC: 0.7086\n",
      "[Final Train] Epoch 24 | Loss: 0.6079 | AUC: 0.7111\n",
      "[Final Train] Epoch 25 | Loss: 0.6053 | AUC: 0.7064\n",
      "[Final Train] Epoch 26 | Loss: 0.5993 | AUC: 0.7169\n",
      "[Final Train] Epoch 27 | Loss: 0.5963 | AUC: 0.7172\n",
      "[Final Train] Epoch 28 | Loss: 0.5980 | AUC: 0.7277\n",
      "[Final Train] Epoch 29 | Loss: 0.5929 | AUC: 0.7272\n",
      "[Final Train] Epoch 30 | Loss: 0.5911 | AUC: 0.7270\n",
      "[Final Train] Epoch 31 | Loss: 0.5896 | AUC: 0.7320\n",
      "[Final Train] Epoch 32 | Loss: 0.5858 | AUC: 0.7368\n",
      "[Final Train] Epoch 33 | Loss: 0.5901 | AUC: 0.7408\n",
      "[Final Train] Epoch 34 | Loss: 0.5879 | AUC: 0.7395\n",
      "[Final Train] Epoch 35 | Loss: 0.5930 | AUC: 0.7493\n",
      "[Final Train] Epoch 36 | Loss: 0.6108 | AUC: 0.7104\n",
      "[Final Train] Epoch 37 | Loss: 0.5930 | AUC: 0.7421\n",
      "[Final Train] Epoch 38 | Loss: 0.5775 | AUC: 0.7392\n",
      "[Final Train] Epoch 39 | Loss: 0.5926 | AUC: 0.7511\n",
      "[Final Train] Epoch 40 | Loss: 0.5982 | AUC: 0.7436\n",
      "[Final Train] Epoch 41 | Loss: 0.5782 | AUC: 0.7483\n",
      "[Final Train] Epoch 42 | Loss: 0.5861 | AUC: 0.7520\n",
      "[Final Train] Epoch 43 | Loss: 0.5810 | AUC: 0.7555\n",
      "[Final Train] Epoch 44 | Loss: 0.5779 | AUC: 0.7539\n",
      "[Final Train] Epoch 45 | Loss: 0.5716 | AUC: 0.7620\n",
      "[Final Train] Epoch 46 | Loss: 0.5639 | AUC: 0.7625\n",
      "[Final Train] Epoch 47 | Loss: 0.5640 | AUC: 0.7599\n",
      "[Final Train] Epoch 48 | Loss: 0.5813 | AUC: 0.7752\n",
      "[Final Train] Epoch 49 | Loss: 0.5743 | AUC: 0.7699\n",
      "[Final Train] Epoch 50 | Loss: 0.5602 | AUC: 0.7563\n",
      "[Final Train] Epoch 51 | Loss: 0.5546 | AUC: 0.7733\n",
      "[Final Train] Epoch 52 | Loss: 0.5681 | AUC: 0.7750\n",
      "[Final Train] Epoch 53 | Loss: 0.5573 | AUC: 0.7773\n",
      "[Final Train] Epoch 54 | Loss: 0.5491 | AUC: 0.7828\n",
      "[Final Train] Epoch 55 | Loss: 0.5615 | AUC: 0.7756\n",
      "[Final Train] Epoch 56 | Loss: 0.5593 | AUC: 0.7823\n",
      "[Final Train] Epoch 57 | Loss: 0.5725 | AUC: 0.7897\n",
      "[Final Train] Epoch 58 | Loss: 0.5592 | AUC: 0.7866\n",
      "[Final Train] Epoch 59 | Loss: 0.5491 | AUC: 0.7958\n",
      "[Final Train] Epoch 60 | Loss: 0.5391 | AUC: 0.7820\n",
      "[Final Train] Epoch 61 | Loss: 0.5515 | AUC: 0.7908\n",
      "[Final Train] Epoch 62 | Loss: 0.5472 | AUC: 0.7951\n",
      "[Final Train] Epoch 63 | Loss: 0.5554 | AUC: 0.7695\n",
      "[Final Train] Epoch 64 | Loss: 0.5484 | AUC: 0.7932\n",
      "[Final Train] Epoch 65 | Loss: 0.5314 | AUC: 0.8005\n",
      "[Final Train] Epoch 66 | Loss: 0.5483 | AUC: 0.8023\n",
      "[Final Train] Epoch 67 | Loss: 0.5437 | AUC: 0.8003\n",
      "[Final Train] Epoch 68 | Loss: 0.5559 | AUC: 0.7907\n",
      "[Final Train] Epoch 69 | Loss: 0.5535 | AUC: 0.7899\n",
      "[Final Train] Epoch 70 | Loss: 0.5372 | AUC: 0.7967\n",
      "[Final Train] Epoch 71 | Loss: 0.5322 | AUC: 0.7995\n",
      "[Final Train] Epoch 72 | Loss: 0.5278 | AUC: 0.8109\n",
      "[Final Train] Epoch 73 | Loss: 0.5231 | AUC: 0.8063\n",
      "[Final Train] Epoch 74 | Loss: 0.5207 | AUC: 0.8149\n",
      "[Final Train] Epoch 75 | Loss: 0.5182 | AUC: 0.8109\n",
      "[Final Train] Epoch 76 | Loss: 0.5159 | AUC: 0.8158\n",
      "[Final Train] Epoch 77 | Loss: 0.5174 | AUC: 0.8140\n",
      "[Final Train] Epoch 78 | Loss: 0.5309 | AUC: 0.8036\n",
      "[Final Train] Epoch 79 | Loss: 0.5182 | AUC: 0.8157\n",
      "[Final Train] Epoch 80 | Loss: 0.5174 | AUC: 0.8154\n",
      "[Final Train] Epoch 81 | Loss: 0.5207 | AUC: 0.8081\n",
      "[Final Train] Epoch 82 | Loss: 0.5128 | AUC: 0.8205\n",
      "[Final Train] Epoch 83 | Loss: 0.5142 | AUC: 0.8237\n",
      "[Final Train] Epoch 84 | Loss: 0.5320 | AUC: 0.8187\n",
      "[Final Train] Epoch 85 | Loss: 0.5171 | AUC: 0.8267\n",
      "[Final Train] Epoch 86 | Loss: 0.5136 | AUC: 0.8038\n",
      "[Final Train] Epoch 87 | Loss: 0.5239 | AUC: 0.8101\n",
      "[Final Train] Epoch 88 | Loss: 0.5190 | AUC: 0.8234\n",
      "[Final Train] Epoch 89 | Loss: 0.5155 | AUC: 0.8094\n",
      "[Final Train] Epoch 90 | Loss: 0.5528 | AUC: 0.8194\n",
      "[Final Train] Epoch 91 | Loss: 0.5389 | AUC: 0.7824\n",
      "[Final Train] Epoch 92 | Loss: 0.5306 | AUC: 0.8162\n",
      "[Final Train] Epoch 93 | Loss: 0.5101 | AUC: 0.8218\n",
      "[Final Train] Epoch 94 | Loss: 0.5106 | AUC: 0.8114\n",
      "[Final Train] Epoch 95 | Loss: 0.5066 | AUC: 0.8271\n",
      "[Final Train] Epoch 96 | Loss: 0.5060 | AUC: 0.8335\n",
      "[Final Train] Epoch 97 | Loss: 0.5024 | AUC: 0.8270\n",
      "[Final Train] Epoch 98 | Loss: 0.5183 | AUC: 0.8306\n",
      "[Final Train] Epoch 99 | Loss: 0.5208 | AUC: 0.8024\n",
      "[Final Train] Epoch 100 | Loss: 0.5181 | AUC: 0.8302\n",
      "\n",
      "🧪 Final Test Set Metrics:\n",
      "AUC: 0.7474\n",
      "Accuracy: 0.7368\n",
      "MCC: 0.3993\n",
      "Precision: 0.7589\n",
      "F1: 0.8095\n",
      "Kappa: 0.3900\n",
      "Brier: 0.1868\n"
     ]
    }
   ],
   "source": [
    "# combined_gcn_pipeline_optuna_cv.py\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, matthews_corrcoef,\n",
    "    cohen_kappa_score, brier_score_loss, confusion_matrix,\n",
    "    precision_score, f1_score, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "# Ensure output directory\n",
    "output_dir = 'GCN_results' # apr_4\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Expanded atom features\n",
    "def atom_features(atom):\n",
    "    return torch.tensor([\n",
    "        # Basic properties\n",
    "        atom.GetAtomicNum(),                     # Atomic number\n",
    "        atom.GetDegree(),                        # Number of bonded neighbors\n",
    "        atom.GetFormalCharge(),                  # Formal charge\n",
    "        atom.GetNumRadicalElectrons(),           # Number of radical electrons\n",
    "        int(atom.GetIsAromatic()),               # Aromaticity flag\n",
    "        \n",
    "        # Extended properties\n",
    "        atom.GetExplicitValence(),               # Explicit valence\n",
    "        atom.GetImplicitValence(),               # Implicit valence\n",
    "        atom.GetTotalValence(),                  # Total valence\n",
    "        atom.GetNumImplicitHs(),                 # Number of implicit hydrogens\n",
    "        atom.GetHybridization(),                 # Hybridization state\n",
    "        atom.GetTotalNumHs(),                    # Total number of hydrogens\n",
    "        \n",
    "        # Topological properties\n",
    "        int(atom.IsInRing()),                    # Whether the atom is in a ring\n",
    "        int(atom.IsInRingSize(3)),               # Whether in 3-membered ring\n",
    "        int(atom.IsInRingSize(4)),               # Whether in 4-membered ring\n",
    "        int(atom.IsInRingSize(5)),               # Whether in 5-membered ring\n",
    "        int(atom.IsInRingSize(6)),               # Whether in 6-membered ring\n",
    "        int(atom.IsInRingSize(7)),               # Whether in 7-membered ring\n",
    "        \n",
    "        # Electronic properties\n",
    "        atom.GetChiralTag(),                     # Chirality\n",
    "        atom.GetMass(),                          # Atomic mass\n",
    "        Chem.rdMolDescriptors.CalcCrippenDescriptors(\n",
    "            Chem.MolFromSmiles(f\"[{atom.GetSymbol()}]\"))[0]  # LogP contribution\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "# Molecule to PyTorch Geometric graph\n",
    "def mol_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    atoms = [atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    if not atoms: return None\n",
    "    x = torch.stack(atoms, dim=0)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "    edge_attr = [[bond.GetBondTypeAsDouble(), bond.GetIsConjugated(), bond.IsInRing()] * 2 for bond in mol.GetBonds()]\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).reshape(-1, 3)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]) or pd.isna(row[target_col]):\n",
    "            continue\n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "# GCN model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "# Training and AUC\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "        loss = criterion(torch.sigmoid(out), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def compute_auc(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_probs = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            y_probs.extend(torch.sigmoid(out).cpu().numpy())\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "    return roc_auc_score(y_true, y_probs)\n",
    "\n",
    "# Model evaluation\n",
    "def get_metrics(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_probs = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            y_probs.extend(torch.sigmoid(out).cpu().numpy())\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "    y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "    return {\n",
    "        'AUC': roc_auc_score(y_true, y_probs),\n",
    "        'Accuracy': accuracy_score(y_true, y_preds),\n",
    "        'MCC': matthews_corrcoef(y_true, y_preds),\n",
    "        'Precision': precision_score(y_true, y_preds),\n",
    "        'F1': f1_score(y_true, y_preds),\n",
    "        'Kappa': cohen_kappa_score(y_true, y_preds),\n",
    "        'Brier': brier_score_loss(y_true, y_probs),\n",
    "    }\n",
    "\n",
    "# Globals for Optuna\n",
    "trial_train_loader = None\n",
    "trial_val_loader = None\n",
    "\n",
    "# Optuna objective\n",
    "def objective(trial):\n",
    "    hidden_channels = trial.suggest_int(\"hidden_channels\", 32, 128)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = GCN(20, hidden_channels, 1, num_layers, dropout)  # Updated input dimension\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        train(model, trial_train_loader, optimizer, criterion)\n",
    "\n",
    "    return compute_auc(model, trial_val_loader)\n",
    "\n",
    "def main():\n",
    "    global trial_train_loader, trial_val_loader\n",
    "\n",
    "    graphs = load_dataset(\"dataset_main.xlsx\")\n",
    "    train_data, test_data = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "    trial_train, trial_val = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "    trial_train_loader = DataLoader(trial_train, batch_size=32, shuffle=True)\n",
    "    trial_val_loader = DataLoader(trial_val, batch_size=32)\n",
    "\n",
    "    # Optuna tuning\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=30)\n",
    "    best_params = study.best_trial.params\n",
    "    json.dump(best_params, open(os.path.join(output_dir, \"study_best_params.json\"), \"w\"), indent=4)\n",
    "\n",
    "    # 10-fold cross-validation (mean metrics only)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    metrics_list = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_data), start=1):\n",
    "        model = GCN(20, best_params[\"hidden_channels\"], 1, best_params[\"num_layers\"], best_params[\"dropout\"])  # Updated input dimension\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "        criterion = torch.nn.BCELoss()\n",
    "\n",
    "        train_fold = [train_data[i] for i in train_idx]\n",
    "        val_fold = [train_data[i] for i in val_idx]\n",
    "        loader_train = DataLoader(train_fold, batch_size=32, shuffle=True)\n",
    "        loader_val = DataLoader(val_fold, batch_size=32)\n",
    "\n",
    "        for epoch in range(30):\n",
    "            train(model, loader_train, optimizer, criterion)\n",
    "\n",
    "        metrics = get_metrics(model, loader_val)\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "    # Save and print mean of cross-validation metrics\n",
    "    df_cv = pd.DataFrame(metrics_list)\n",
    "    mean_metrics = df_cv.mean()\n",
    "    df_cv.loc['mean'] = mean_metrics\n",
    "    df_cv.tail(1).to_excel(os.path.join(output_dir, \"cv_metrics_mean.xlsx\"), index=False)\n",
    "\n",
    "    print(\"\\n📊 10-Fold Cross-Validation Mean Metrics:\")\n",
    "    for key, value in mean_metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "    # Final training on full training set\n",
    "    full_train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "    final_model = GCN(20, best_params[\"hidden_channels\"], 1, best_params[\"num_layers\"], best_params[\"dropout\"])  # Updated input dimension\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params[\"lr\"])\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    losses, aucs = [], []\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(final_model, full_train_loader, optimizer, criterion)\n",
    "        auc = compute_auc(final_model, full_train_loader)\n",
    "        losses.append(loss)\n",
    "        aucs.append(auc)\n",
    "        print(f\"[Final Train] Epoch {epoch} | Loss: {loss:.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "    torch.save(final_model.state_dict(), os.path.join(output_dir, \"gcn_best_model.pth\"))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(losses, label=\"Loss\")\n",
    "    plt.title(\"Final Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(os.path.join(output_dir, \"final_training_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(aucs, label=\"AUC\", color='red')\n",
    "    plt.title(\"Final Training AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.savefig(os.path.join(output_dir, \"final_training_auc.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Final test set evaluation\n",
    "    test_metrics = get_metrics(final_model, test_loader)\n",
    "    pd.DataFrame([test_metrics]).to_excel(os.path.join(output_dir, \"test_metrics.xlsx\"), index=False)\n",
    "\n",
    "    print(\"\\n🧪 Final Test Set Metrics:\")\n",
    "    for key, value in test_metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "    # ROC Curve\n",
    "    model = final_model\n",
    "    model.eval()\n",
    "    y_true, y_probs = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            y_probs.extend(torch.sigmoid(out).cpu().numpy())\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {test_metrics['AUC']:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Test ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, \"test_roc.png\"))\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5470b29-4d31-4951-9ca6-9e08cfcc2544",
   "metadata": {},
   "source": [
    "## Confusion matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a98784-22c7-4182-ad81-973378789d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd15/Desktop/Amarjit/myvenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "===== Confusion Matrix =====\n",
      "True Negative (TN): 27\n",
      "False Positive (FP): 27\n",
      "False Negative (FN): 13\n",
      "True Positive (TP): 85\n",
      "\n",
      "===== Detailed Metrics =====\n",
      "True Positive Rate (Sensitivity/Recall): 0.8673\n",
      "True Negative Rate (Specificity): 0.5000\n",
      "False Positive Rate: 0.5000\n",
      "False Negative Rate: 0.1327\n",
      "Precision: 0.7589\n",
      "F1 Score: 0.8095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "# Reuse the necessary functions from cell1\n",
    "def atom_features(atom):\n",
    "    return torch.tensor([\n",
    "        # Basic properties\n",
    "        atom.GetAtomicNum(),\n",
    "        atom.GetDegree(),\n",
    "        atom.GetFormalCharge(),\n",
    "        atom.GetNumRadicalElectrons(),\n",
    "        int(atom.GetIsAromatic()),\n",
    "        \n",
    "        # Extended properties\n",
    "        atom.GetExplicitValence(),\n",
    "        atom.GetImplicitValence(),\n",
    "        atom.GetTotalValence(),\n",
    "        atom.GetNumImplicitHs(),\n",
    "        atom.GetHybridization(),\n",
    "        atom.GetTotalNumHs(),\n",
    "        \n",
    "        # Topological properties\n",
    "        int(atom.IsInRing()),\n",
    "        int(atom.IsInRingSize(3)),\n",
    "        int(atom.IsInRingSize(4)),\n",
    "        int(atom.IsInRingSize(5)),\n",
    "        int(atom.IsInRingSize(6)),\n",
    "        int(atom.IsInRingSize(7)),\n",
    "        \n",
    "        # Electronic properties\n",
    "        atom.GetChiralTag(),\n",
    "        atom.GetMass(),\n",
    "        Chem.rdMolDescriptors.CalcCrippenDescriptors(\n",
    "            Chem.MolFromSmiles(f\"[{atom.GetSymbol()}]\"))[0]\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "def mol_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    atoms = [atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    if not atoms: return None\n",
    "    x = torch.stack(atoms, dim=0)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "    edge_attr = [[bond.GetBondTypeAsDouble(), bond.GetIsConjugated(), bond.IsInRing()] * 2 for bond in mol.GetBonds()]\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).reshape(-1, 3)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "def load_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]) or pd.isna(row[target_col]):\n",
    "            continue\n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "# Use GCN class from cell1 instead of MPNN\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "# Main execution for generating confusion matrix\n",
    "def generate_confusion_matrix():\n",
    "    output_dir = 'GCN_results'  # Match the original GCN directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the best parameters\n",
    "    try:\n",
    "        with open(os.path.join(output_dir, \"study_best_params.json\"), \"r\") as f:\n",
    "            best_params = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Best parameters file not found. Using default parameters.\")\n",
    "        best_params = {\n",
    "            \"hidden_channels\": 64,\n",
    "            \"num_layers\": 3, \n",
    "            \"dropout\": 0.3,\n",
    "            \"lr\": 0.001\n",
    "        }\n",
    "    \n",
    "    # Load dataset and create test loader\n",
    "    graphs = load_dataset(\"dataset_main.xlsx\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    _, test_data = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "    \n",
    "    # Initialize GCN model with best parameters\n",
    "    model = GCN(20, best_params[\"hidden_channels\"], 1, \n",
    "                best_params[\"num_layers\"], best_params[\"dropout\"])\n",
    "    \n",
    "    # Load trained model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(os.path.join(output_dir, \"gcn_best_model.pth\")))\n",
    "        print(\"Model loaded successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model file not found. Cannot generate confusion matrix without trained model.\")\n",
    "        return\n",
    "    \n",
    "    # Generate predictions\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "    molecule_smiles = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            probs = torch.sigmoid(out).cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            \n",
    "            y_probs.extend(probs)\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "            molecule_smiles.extend([g.smiles for g in data.to_data_list()])\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_names = ['Negative', 'Positive']\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "    plt.title('Confusion Matrix for GCN Model')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"confusion_matrix.png\"))\n",
    "    \n",
    "    # Create a prettier confusion matrix with seaborn\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix for GCN Model')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"confusion_matrix_seaborn.png\"))\n",
    "    \n",
    "    # Create a dataframe with predictions for analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'SMILES': molecule_smiles,\n",
    "        'True_Label': y_true,\n",
    "        'Predicted_Label': y_pred,\n",
    "        'Prediction_Probability': y_probs\n",
    "    })\n",
    "    \n",
    "    # Save predictions to Excel\n",
    "    results_df.to_excel(os.path.join(output_dir, \"prediction_results.xlsx\"), index=False)\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    \n",
    "    # True Positive Rate (Sensitivity or Recall)\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # True Negative Rate (Specificity)\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    # False Positive Rate\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    \n",
    "    # False Negative Rate\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # Precision\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    \n",
    "    # F1 Score\n",
    "    f1 = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(\"\\n===== Confusion Matrix =====\")\n",
    "    print(f\"True Negative (TN): {TN}\")\n",
    "    print(f\"False Positive (FP): {FP}\")\n",
    "    print(f\"False Negative (FN): {FN}\")\n",
    "    print(f\"True Positive (TP): {TP}\")\n",
    "    print(\"\\n===== Detailed Metrics =====\")\n",
    "    print(f\"True Positive Rate (Sensitivity/Recall): {TPR:.4f}\")\n",
    "    print(f\"True Negative Rate (Specificity): {TNR:.4f}\")\n",
    "    print(f\"False Positive Rate: {FPR:.4f}\")\n",
    "    print(f\"False Negative Rate: {FNR:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save metrics to file\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['TN', 'FP', 'FN', 'TP', 'Sensitivity/Recall', 'Specificity', \n",
    "                  'False Positive Rate', 'False Negative Rate', 'Precision', 'F1 Score'],\n",
    "        'Value': [TN, FP, FN, TP, TPR, TNR, FPR, FNR, precision, f1]\n",
    "    })\n",
    "    metrics_df.to_excel(os.path.join(output_dir, \"detailed_metrics.xlsx\"), index=False)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    generate_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea3ace5-5a09-4b1f-8886-1bf50963b066",
   "metadata": {},
   "source": [
    "# External Dataset Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78424e9f-c993-485f-a702-ea87c2f9df6f",
   "metadata": {},
   "source": [
    "## Phytos_Results.xlsx\n",
    "- Predicted Results saved to excel\n",
    "- ROC plot and Confusion Matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e12f3-629b-4556-81f3-781dfa5ca8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model layers:\n",
      "convs.0.lin.weight: torch.Size([126, 20])\n",
      "convs.1.lin.weight: torch.Size([126, 126])\n",
      "convs.2.lin.weight: torch.Size([1, 126])\n",
      "Detected hidden size: 126\n",
      "Error loading model weights: Error(s) in loading state_dict for GCNForLoading:\n",
      "\tMissing key(s) in state_dict: \"convs.3.bias\", \"convs.3.lin.weight\". \n",
      "\tsize mismatch for convs.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([126]).\n",
      "\tsize mismatch for convs.2.lin.weight: copying a param with shape torch.Size([1, 126]) from checkpoint, the shape in current model is torch.Size([126, 126]).\n",
      "This may happen if the model architecture doesn't match the saved weights.\n",
      "Make sure you've trained the model with the updated atom features first.\n",
      "Continuing with uninitialized model for demonstration...\n",
      "\n",
      "⚠️ Warning: Only one class is present in the dataset.\n",
      "AUC and MCC are not defined in this case and will be reported as N/A.\n",
      "\n",
      "🧪 External Dataset Metrics:\n",
      "Accuracy: 0.9779\n",
      "Precision: 1.0000\n",
      "F1: 0.9888\n",
      "Kappa: 0.0000\n",
      "Brier: 0.1076\n",
      "AUC: N/A\n",
      "MCC: N/A\n",
      "\n",
      "📊 Class Distribution in External Dataset:\n",
      "Class 0: 0 samples (0.0%)\n",
      "Class 1: 1313 samples (100.0%)\n",
      "\n",
      "💾 Predictions for 1313 molecules saved to apr_4/external_predictions.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: External Dataset Evaluation with Fixed Model Loading\n",
    "\n",
    "# Import additional required libraries\n",
    "import seaborn as sns\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = 'GCN_results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# First, examine the saved model to understand its architecture\n",
    "saved_state_dict = torch.load(os.path.join(output_dir, \"gcn_best_model.pth\"))\n",
    "\n",
    "# Print the keys to see the model structure\n",
    "print(\"Saved model layers:\")\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'weight' in key:\n",
    "        print(f\"{key}: {saved_state_dict[key].shape}\")\n",
    "\n",
    "# Function to load external dataset\n",
    "def load_external_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    molecules = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]):\n",
    "            continue\n",
    "            \n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            # If target is available, use it, otherwise set to None\n",
    "            if target_col in df.columns and not pd.isna(row[target_col]):\n",
    "                g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            else:\n",
    "                g.y = None\n",
    "                \n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "            molecules.append(row.to_dict())\n",
    "    \n",
    "    return graphs, pd.DataFrame(molecules)\n",
    "\n",
    "# Custom model class that matches the saved architecture\n",
    "class GCNForLoading(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_size):\n",
    "        super().__init__()\n",
    "        # Initialize with the architecture from the saved model\n",
    "        # Using parameters based on the saved state shapes\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_features, hidden_size))  # Input features to hidden\n",
    "        self.convs.append(GCNConv(hidden_size, hidden_size))  # Hidden to hidden\n",
    "        self.convs.append(GCNConv(hidden_size, hidden_size))  # Hidden to hidden  \n",
    "        self.convs.append(GCNConv(hidden_size, 1))           # Hidden to output\n",
    "        self.dropout = 0.3  # Default value, will be overridden by loaded state\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "# Get hidden size from saved model\n",
    "# First convolutional layer weight shape is [hidden_size, in_features]\n",
    "# Find the first weight key and get its shape\n",
    "hidden_size = None\n",
    "in_features = 20  # Our updated model has 20 input features\n",
    "\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'weight' in key and 'convs.0' in key:\n",
    "        hidden_size = saved_state_dict[key].shape[0]\n",
    "        break\n",
    "\n",
    "if hidden_size is None:\n",
    "    # Default if we couldn't determine from saved state\n",
    "    hidden_size = 64\n",
    "    print(f\"Warning: Could not determine hidden size from saved model. Using default: {hidden_size}\")\n",
    "else:\n",
    "    print(f\"Detected hidden size: {hidden_size}\")\n",
    "\n",
    "# Create the model with the correct architecture\n",
    "model = GCNForLoading(in_features=in_features, hidden_size=hidden_size)\n",
    "\n",
    "# Try to load the saved state\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(output_dir, \"gcn_best_model.pth\")))\n",
    "    print(\"Successfully loaded model weights\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model weights: {str(e)}\")\n",
    "    print(\"This may happen if the model architecture doesn't match the saved weights.\")\n",
    "    print(\"Make sure you've trained the model with the updated atom features first.\")\n",
    "    # Continue anyway for demonstration purposes\n",
    "    print(\"Continuing with uninitialized model for demonstration...\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load external dataset\n",
    "external_data, external_df = load_external_dataset(\"Phytos_results.xlsx\")\n",
    "# Suppress deprecation warning for DataLoader\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    external_loader = DataLoader(external_data, batch_size=32)\n",
    "\n",
    "# Get predictions\n",
    "y_true = []\n",
    "y_probs = []\n",
    "smiles_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in external_loader:\n",
    "        try:\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            # Don't squeeze - handle the dimensionality properly\n",
    "            probs = torch.sigmoid(out).cpu().numpy()\n",
    "            \n",
    "            # Handle both single-item and multi-item batches\n",
    "            if len(probs.shape) == 0:  # Single item case (0-d array)\n",
    "                probs = np.array([probs.item()])\n",
    "            \n",
    "            for i in range(len(probs)):\n",
    "                y_probs.append(probs[i])\n",
    "                \n",
    "                # Get the SMILES safely\n",
    "                if hasattr(batch, 'smiles'):\n",
    "                    if isinstance(batch.smiles, list):\n",
    "                        smiles_list.append(batch.smiles[i])\n",
    "                    else:\n",
    "                        # Handle the case where smiles might be a single string\n",
    "                        smiles_list.append(batch.smiles)\n",
    "                \n",
    "                # Get the true value if it exists\n",
    "                if hasattr(batch, 'y') and batch.y is not None:\n",
    "                    if batch.y.dim() > 0 and i < batch.y.size(0):\n",
    "                        y_true.append(batch.y[i].item())\n",
    "                    elif batch.y.dim() == 0:  # Single item\n",
    "                        y_true.append(batch.y.item())\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Save predictions to Excel\n",
    "results_df = pd.DataFrame({\n",
    "    'Smiles': smiles_list,\n",
    "    'Predicted_Probability': y_probs,\n",
    "    'Predicted_Class': [1 if p > 0.5 else 0 for p in y_probs]\n",
    "})\n",
    "\n",
    "# If we have true values, add them and calculate metrics\n",
    "if len(y_true) > 0 and len(y_true) == len(y_probs):\n",
    "    results_df['Actual'] = y_true\n",
    "    \n",
    "    # Calculate metrics\n",
    "    y_true_np = np.array(y_true)  # Convert list to numpy array\n",
    "    y_probs_np = np.array(y_probs)\n",
    "    y_preds = (y_probs_np > 0.5).astype(int)\n",
    "    \n",
    "    # Check if we have multiple classes for metrics that require it\n",
    "    unique_classes = np.unique(y_true_np)\n",
    "    has_multiple_classes = len(unique_classes) > 1\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true_np, y_preds),\n",
    "        'Precision': precision_score(y_true_np, y_preds, zero_division=0),\n",
    "        'F1': f1_score(y_true_np, y_preds, zero_division=0),\n",
    "        'Kappa': cohen_kappa_score(y_true_np, y_preds),\n",
    "        'Brier': brier_score_loss(y_true_np, y_probs_np),\n",
    "    }\n",
    "    \n",
    "    # Only calculate AUC and MCC if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        # Suppress the UndefinedMetricWarning\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            metrics['AUC'] = roc_auc_score(y_true_np, y_probs_np)\n",
    "            metrics['MCC'] = matthews_corrcoef(y_true_np, y_preds)\n",
    "    else:\n",
    "        print(\"\\n⚠️ Warning: Only one class is present in the dataset.\")\n",
    "        print(\"AUC and MCC are not defined in this case and will be reported as N/A.\")\n",
    "        metrics['AUC'] = \"N/A\"\n",
    "        metrics['MCC'] = \"N/A\"\n",
    "    \n",
    "    # Convert N/A values to NaN for Excel export\n",
    "    metrics_for_excel = {k: np.nan if v == \"N/A\" else v for k, v in metrics.items()}\n",
    "    \n",
    "    # Save metrics\n",
    "    pd.DataFrame([metrics_for_excel]).to_excel(os.path.join(output_dir, \"external_metrics.xlsx\"), index=False)\n",
    "    \n",
    "    print(\"\\n🧪 External Dataset Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, str):\n",
    "            print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    # Only generate ROC curve if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            fpr, tpr, _ = roc_curve(y_true_np, y_probs_np)\n",
    "            \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {metrics['AUC']:.2f}\" if isinstance(metrics['AUC'], float) else \"AUC = N/A\")\n",
    "        plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"External Dataset ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_dir, \"external_roc.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true_np, y_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix - External Dataset')\n",
    "    plt.savefig(os.path.join(output_dir, \"external_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Class distribution information\n",
    "    class_counts = np.bincount(y_true_np.astype(int))\n",
    "    print(\"\\n📊 Class Distribution in External Dataset:\")\n",
    "    for i, count in enumerate(class_counts):\n",
    "        print(f\"Class {i}: {count} samples ({count/len(y_true_np)*100:.1f}%)\")\n",
    "\n",
    "# Save all predictions\n",
    "results_df.to_excel(os.path.join(output_dir, \"external_predictions.xlsx\"), index=False)\n",
    "print(f\"\\n💾 Predictions for {len(results_df)} molecules saved to {os.path.join(output_dir, 'external_predictions.xlsx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92544285-ec36-4b39-91b6-832c0ed420c3",
   "metadata": {},
   "source": [
    "## cancer_set.xlsx\n",
    "- Predicted Results saved to excel\n",
    "- ROC plot and Confusion Matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9376c6-f721-457c-9e66-ee18257ece69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model layers:\n",
      "convs.0.lin.weight: torch.Size([126, 20])\n",
      "convs.1.lin.weight: torch.Size([126, 126])\n",
      "convs.2.lin.weight: torch.Size([1, 126])\n",
      "Detected hidden size: 126\n",
      "Error loading model weights: Error(s) in loading state_dict for GCNForLoading:\n",
      "\tMissing key(s) in state_dict: \"convs.3.bias\", \"convs.3.lin.weight\". \n",
      "\tsize mismatch for convs.2.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([126]).\n",
      "\tsize mismatch for convs.2.lin.weight: copying a param with shape torch.Size([1, 126]) from checkpoint, the shape in current model is torch.Size([126, 126]).\n",
      "This may happen if the model architecture doesn't match the saved weights.\n",
      "Make sure you've trained the model with the updated atom features first.\n",
      "Continuing with uninitialized model for demonstration...\n",
      "\n",
      "⚠️ Warning: Only one class is present in the dataset.\n",
      "AUC and MCC are not defined in this case and will be reported as N/A.\n",
      "\n",
      "🧪 External Dataset Metrics:\n",
      "Accuracy: 0.6976\n",
      "Precision: 1.0000\n",
      "F1: 0.8219\n",
      "Kappa: 0.0000\n",
      "Brier: 0.2401\n",
      "AUC: N/A\n",
      "MCC: N/A\n",
      "\n",
      "📊 Class Distribution in External Dataset:\n",
      "Class 0: 0 samples (0.0%)\n",
      "Class 1: 248 samples (100.0%)\n",
      "\n",
      "💾 Predictions for 248 molecules saved to apr_4/external_predictions_cancer.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: External Dataset Evaluation with Fixed Model Loading\n",
    "\n",
    "# Import additional required libraries\n",
    "import seaborn as sns\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = 'GCN_results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# First, examine the saved model to understand its architecture\n",
    "saved_state_dict = torch.load(os.path.join(output_dir, \"gcn_best_model.pth\"))\n",
    "\n",
    "# Print the keys to see the model structure\n",
    "print(\"Saved model layers:\")\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'weight' in key:\n",
    "        print(f\"{key}: {saved_state_dict[key].shape}\")\n",
    "\n",
    "# Function to load external dataset\n",
    "def load_external_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    molecules = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]):\n",
    "            continue\n",
    "            \n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            # If target is available, use it, otherwise set to None\n",
    "            if target_col in df.columns and not pd.isna(row[target_col]):\n",
    "                g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            else:\n",
    "                g.y = None\n",
    "                \n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "            molecules.append(row.to_dict())\n",
    "    \n",
    "    return graphs, pd.DataFrame(molecules)\n",
    "\n",
    "# Custom model class that matches the saved architecture\n",
    "class GCNForLoading(torch.nn.Module):\n",
    "    def __init__(self, in_features, hidden_size):\n",
    "        super().__init__()\n",
    "        # Initialize with the architecture from the saved model\n",
    "        # Using parameters based on the saved state shapes\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_features, hidden_size))  # Input features to hidden\n",
    "        self.convs.append(GCNConv(hidden_size, hidden_size))  # Hidden to hidden\n",
    "        self.convs.append(GCNConv(hidden_size, hidden_size))  # Hidden to hidden  \n",
    "        self.convs.append(GCNConv(hidden_size, 1))           # Hidden to output\n",
    "        self.dropout = 0.3  # Default value, will be overridden by loaded state\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, edge_index)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "# Get hidden size from saved model\n",
    "# First convolutional layer weight shape is [hidden_size, in_features]\n",
    "# Find the first weight key and get its shape\n",
    "hidden_size = None\n",
    "in_features = 20  # Our updated model has 20 input features\n",
    "\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'weight' in key and 'convs.0' in key:\n",
    "        hidden_size = saved_state_dict[key].shape[0]\n",
    "        break\n",
    "\n",
    "if hidden_size is None:\n",
    "    # Default if we couldn't determine from saved state\n",
    "    hidden_size = 64\n",
    "    print(f\"Warning: Could not determine hidden size from saved model. Using default: {hidden_size}\")\n",
    "else:\n",
    "    print(f\"Detected hidden size: {hidden_size}\")\n",
    "\n",
    "# Create the model with the correct architecture\n",
    "model = GCNForLoading(in_features=in_features, hidden_size=hidden_size)\n",
    "\n",
    "# Try to load the saved state\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(output_dir, \"gcn_best_model.pth\")))\n",
    "    print(\"Successfully loaded model weights\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model weights: {str(e)}\")\n",
    "    print(\"This may happen if the model architecture doesn't match the saved weights.\")\n",
    "    print(\"Make sure you've trained the model with the updated atom features first.\")\n",
    "    # Continue anyway for demonstration purposes\n",
    "    print(\"Continuing with uninitialized model for demonstration...\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load external dataset\n",
    "external_data, external_df = load_external_dataset(\"cancer_set.xlsx\")\n",
    "# Suppress deprecation warning for DataLoader\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    external_loader = DataLoader(external_data, batch_size=32)\n",
    "\n",
    "# Get predictions\n",
    "y_true = []\n",
    "y_probs = []\n",
    "smiles_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in external_loader:\n",
    "        try:\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            # Don't squeeze - handle the dimensionality properly\n",
    "            probs = torch.sigmoid(out).cpu().numpy()\n",
    "            \n",
    "            # Handle both single-item and multi-item batches\n",
    "            if len(probs.shape) == 0:  # Single item case (0-d array)\n",
    "                probs = np.array([probs.item()])\n",
    "            \n",
    "            for i in range(len(probs)):\n",
    "                y_probs.append(probs[i])\n",
    "                \n",
    "                # Get the SMILES safely\n",
    "                if hasattr(batch, 'smiles'):\n",
    "                    if isinstance(batch.smiles, list):\n",
    "                        smiles_list.append(batch.smiles[i])\n",
    "                    else:\n",
    "                        # Handle the case where smiles might be a single string\n",
    "                        smiles_list.append(batch.smiles)\n",
    "                \n",
    "                # Get the true value if it exists\n",
    "                if hasattr(batch, 'y') and batch.y is not None:\n",
    "                    if batch.y.dim() > 0 and i < batch.y.size(0):\n",
    "                        y_true.append(batch.y[i].item())\n",
    "                    elif batch.y.dim() == 0:  # Single item\n",
    "                        y_true.append(batch.y.item())\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Save predictions to Excel\n",
    "results_df = pd.DataFrame({\n",
    "    'Smiles': smiles_list,\n",
    "    'Predicted_Probability': y_probs,\n",
    "    'Predicted_Class': [1 if p > 0.5 else 0 for p in y_probs]\n",
    "})\n",
    "\n",
    "# If we have true values, add them and calculate metrics\n",
    "if len(y_true) > 0 and len(y_true) == len(y_probs):\n",
    "    results_df['Actual'] = y_true\n",
    "    \n",
    "    # Calculate metrics\n",
    "    y_true_np = np.array(y_true)  # Convert list to numpy array\n",
    "    y_probs_np = np.array(y_probs)\n",
    "    y_preds = (y_probs_np > 0.5).astype(int)\n",
    "    \n",
    "    # Check if we have multiple classes for metrics that require it\n",
    "    unique_classes = np.unique(y_true_np)\n",
    "    has_multiple_classes = len(unique_classes) > 1\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true_np, y_preds),\n",
    "        'Precision': precision_score(y_true_np, y_preds, zero_division=0),\n",
    "        'F1': f1_score(y_true_np, y_preds, zero_division=0),\n",
    "        'Kappa': cohen_kappa_score(y_true_np, y_preds),\n",
    "        'Brier': brier_score_loss(y_true_np, y_probs_np),\n",
    "    }\n",
    "    \n",
    "    # Only calculate AUC and MCC if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        # Suppress the UndefinedMetricWarning\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            metrics['AUC'] = roc_auc_score(y_true_np, y_probs_np)\n",
    "            metrics['MCC'] = matthews_corrcoef(y_true_np, y_preds)\n",
    "    else:\n",
    "        print(\"\\n⚠️ Warning: Only one class is present in the dataset.\")\n",
    "        print(\"AUC and MCC are not defined in this case and will be reported as N/A.\")\n",
    "        metrics['AUC'] = \"N/A\"\n",
    "        metrics['MCC'] = \"N/A\"\n",
    "    \n",
    "    # Convert N/A values to NaN for Excel export\n",
    "    metrics_for_excel = {k: np.nan if v == \"N/A\" else v for k, v in metrics.items()}\n",
    "    \n",
    "    # Save metrics\n",
    "    pd.DataFrame([metrics_for_excel]).to_excel(os.path.join(output_dir, \"external_metrics.xlsx\"), index=False)\n",
    "    \n",
    "    print(\"\\n🧪 External Dataset Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, str):\n",
    "            print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    # Only generate ROC curve if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            fpr, tpr, _ = roc_curve(y_true_np, y_probs_np)\n",
    "            \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {metrics['AUC']:.2f}\" if isinstance(metrics['AUC'], float) else \"AUC = N/A\")\n",
    "        plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"External Dataset ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_dir, \"external_roc_cancer.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true_np, y_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix - External Dataset')\n",
    "    plt.savefig(os.path.join(output_dir, \"external_confusion_matrix_cancer.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Class distribution information\n",
    "    class_counts = np.bincount(y_true_np.astype(int))\n",
    "    print(\"\\n📊 Class Distribution in External Dataset:\")\n",
    "    for i, count in enumerate(class_counts):\n",
    "        print(f\"Class {i}: {count} samples ({count/len(y_true_np)*100:.1f}%)\")\n",
    "\n",
    "# Save all predictions\n",
    "results_df.to_excel(os.path.join(output_dir, \"external_predictions_cancer.xlsx\"), index=False)\n",
    "print(f\"\\n💾 Predictions for {len(results_df)} molecules saved to {os.path.join(output_dir, 'external_predictions_cancer.xlsx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30540b-4129-4b08-ae04-2369dae4c724",
   "metadata": {},
   "source": [
    "# Explinibilty using Integrated Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df70123-896f-4740-8a6b-ddf9c8cdbe30",
   "metadata": {},
   "source": [
    "##  Dataset used dataset_main.xlsx\n",
    "- Top 40 most contributing SMILES plot\n",
    "- Feature Importance plot and saved the values in xlsx\n",
    "- Node importance vlaue saved in xlsx\n",
    "- Atom Type Importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de92515d-c605-4478-a4c9-192f65c636e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 26 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:53] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 25 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:53] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 39 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:53] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 24 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:53] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:54] The new font size 0.8 is below the current minimum (6).                                                                                            | 4/100 [00:00<00:11,  8.05it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 22 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:54] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 23 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:54] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 45 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:54] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 31 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:54] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 21 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:54] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:55] The new font size 0.8 is below the current minimum (6).                                                                                           | 10/100 [00:01<00:20,  4.44it/s]\n",
      "[17:00:55] The new font size 0.8 is below the current minimum (6).                                                                                           | 11/100 [00:01<00:20,  4.32it/s]\n",
      "[17:00:55] The new font size 0.8 is below the current minimum (6).                                                                                           | 12/100 [00:02<00:21,  4.13it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 35 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:55] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 29 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 34 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 32 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).                                                                                           | 17/100 [00:02<00:13,  6.19it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 42 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).                                                                                           | 19/100 [00:03<00:11,  7.29it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 28 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 5 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:56] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 23/100 [00:03<00:09,  8.50it/s]\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 24/100 [00:03<00:09,  8.43it/s]\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 25/100 [00:03<00:08,  8.60it/s]\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 26/100 [00:03<00:08,  8.69it/s]\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 27/100 [00:04<00:08,  8.77it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 73 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 27 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 38 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:57] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).█▎                                                                                         | 31/100 [00:04<00:08,  8.25it/s]\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).██▌                                                                                        | 32/100 [00:04<00:08,  8.45it/s]\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).███▉                                                                                       | 33/100 [00:04<00:07,  8.63it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 30 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 40 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).███████▊                                                                                   | 36/100 [00:05<00:07,  8.70it/s]\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).█████████                                                                                  | 37/100 [00:05<00:07,  8.69it/s]\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).██████████▍                                                                                | 38/100 [00:05<00:07,  8.68it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 9 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:58] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).█████████████                                                                              | 40/100 [00:05<00:06,  9.05it/s]\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).██████████████▎                                                                            | 41/100 [00:05<00:06,  8.95it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 59 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).████████████████▉                                                                          | 43/100 [00:05<00:06,  8.33it/s]\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).██████████████████▏                                                                        | 44/100 [00:05<00:06,  8.50it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 55 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 46 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).\n",
      "[17:00:59] The new font size 0.8 is below the current minimum (6).██████████████████████                                                                     | 47/100 [00:06<00:06,  8.19it/s]\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).███████████████████████▍                                                                   | 48/100 [00:06<00:06,  8.16it/s]\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).████████████████████████▋                                                                  | 49/100 [00:06<00:06,  8.19it/s]\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).██████████████████████████                                                                 | 50/100 [00:06<00:06,  8.28it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 36 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).████████████████████████████▌                                                              | 52/100 [00:06<00:05,  8.61it/s]\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).█████████████████████████████▉                                                             | 53/100 [00:07<00:05,  8.60it/s]\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).███████████████████████████████▏                                                           | 54/100 [00:07<00:05,  8.50it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 33 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:00] The new font size 0.8 is below the current minimum (6).█████████████████████████████████▊                                                         | 56/100 [00:07<00:05,  8.38it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).███████████████████████████████████                                                        | 57/100 [00:07<00:05,  8.15it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).████████████████████████████████████▍                                                      | 58/100 [00:07<00:05,  8.34it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████▋                                                     | 59/100 [00:07<00:04,  8.55it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████                                                    | 60/100 [00:07<00:04,  8.70it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████▎                                                  | 61/100 [00:07<00:04,  8.88it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████▌                                                 | 62/100 [00:08<00:04,  8.92it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████▉                                                | 63/100 [00:08<00:04,  8.91it/s]\n",
      "[17:01:01] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████▏                                              | 64/100 [00:08<00:04,  8.84it/s]\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████▌                                             | 65/100 [00:08<00:03,  8.97it/s]\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████▊                                            | 66/100 [00:08<00:03,  8.64it/s]\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████                                           | 67/100 [00:08<00:03,  8.61it/s]\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████▍                                         | 68/100 [00:08<00:03,  8.60it/s]\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████▋                                        | 69/100 [00:08<00:03,  8.68it/s]\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████                                       | 70/100 [00:09<00:03,  8.70it/s]\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████▎                                     | 71/100 [00:09<00:03,  8.75it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 41 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:02] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████▉                                   | 73/100 [00:09<00:03,  8.40it/s]\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████▏                                 | 74/100 [00:09<00:03,  8.15it/s]\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████▌                                | 75/100 [00:09<00:02,  8.33it/s]\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████▊                               | 76/100 [00:09<00:02,  8.21it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 17 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████▍                            | 78/100 [00:09<00:02,  8.45it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 43 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████                          | 80/100 [00:10<00:02,  8.32it/s]\n",
      "[17:01:03] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████▎                        | 81/100 [00:10<00:02,  8.36it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████▌                       | 82/100 [00:10<00:02,  8.60it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████▉                      | 83/100 [00:10<00:01,  8.73it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████▏                    | 84/100 [00:10<00:01,  8.70it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████▌                   | 85/100 [00:10<00:01,  8.75it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████▊                  | 86/100 [00:10<00:01,  9.00it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████████                 | 87/100 [00:11<00:01,  9.13it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████████▍               | 88/100 [00:11<00:01,  8.90it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████▋              | 89/100 [00:11<00:01,  8.99it/s]\n",
      "[17:01:04] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████████████             | 90/100 [00:11<00:01,  9.00it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 37 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████▌          | 92/100 [00:11<00:00,  8.87it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 18 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████████████████▏       | 94/100 [00:11<00:00,  8.99it/s]\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████████▌      | 95/100 [00:11<00:00,  8.69it/s]\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████████████████████████▊     | 96/100 [00:12<00:00,  8.74it/s]\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████████████████████    | 97/100 [00:12<00:00,  8.61it/s]\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████████████▍  | 98/100 [00:12<00:00,  8.70it/s]\n",
      "[17:01:05] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████████████████████████████▋ | 99/100 [00:12<00:00,  8.61it/s]\n",
      "Processing molecules: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:12<00:00,  8.00it/s]\n",
      "Analyzing feature importance: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.65it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 5 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:14] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 9 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:14] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 21 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 1: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 2: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 3: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:14] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:14] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 17 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:14] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 25 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:14] The new font size 0.8 is below the current minimum (6).\n",
      "Saving top molecule images: 6it [00:00, 10.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 4: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 5: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 6: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 24 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:14] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 26 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 22 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 7: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 8: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 9: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 31 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 27 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 28 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 10: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 11: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 12: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 13: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 14: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 15: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 29 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 32 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "Saving top molecule images: 18it [00:01, 11.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 16: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 17: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 18: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 35 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 38 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 19: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 20: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 21: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 18 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "Saving top molecule images: 24it [00:02, 12.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 22: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 23: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 24: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 25: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 26: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 27: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "Saving top molecule images: 30it [00:02, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 28: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 29: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 30: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:16] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 34 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 31: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 32: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 33: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 30 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "Saving top molecule images: 36it [00:03, 12.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 34: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 35: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 36: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 33 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 37: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 38: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 39: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:01:17] The new font size 0.8 is below the current minimum (6).\n",
      "Saving top molecule images: 40it [00:03, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 40: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 39 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 23 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 45 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 42 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 73 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 40 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 59 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 55 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 46 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 36 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 41 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 43 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 37 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "Analyzing node types: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 12.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created color-coded Excel file: apr_4/external_gcn/molecule_importances_colored.xlsx\n",
      "✅ Analysis complete! All results saved to apr_4/external_gcn\n",
      "📊 Key files generated:\n",
      " - Top 40 individual molecules: apr_4/external_gcn/top_molecules/*.png\n",
      " - Top molecules SMILES list: apr_4/external_gcn/top_molecules/top_smiles.csv\n",
      " - Feature importance analysis: apr_4/external_gcn/feature_importance.xlsx\n",
      " - Molecule importance spreadsheet: apr_4/external_gcn/molecule_importances.xlsx\n",
      " - Atom type importance: apr_4/external_gcn/atom_type_importance.png\n",
      " - All molecule visualizations: apr_4/external_gcn/molecule_viz/*.png\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: GCN Model Interpretation and Visualization\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from torch_geometric.data import DataLoader\n",
    "import seaborn as sns\n",
    "from captum.attr import IntegratedGradients\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Create output directory\n",
    "output_dir = os.path.join('GCN_results', 'external_gcn')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the trained model\n",
    "def load_trained_model(model_path, input_dim=20, hidden_params_path=os.path.join('GCN_results', 'study_best_params.json')):\n",
    "    import json\n",
    "    with open(hidden_params_path, 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    \n",
    "    model = GCN(\n",
    "        in_channels=input_dim,\n",
    "        hidden_channels=best_params['hidden_channels'],\n",
    "        out_channels=1,\n",
    "        num_layers=best_params['num_layers'],\n",
    "        dropout=best_params['dropout']\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load model\n",
    "model_path = os.path.join('GCN_results', 'gcn_best_model.pth')\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "# Load dataset (reusing the function from your original code)\n",
    "train_data = load_dataset(\"dataset_main.xlsx\")  # Load your full dataset\n",
    "\n",
    "# Helper function to create a wrapper model for attribution methods\n",
    "class GCNWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        return torch.sigmoid(self.model(x, edge_index, edge_attr, batch))\n",
    "\n",
    "# Initialize attribution method\n",
    "wrapper_model = GCNWrapper(model)\n",
    "integrated_gradients = IntegratedGradients(wrapper_model)\n",
    "\n",
    "# Function to interpret molecule graph and get node/edge importance\n",
    "def interpret_molecule(graph):\n",
    "    graph_batch = graph.clone()\n",
    "    graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "    \n",
    "    # Get integrated gradients attribution\n",
    "    node_attr = integrated_gradients.attribute(\n",
    "        graph.x, \n",
    "        additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "        internal_batch_size=1\n",
    "    )\n",
    "    \n",
    "    # Sum across feature dimensions to get per-node importance\n",
    "    node_importance = torch.abs(node_attr).sum(dim=1).detach().numpy()\n",
    "    \n",
    "    # For edge importance, we'll use a simple approximation based on connected nodes\n",
    "    edge_importance = []\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        src, dst = graph.edge_index[0, i].item(), graph.edge_index[1, i].item()\n",
    "        edge_imp = (node_importance[src] + node_importance[dst]) / 2\n",
    "        edge_importance.append(edge_imp)\n",
    "    \n",
    "    return node_importance, np.array(edge_importance)\n",
    "\n",
    "# Function to visualize molecule with importance highlighting\n",
    "def visualize_molecule_importance(smiles, node_importance, mol=None, title=None, size=(600, 600)):\n",
    "    if mol is None:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Normalize importances for coloring\n",
    "    if len(node_importance) > 0:\n",
    "        norm = Normalize(vmin=np.min(node_importance), vmax=np.max(node_importance))\n",
    "        atom_colors = {}\n",
    "        for i, imp in enumerate(node_importance):\n",
    "            color_val = norm(imp)\n",
    "            atom_colors[i] = tuple(plt.cm.viridis(color_val)[:3])\n",
    "    else:\n",
    "        atom_colors = {}\n",
    "    \n",
    "    # Create drawing\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    drawer.SetFontSize(0.8)\n",
    "    \n",
    "    # Set up atom highlights\n",
    "    highlight_atoms = list(range(mol.GetNumAtoms()))\n",
    "    highlight_bonds = []\n",
    "    highlight_atom_colors = atom_colors\n",
    "    highlight_bond_colors = {}\n",
    "    \n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        drawer.DrawMoleculeWithHighlights(\n",
    "            mol, title, \n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    else:\n",
    "        # Draw the molecule with highlights\n",
    "        drawer.DrawMolecule(\n",
    "            mol,\n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    return drawer.GetDrawingText()\n",
    "\n",
    "# Function to analyze feature importance across the dataset\n",
    "def analyze_feature_importance(data_list, top_n=20):\n",
    "    all_attributions = []\n",
    "    \n",
    "    for graph in tqdm(data_list, desc=\"Analyzing feature importance\"):\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        \n",
    "        attr = integrated_gradients.attribute(\n",
    "            graph.x, \n",
    "            additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "            internal_batch_size=1\n",
    "        )\n",
    "        \n",
    "        # Average attribution per feature across all nodes\n",
    "        avg_attr = torch.abs(attr).mean(dim=0).detach().numpy()\n",
    "        all_attributions.append(avg_attr)\n",
    "    \n",
    "    # Average across all molecules\n",
    "    feature_importance = np.mean(all_attributions, axis=0)\n",
    "    \n",
    "    # Feature names (same as in atom_features function)\n",
    "    feature_names = [\n",
    "        'Atomic number', 'Degree', 'Formal charge', 'Radical electrons', 'Is aromatic',\n",
    "        'Explicit valence', 'Implicit valence', 'Total valence', 'Implicit Hs',\n",
    "        'Hybridization', 'Total Hs', 'In ring', 'In ring size 3', 'In ring size 4',\n",
    "        'In ring size 5', 'In ring size 6', 'In ring size 7', 'Chiral tag', 'Mass',\n",
    "        'LogP contribution'\n",
    "    ]\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Create output subfolders\n",
    "viz_dir = os.path.join(output_dir, 'molecule_viz')\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "top_molecules_dir = os.path.join(output_dir, 'top_molecules')\n",
    "os.makedirs(top_molecules_dir, exist_ok=True)\n",
    "\n",
    "# Process all molecules in the dataset\n",
    "molecule_importances = []\n",
    "\n",
    "# Process a subset of molecules (limit to 100 for efficiency)\n",
    "num_molecules = min(100, len(train_data))\n",
    "\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Processing molecules\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get prediction score\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        pred_score = wrapper_model(graph.x, graph.edge_index, graph.edge_attr, graph_batch.batch).item()\n",
    "        \n",
    "        # Get node and edge importance\n",
    "        node_importance, edge_importance = interpret_molecule(graph)\n",
    "        \n",
    "        # Calculate importance metrics\n",
    "        avg_importance = np.mean(node_importance)\n",
    "        max_importance = np.max(node_importance)\n",
    "        \n",
    "        # Save molecule image with importance visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol)\n",
    "        with open(os.path.join(viz_dir, f\"mol_{i+1}.png\"), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "        \n",
    "        # Add to our results dataframe\n",
    "        molecule_importances.append({\n",
    "            'Index': i+1,\n",
    "            'SMILES': smiles,\n",
    "            'Prediction': pred_score,\n",
    "            'True_Label': graph.y.item(),\n",
    "            'Average_Importance': avg_importance,\n",
    "            'Max_Importance': max_importance,\n",
    "            'Most_Important_Atom_Index': np.argmax(node_importance)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save dataframe of molecule importances\n",
    "importance_df = pd.DataFrame(molecule_importances)\n",
    "importance_df.to_excel(os.path.join(output_dir, 'molecule_importances.xlsx'), index=False)\n",
    "\n",
    "# Create feature importance analysis\n",
    "feature_imp_df = analyze_feature_importance(train_data[:num_molecules])\n",
    "feature_imp_df.to_excel(os.path.join(output_dir, 'feature_importance.xlsx'), index=False)\n",
    "\n",
    "# Plot and save feature importance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df.head(15))\n",
    "plt.title('Top 15 Important Atom Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'feature_importance.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save individual images of top 40 molecules by importance\n",
    "top_molecules_count = min(40, len(importance_df))\n",
    "top_mols = importance_df.sort_values('Average_Importance', ascending=False).head(top_molecules_count)\n",
    "\n",
    "# Create individual high-quality images for top molecules\n",
    "for i, (_, row) in enumerate(tqdm(top_mols.iterrows(), desc=\"Saving top molecule images\")):\n",
    "    try:\n",
    "        # Get the molecule and its data\n",
    "        idx = row['Index']\n",
    "        smiles = row['SMILES']\n",
    "        pred = row['Prediction']\n",
    "        true_label = row['True_Label']\n",
    "        \n",
    "        # Get the corresponding graph data\n",
    "        graph = train_data[idx-1]  # -1 because indices start at 1 in our data\n",
    "        \n",
    "        # Re-interpret the molecule for visualization\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get node importance\n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Create a title with info\n",
    "        title = f\"#{idx}: Pred={pred:.3f}, True={true_label:.0f}, Importance={row['Average_Importance']:.3f}\"\n",
    "        \n",
    "        # Create a high-quality visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol, title=title, size=(800, 800))\n",
    "        \n",
    "        # Save to the top molecules directory\n",
    "        rank = i + 1  # 1-based ranking\n",
    "        with open(os.path.join(top_molecules_dir, f\"top_{rank}_mol_{idx}.png\"), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "            \n",
    "        # Also save a CSV with SMILES\n",
    "        with open(os.path.join(top_molecules_dir, \"top_smiles.csv\"), \"w\") as f:\n",
    "            f.write(\"Rank,MoleculeIndex,SMILES,Prediction,TrueLabel,AverageImportance\\n\")\n",
    "            for j, (_, r) in enumerate(top_mols.iterrows()):\n",
    "                f.write(f\"{j+1},{r['Index']},{r['SMILES']},{r['Prediction']:.4f},{r['True_Label']:.0f},{r['Average_Importance']:.4f}\\n\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating top molecule image for rank {i+1}: {e}\")\n",
    "\n",
    "# Create node importance analysis\n",
    "node_importances = []\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Analyzing node types\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Get atom types and their importance\n",
    "        for atom_idx, importance in enumerate(node_importance):\n",
    "            atom_symbol = mol.GetAtomWithIdx(atom_idx).GetSymbol()\n",
    "            node_importances.append({\n",
    "                'Molecule_Index': i+1,\n",
    "                'Atom_Index': atom_idx,\n",
    "                'Atom_Symbol': atom_symbol,\n",
    "                'Importance': importance\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing node for molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save node importance dataframe\n",
    "node_imp_df = pd.DataFrame(node_importances)\n",
    "node_imp_df.to_excel(os.path.join(output_dir, 'node_importances.xlsx'), index=False)\n",
    "\n",
    "# Analyze importance by atom type\n",
    "atom_importance = node_imp_df.groupby('Atom_Symbol')['Importance'].mean().reset_index()\n",
    "atom_importance = atom_importance.sort_values('Importance', ascending=False)\n",
    "atom_importance.to_excel(os.path.join(output_dir, 'atom_type_importance.xlsx'), index=False)\n",
    "\n",
    "# Plot atom type importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Atom_Symbol', data=atom_importance)\n",
    "plt.title('Average Importance by Atom Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'atom_type_importance.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create a color-coded Excel file with molecule importances\n",
    "try:\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.styles import PatternFill\n",
    "    from openpyxl.styles.differential import DifferentialStyle\n",
    "    from openpyxl.formatting.rule import ColorScaleRule\n",
    "    \n",
    "    color_excel_path = os.path.join(output_dir, 'molecule_importances_colored.xlsx')\n",
    "    importance_df.to_excel(color_excel_path, index=False)\n",
    "    \n",
    "    # Open the workbook and add color scales\n",
    "    wb = load_workbook(color_excel_path)\n",
    "    ws = wb.active\n",
    "    \n",
    "    # Add color scale to Average_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Average_Importance\") + 1  # +1 because Excel is 1-indexed\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add color scale to Max_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Max_Importance\") + 1\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Save the workbook\n",
    "    wb.save(color_excel_path)\n",
    "    print(f\"Created color-coded Excel file: {color_excel_path}\")\n",
    "except ImportError:\n",
    "    print(\"openpyxl not available - skipping colored Excel creation\")\n",
    "\n",
    "print(f\"✅ Analysis complete! All results saved to {output_dir}\")\n",
    "print(f\"📊 Key files generated:\")\n",
    "print(f\" - Top 40 individual molecules: {top_molecules_dir}/*.png\")\n",
    "print(f\" - Top molecules SMILES list: {os.path.join(top_molecules_dir, 'top_smiles.csv')}\")\n",
    "print(f\" - Feature importance analysis: {os.path.join(output_dir, 'feature_importance.xlsx')}\")\n",
    "print(f\" - Molecule importance spreadsheet: {os.path.join(output_dir, 'molecule_importances.xlsx')}\")\n",
    "print(f\" - Atom type importance: {os.path.join(output_dir, 'atom_type_importance.png')}\")\n",
    "print(f\" - All molecule visualizations: {viz_dir}/*.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7608f91-d2d2-4ee9-95a6-5b55ebe0884c",
   "metadata": {},
   "source": [
    "##  Dataset used cancer_set.xlsx(FDA approved)\n",
    "- Top 40 most contributing SMILES plot\n",
    "- Feature Importance plot and saved the values in xlsx\n",
    "- Node importance vlaue saved in xlsx\n",
    "- Atom Type Importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2526b54d-0524-42f8-a07f-abbd6cb3748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: GCN Model Interpretation and Visualization\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from torch_geometric.data import DataLoader\n",
    "import seaborn as sns\n",
    "from captum.attr import IntegratedGradients\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "\n",
    "# Create output directory\n",
    "output_dir = os.path.join('apr_4', 'external_gcn')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the trained model\n",
    "def load_trained_model(model_path, input_dim=20, hidden_params_path=os.path.join('GCN_results', 'study_best_params.json')):\n",
    "    import json\n",
    "    with open(hidden_params_path, 'r') as f:\n",
    "        best_params = json.load(f)\n",
    "    \n",
    "    model = GCN(\n",
    "        in_channels=input_dim,\n",
    "        hidden_channels=best_params['hidden_channels'],\n",
    "        out_channels=1,\n",
    "        num_layers=best_params['num_layers'],\n",
    "        dropout=best_params['dropout']\n",
    "    )\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load model\n",
    "model_path = os.path.join('GCN_results', 'gcn_best_model.pth')\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "# Load dataset (reusing the function from your original code)\n",
    "train_data = load_dataset(\"cancer_set.xlsx\")  # Load your full dataset\n",
    "\n",
    "# Helper function to create a wrapper model for attribution methods\n",
    "class GCNWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        return torch.sigmoid(self.model(x, edge_index, edge_attr, batch))\n",
    "\n",
    "# Initialize attribution method\n",
    "wrapper_model = GCNWrapper(model)\n",
    "integrated_gradients = IntegratedGradients(wrapper_model)\n",
    "\n",
    "# Function to interpret molecule graph and get node/edge importance\n",
    "def interpret_molecule(graph):\n",
    "    graph_batch = graph.clone()\n",
    "    graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "    \n",
    "    # Get integrated gradients attribution\n",
    "    node_attr = integrated_gradients.attribute(\n",
    "        graph.x, \n",
    "        additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "        internal_batch_size=1\n",
    "    )\n",
    "    \n",
    "    # Sum across feature dimensions to get per-node importance\n",
    "    node_importance = torch.abs(node_attr).sum(dim=1).detach().numpy()\n",
    "    \n",
    "    # For edge importance, we'll use a simple approximation based on connected nodes\n",
    "    edge_importance = []\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        src, dst = graph.edge_index[0, i].item(), graph.edge_index[1, i].item()\n",
    "        edge_imp = (node_importance[src] + node_importance[dst]) / 2\n",
    "        edge_importance.append(edge_imp)\n",
    "    \n",
    "    return node_importance, np.array(edge_importance)\n",
    "\n",
    "# Function to visualize molecule with importance highlighting\n",
    "def visualize_molecule_importance(smiles, node_importance, mol=None, title=None, size=(600, 600)):\n",
    "    if mol is None:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Normalize importances for coloring\n",
    "    if len(node_importance) > 0:\n",
    "        norm = Normalize(vmin=np.min(node_importance), vmax=np.max(node_importance))\n",
    "        atom_colors = {}\n",
    "        for i, imp in enumerate(node_importance):\n",
    "            color_val = norm(imp)\n",
    "            atom_colors[i] = tuple(plt.cm.viridis(color_val)[:3])\n",
    "    else:\n",
    "        atom_colors = {}\n",
    "    \n",
    "    # Create drawing\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    drawer.SetFontSize(0.8)\n",
    "    \n",
    "    # Set up atom highlights\n",
    "    highlight_atoms = list(range(mol.GetNumAtoms()))\n",
    "    highlight_bonds = []\n",
    "    highlight_atom_colors = atom_colors\n",
    "    highlight_bond_colors = {}\n",
    "    \n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        drawer.DrawMoleculeWithHighlights(\n",
    "            mol, title, \n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    else:\n",
    "        # Draw the molecule with highlights\n",
    "        drawer.DrawMolecule(\n",
    "            mol,\n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    return drawer.GetDrawingText()\n",
    "\n",
    "# Function to analyze feature importance across the dataset\n",
    "def analyze_feature_importance(data_list, top_n=20):\n",
    "    all_attributions = []\n",
    "    \n",
    "    for graph in tqdm(data_list, desc=\"Analyzing feature importance\"):\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        \n",
    "        attr = integrated_gradients.attribute(\n",
    "            graph.x, \n",
    "            additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "            internal_batch_size=1\n",
    "        )\n",
    "        \n",
    "        # Average attribution per feature across all nodes\n",
    "        avg_attr = torch.abs(attr).mean(dim=0).detach().numpy()\n",
    "        all_attributions.append(avg_attr)\n",
    "    \n",
    "    # Average across all molecules\n",
    "    feature_importance = np.mean(all_attributions, axis=0)\n",
    "    \n",
    "    # Feature names (same as in atom_features function)\n",
    "    feature_names = [\n",
    "        'Atomic number', 'Degree', 'Formal charge', 'Radical electrons', 'Is aromatic',\n",
    "        'Explicit valence', 'Implicit valence', 'Total valence', 'Implicit Hs',\n",
    "        'Hybridization', 'Total Hs', 'In ring', 'In ring size 3', 'In ring size 4',\n",
    "        'In ring size 5', 'In ring size 6', 'In ring size 7', 'Chiral tag', 'Mass',\n",
    "        'LogP contribution'\n",
    "    ]\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Create output subfolders\n",
    "viz_dir = os.path.join(output_dir, 'molecule_viz_cancer')\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "top_molecules_dir = os.path.join(output_dir, 'top_molecules_cancer')\n",
    "os.makedirs(top_molecules_dir, exist_ok=True)\n",
    "\n",
    "# Process all molecules in the dataset\n",
    "molecule_importances = []\n",
    "\n",
    "# Process a subset of molecules (limit to 100 for efficiency)\n",
    "num_molecules = min(100, len(train_data))\n",
    "\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Processing molecules\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get prediction score\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        pred_score = wrapper_model(graph.x, graph.edge_index, graph.edge_attr, graph_batch.batch).item()\n",
    "        \n",
    "        # Get node and edge importance\n",
    "        node_importance, edge_importance = interpret_molecule(graph)\n",
    "        \n",
    "        # Calculate importance metrics\n",
    "        avg_importance = np.mean(node_importance)\n",
    "        max_importance = np.max(node_importance)\n",
    "        \n",
    "        # Save molecule image with importance visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol)\n",
    "        with open(os.path.join(viz_dir, f\"mol_{i+1}.png\"), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "        \n",
    "        # Add to our results dataframe\n",
    "        molecule_importances.append({\n",
    "            'Index': i+1,\n",
    "            'SMILES': smiles,\n",
    "            'Prediction': pred_score,\n",
    "            'True_Label': graph.y.item(),\n",
    "            'Average_Importance': avg_importance,\n",
    "            'Max_Importance': max_importance,\n",
    "            'Most_Important_Atom_Index': np.argmax(node_importance)\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save dataframe of molecule importances\n",
    "importance_df = pd.DataFrame(molecule_importances)\n",
    "importance_df.to_excel(os.path.join(output_dir, 'molecule_importances_cancer.xlsx'), index=False)\n",
    "\n",
    "# Create feature importance analysis\n",
    "feature_imp_df = analyze_feature_importance(train_data[:num_molecules])\n",
    "feature_imp_df.to_excel(os.path.join(output_dir, 'feature_importance_cancer.xlsx'), index=False)\n",
    "\n",
    "# Plot and save feature importance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df.head(15))\n",
    "plt.title('Top 15 Important Atom Features')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'feature_importance_cancer.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Save individual images of top 40 molecules by importance\n",
    "top_molecules_count = min(40, len(importance_df))\n",
    "top_mols = importance_df.sort_values('Average_Importance', ascending=False).head(top_molecules_count)\n",
    "\n",
    "# Create individual high-quality images for top molecules\n",
    "for i, (_, row) in enumerate(tqdm(top_mols.iterrows(), desc=\"Saving top molecule images\")):\n",
    "    try:\n",
    "        # Get the molecule and its data\n",
    "        idx = row['Index']\n",
    "        smiles = row['SMILES']\n",
    "        pred = row['Prediction']\n",
    "        true_label = row['True_Label']\n",
    "        \n",
    "        # Get the corresponding graph data\n",
    "        graph = train_data[idx-1]  # -1 because indices start at 1 in our data\n",
    "        \n",
    "        # Re-interpret the molecule for visualization\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get node importance\n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Create a title with info\n",
    "        title = f\"#{idx}: Pred={pred:.3f}, True={true_label:.0f}, Importance={row['Average_Importance']:.3f}\"\n",
    "        \n",
    "        # Create a high-quality visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol, title=title, size=(800, 800))\n",
    "        \n",
    "        # Save to the top molecules directory\n",
    "        rank = i + 1  # 1-based ranking\n",
    "        with open(os.path.join(top_molecules_dir, f\"top_{rank}_mol_{idx}.png\"), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "            \n",
    "        # Also save a CSV with SMILES\n",
    "        with open(os.path.join(top_molecules_dir, \"top_smiles_cancer.csv\"), \"w\") as f:\n",
    "            f.write(\"Rank,MoleculeIndex,SMILES,Prediction,TrueLabel,AverageImportance\\n\")\n",
    "            for j, (_, r) in enumerate(top_mols.iterrows()):\n",
    "                f.write(f\"{j+1},{r['Index']},{r['SMILES']},{r['Prediction']:.4f},{r['True_Label']:.0f},{r['Average_Importance']:.4f}\\n\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating top molecule image for rank {i+1}: {e}\")\n",
    "\n",
    "# Create node importance analysis\n",
    "node_importances = []\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Analyzing node types\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Get atom types and their importance\n",
    "        for atom_idx, importance in enumerate(node_importance):\n",
    "            atom_symbol = mol.GetAtomWithIdx(atom_idx).GetSymbol()\n",
    "            node_importances.append({\n",
    "                'Molecule_Index': i+1,\n",
    "                'Atom_Index': atom_idx,\n",
    "                'Atom_Symbol': atom_symbol,\n",
    "                'Importance': importance\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing node for molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save node importance dataframe\n",
    "node_imp_df = pd.DataFrame(node_importances)\n",
    "node_imp_df.to_excel(os.path.join(output_dir, 'node_importances_cancer.xlsx'), index=False)\n",
    "\n",
    "# Analyze importance by atom type\n",
    "atom_importance = node_imp_df.groupby('Atom_Symbol')['Importance'].mean().reset_index()\n",
    "atom_importance = atom_importance.sort_values('Importance', ascending=False)\n",
    "atom_importance.to_excel(os.path.join(output_dir, 'atom_type_importance_cancer.xlsx'), index=False)\n",
    "\n",
    "# Plot atom type importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Atom_Symbol', data=atom_importance)\n",
    "plt.title('Average Importance by Atom Type')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'atom_type_importance.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create a color-coded Excel file with molecule importances\n",
    "try:\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.styles import PatternFill\n",
    "    from openpyxl.styles.differential import DifferentialStyle\n",
    "    from openpyxl.formatting.rule import ColorScaleRule\n",
    "    \n",
    "    color_excel_path = os.path.join(output_dir, 'molecule_importances_colored.xlsx')\n",
    "    importance_df.to_excel(color_excel_path, index=False)\n",
    "    \n",
    "    # Open the workbook and add color scales\n",
    "    wb = load_workbook(color_excel_path)\n",
    "    ws = wb.active\n",
    "    \n",
    "    # Add color scale to Average_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Average_Importance\") + 1  # +1 because Excel is 1-indexed\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add color scale to Max_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Max_Importance\") + 1\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Save the workbook\n",
    "    wb.save(color_excel_path)\n",
    "    print(f\"Created color-coded Excel file: {color_excel_path}\")\n",
    "except ImportError:\n",
    "    print(\"openpyxl not available - skipping colored Excel creation\")\n",
    "\n",
    "print(f\"✅ Analysis complete! All results saved to {output_dir}\")\n",
    "print(f\"📊 Key files generated:\")\n",
    "print(f\" - Top 40 individual molecules: {top_molecules_dir}/*.png\")\n",
    "print(f\" - Top molecules SMILES list: {os.path.join(top_molecules_dir, 'top_smiles_cancer.csv')}\")\n",
    "print(f\" - Feature importance analysis: {os.path.join(output_dir, 'feature_importance_cancer.xlsx')}\")\n",
    "print(f\" - Molecule importance spreadsheet: {os.path.join(output_dir, 'molecule_importances_cancer.xlsx')}\")\n",
    "print(f\" - Atom type importance: {os.path.join(output_dir, 'atom_type_importance_cancer.png')}\")\n",
    "print(f\" - All molecule visualizations: {viz_dir}/*.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1bcef4-5ba2-48e6-852c-bf964c5d2316",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

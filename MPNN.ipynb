{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a17a2b8-2818-466f-b5a4-3ba2b8327c71",
   "metadata": {},
   "source": [
    "# Model Development\n",
    "- Train/Test Split > Tuning > Cross Verification > Training > Testing > Model Saved\n",
    "- Traing Loss and Training AUC Plot and Test ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44183c76-8152-4351-a4c8-5c95e5a4d22b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "[I 2025-04-09 14:48:53,816] A new study created in memory with name: no-name-4c9b0b74-890c-4e75-85e8-05929752f37f\n",
      "[I 2025-04-09 14:49:22,520] Trial 0 finished with value: 0.6256338028169015 and parameters: {'hidden_dim': 73, 'num_layers': 4, 'dropout': 0.30296209264264473, 'lr': 0.004412178103906789}. Best is trial 0 with value: 0.6256338028169015.\n",
      "[I 2025-04-09 14:50:09,328] Trial 1 finished with value: 0.6740845070422534 and parameters: {'hidden_dim': 122, 'num_layers': 2, 'dropout': 0.4938890948189606, 'lr': 0.00033366716040300224}. Best is trial 1 with value: 0.6740845070422534.\n",
      "[I 2025-04-09 14:50:24,553] Trial 2 finished with value: 0.5101408450704226 and parameters: {'hidden_dim': 58, 'num_layers': 4, 'dropout': 0.306553857134593, 'lr': 0.0030901717006129154}. Best is trial 1 with value: 0.6740845070422534.\n",
      "[I 2025-04-09 14:50:35,062] Trial 3 finished with value: 0.6585915492957747 and parameters: {'hidden_dim': 55, 'num_layers': 3, 'dropout': 0.454323858858788, 'lr': 0.0002079617398843695}. Best is trial 1 with value: 0.6740845070422534.\n",
      "[I 2025-04-09 14:50:45,057] Trial 4 finished with value: 0.7459154929577464 and parameters: {'hidden_dim': 60, 'num_layers': 2, 'dropout': 0.32315222121147424, 'lr': 0.0008244593391164163}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:51:02,150] Trial 5 finished with value: 0.6574647887323943 and parameters: {'hidden_dim': 63, 'num_layers': 3, 'dropout': 0.47313824549350114, 'lr': 0.007093924110568259}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:51:15,385] Trial 6 finished with value: 0.7123943661971831 and parameters: {'hidden_dim': 58, 'num_layers': 3, 'dropout': 0.3001944343347266, 'lr': 0.00038285297931105297}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:51:53,878] Trial 7 finished with value: 0.6864788732394366 and parameters: {'hidden_dim': 93, 'num_layers': 3, 'dropout': 0.377256860369806, 'lr': 0.0009058065115115252}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:52:03,919] Trial 8 finished with value: 0.6811267605633803 and parameters: {'hidden_dim': 48, 'num_layers': 4, 'dropout': 0.21111524291896908, 'lr': 0.002166374973474334}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:52:14,657] Trial 9 finished with value: 0.6135211267605634 and parameters: {'hidden_dim': 64, 'num_layers': 2, 'dropout': 0.40355993963972514, 'lr': 0.00027759495552991424}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:52:17,352] Trial 10 finished with value: 0.6856338028169014 and parameters: {'hidden_dim': 34, 'num_layers': 2, 'dropout': 0.14070394440346948, 'lr': 0.0011713046508816508}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:52:41,001] Trial 11 finished with value: 0.6994366197183098 and parameters: {'hidden_dim': 89, 'num_layers': 2, 'dropout': 0.24502779218481346, 'lr': 0.0001002282198833027}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:52:46,147] Trial 12 finished with value: 0.6757746478873239 and parameters: {'hidden_dim': 36, 'num_layers': 3, 'dropout': 0.3499389709839539, 'lr': 0.0006611046907281539}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:53:03,286] Trial 13 finished with value: 0.676056338028169 and parameters: {'hidden_dim': 76, 'num_layers': 2, 'dropout': 0.24222417267517277, 'lr': 0.00045348992246552986}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:53:54,755] Trial 14 finished with value: 0.6811267605633803 and parameters: {'hidden_dim': 103, 'num_layers': 3, 'dropout': 0.14274286895199478, 'lr': 0.0011812901767770199}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:54:02,346] Trial 15 finished with value: 0.6408450704225352 and parameters: {'hidden_dim': 45, 'num_layers': 3, 'dropout': 0.34159170918489146, 'lr': 0.0001502811790582361}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:54:18,060] Trial 16 finished with value: 0.6923943661971831 and parameters: {'hidden_dim': 71, 'num_layers': 2, 'dropout': 0.4178928350203526, 'lr': 0.0005414576145458751}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:54:26,826] Trial 17 finished with value: 0.6447887323943662 and parameters: {'hidden_dim': 46, 'num_layers': 4, 'dropout': 0.20321564959287158, 'lr': 0.0016676584871471382}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:54:46,436] Trial 18 finished with value: 0.7261971830985916 and parameters: {'hidden_dim': 84, 'num_layers': 2, 'dropout': 0.2597184333748413, 'lr': 0.0008009730513151501}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:55:24,902] Trial 19 finished with value: 0.7126760563380282 and parameters: {'hidden_dim': 110, 'num_layers': 2, 'dropout': 0.1008145326517482, 'lr': 0.000775630054186285}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:55:45,581] Trial 20 finished with value: 0.5935211267605633 and parameters: {'hidden_dim': 83, 'num_layers': 2, 'dropout': 0.25599913106074634, 'lr': 0.001550207897170231}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:56:25,564] Trial 21 finished with value: 0.6788732394366197 and parameters: {'hidden_dim': 115, 'num_layers': 2, 'dropout': 0.10894205362510123, 'lr': 0.0007185267151597117}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:56:57,731] Trial 22 finished with value: 0.6808450704225352 and parameters: {'hidden_dim': 104, 'num_layers': 2, 'dropout': 0.17771996766230386, 'lr': 0.00093466049392578}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:58:02,941] Trial 23 finished with value: 0.7132394366197182 and parameters: {'hidden_dim': 127, 'num_layers': 2, 'dropout': 0.10367572746235479, 'lr': 0.0025148208106941833}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:58:59,043] Trial 24 finished with value: 0.688450704225352 and parameters: {'hidden_dim': 126, 'num_layers': 2, 'dropout': 0.16244053360056931, 'lr': 0.002735972853897998}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 14:59:25,743] Trial 25 finished with value: 0.7278873239436618 and parameters: {'hidden_dim': 92, 'num_layers': 2, 'dropout': 0.27324700135947305, 'lr': 0.0050988896633049514}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 15:00:13,404] Trial 26 finished with value: 0.7152112676056337 and parameters: {'hidden_dim': 92, 'num_layers': 2, 'dropout': 0.26573553471246386, 'lr': 0.008112722006472768}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 15:00:36,933] Trial 27 finished with value: 0.6929577464788732 and parameters: {'hidden_dim': 83, 'num_layers': 2, 'dropout': 0.3266699253329961, 'lr': 0.005027877583867413}. Best is trial 4 with value: 0.7459154929577464.\n",
      "[I 2025-04-09 15:01:20,083] Trial 28 finished with value: 0.7473239436619717 and parameters: {'hidden_dim': 99, 'num_layers': 3, 'dropout': 0.279499035058576, 'lr': 0.0015741618050324486}. Best is trial 28 with value: 0.7473239436619717.\n",
      "[I 2025-04-09 15:02:10,458] Trial 29 finished with value: 0.6949295774647888 and parameters: {'hidden_dim': 100, 'num_layers': 3, 'dropout': 0.2826252954099629, 'lr': 0.004318594727021703}. Best is trial 28 with value: 0.7473239436619717.\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 10-Fold Cross-Validation Mean Metrics:\n",
      "AUC: 0.7346\n",
      "Accuracy: 0.6906\n",
      "MCC: 0.3023\n",
      "Precision: 0.6952\n",
      "F1: 0.7823\n",
      "Kappa: 0.2681\n",
      "Brier: 0.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Final Train] Epoch 1 | Loss: 0.6789 | AUC: 0.6587\n",
      "[Final Train] Epoch 2 | Loss: 0.6615 | AUC: 0.6431\n",
      "[Final Train] Epoch 3 | Loss: 0.6504 | AUC: 0.6567\n",
      "[Final Train] Epoch 4 | Loss: 0.6485 | AUC: 0.6628\n",
      "[Final Train] Epoch 5 | Loss: 0.6377 | AUC: 0.6669\n",
      "[Final Train] Epoch 6 | Loss: 0.6357 | AUC: 0.6799\n",
      "[Final Train] Epoch 7 | Loss: 0.6426 | AUC: 0.6671\n",
      "[Final Train] Epoch 8 | Loss: 0.6295 | AUC: 0.6828\n",
      "[Final Train] Epoch 9 | Loss: 0.6326 | AUC: 0.6875\n",
      "[Final Train] Epoch 10 | Loss: 0.6181 | AUC: 0.7008\n",
      "[Final Train] Epoch 11 | Loss: 0.6113 | AUC: 0.6981\n",
      "[Final Train] Epoch 12 | Loss: 0.6433 | AUC: 0.7076\n",
      "[Final Train] Epoch 13 | Loss: 0.6262 | AUC: 0.7120\n",
      "[Final Train] Epoch 14 | Loss: 0.6069 | AUC: 0.7169\n",
      "[Final Train] Epoch 15 | Loss: 0.6024 | AUC: 0.7202\n",
      "[Final Train] Epoch 16 | Loss: 0.5999 | AUC: 0.7264\n",
      "[Final Train] Epoch 17 | Loss: 0.5991 | AUC: 0.7205\n",
      "[Final Train] Epoch 18 | Loss: 0.6052 | AUC: 0.7338\n",
      "[Final Train] Epoch 19 | Loss: 0.6090 | AUC: 0.7372\n",
      "[Final Train] Epoch 20 | Loss: 0.5986 | AUC: 0.7404\n",
      "[Final Train] Epoch 21 | Loss: 0.5885 | AUC: 0.7410\n",
      "[Final Train] Epoch 22 | Loss: 0.5902 | AUC: 0.7555\n",
      "[Final Train] Epoch 23 | Loss: 0.5829 | AUC: 0.7525\n",
      "[Final Train] Epoch 24 | Loss: 0.5905 | AUC: 0.7477\n",
      "[Final Train] Epoch 25 | Loss: 0.5942 | AUC: 0.7580\n",
      "[Final Train] Epoch 26 | Loss: 0.5735 | AUC: 0.7616\n",
      "[Final Train] Epoch 27 | Loss: 0.5697 | AUC: 0.7632\n",
      "[Final Train] Epoch 28 | Loss: 0.5675 | AUC: 0.7718\n",
      "[Final Train] Epoch 29 | Loss: 0.5717 | AUC: 0.7734\n",
      "[Final Train] Epoch 30 | Loss: 0.5731 | AUC: 0.7789\n",
      "[Final Train] Epoch 31 | Loss: 0.5581 | AUC: 0.7739\n",
      "[Final Train] Epoch 32 | Loss: 0.5621 | AUC: 0.7812\n",
      "[Final Train] Epoch 33 | Loss: 0.5665 | AUC: 0.7895\n",
      "[Final Train] Epoch 34 | Loss: 0.5519 | AUC: 0.7868\n",
      "[Final Train] Epoch 35 | Loss: 0.5685 | AUC: 0.7805\n",
      "[Final Train] Epoch 36 | Loss: 0.5597 | AUC: 0.7829\n",
      "[Final Train] Epoch 37 | Loss: 0.5666 | AUC: 0.7824\n",
      "[Final Train] Epoch 38 | Loss: 0.5584 | AUC: 0.7863\n",
      "[Final Train] Epoch 39 | Loss: 0.5616 | AUC: 0.7959\n",
      "[Final Train] Epoch 40 | Loss: 0.5396 | AUC: 0.8008\n",
      "[Final Train] Epoch 41 | Loss: 0.5444 | AUC: 0.8092\n",
      "[Final Train] Epoch 42 | Loss: 0.5333 | AUC: 0.8098\n",
      "[Final Train] Epoch 43 | Loss: 0.5376 | AUC: 0.8060\n",
      "[Final Train] Epoch 44 | Loss: 0.5464 | AUC: 0.8144\n",
      "[Final Train] Epoch 45 | Loss: 0.5354 | AUC: 0.8143\n",
      "[Final Train] Epoch 46 | Loss: 0.5440 | AUC: 0.8221\n",
      "[Final Train] Epoch 47 | Loss: 0.5374 | AUC: 0.8262\n",
      "[Final Train] Epoch 48 | Loss: 0.5337 | AUC: 0.8225\n",
      "[Final Train] Epoch 49 | Loss: 0.5221 | AUC: 0.8239\n",
      "[Final Train] Epoch 50 | Loss: 0.5202 | AUC: 0.8248\n",
      "[Final Train] Epoch 51 | Loss: 0.5339 | AUC: 0.8169\n",
      "[Final Train] Epoch 52 | Loss: 0.5377 | AUC: 0.8266\n",
      "[Final Train] Epoch 53 | Loss: 0.5540 | AUC: 0.8127\n",
      "[Final Train] Epoch 54 | Loss: 0.5353 | AUC: 0.8252\n",
      "[Final Train] Epoch 55 | Loss: 0.5249 | AUC: 0.8356\n",
      "[Final Train] Epoch 56 | Loss: 0.5105 | AUC: 0.8286\n",
      "[Final Train] Epoch 57 | Loss: 0.5086 | AUC: 0.8410\n",
      "[Final Train] Epoch 58 | Loss: 0.5117 | AUC: 0.8448\n",
      "[Final Train] Epoch 59 | Loss: 0.4956 | AUC: 0.8381\n",
      "[Final Train] Epoch 60 | Loss: 0.5044 | AUC: 0.8429\n",
      "[Final Train] Epoch 61 | Loss: 0.4915 | AUC: 0.8351\n",
      "[Final Train] Epoch 62 | Loss: 0.5116 | AUC: 0.8274\n",
      "[Final Train] Epoch 63 | Loss: 0.5294 | AUC: 0.8408\n",
      "[Final Train] Epoch 64 | Loss: 0.4902 | AUC: 0.8482\n",
      "[Final Train] Epoch 65 | Loss: 0.5040 | AUC: 0.8445\n",
      "[Final Train] Epoch 66 | Loss: 0.4862 | AUC: 0.8540\n",
      "[Final Train] Epoch 67 | Loss: 0.5045 | AUC: 0.8558\n",
      "[Final Train] Epoch 68 | Loss: 0.4884 | AUC: 0.8553\n",
      "[Final Train] Epoch 69 | Loss: 0.4916 | AUC: 0.8517\n",
      "[Final Train] Epoch 70 | Loss: 0.4900 | AUC: 0.8574\n",
      "[Final Train] Epoch 71 | Loss: 0.4818 | AUC: 0.8547\n",
      "[Final Train] Epoch 72 | Loss: 0.4891 | AUC: 0.8601\n",
      "[Final Train] Epoch 73 | Loss: 0.4704 | AUC: 0.8645\n",
      "[Final Train] Epoch 74 | Loss: 0.4957 | AUC: 0.8554\n",
      "[Final Train] Epoch 75 | Loss: 0.4967 | AUC: 0.8501\n",
      "[Final Train] Epoch 76 | Loss: 0.4887 | AUC: 0.8611\n",
      "[Final Train] Epoch 77 | Loss: 0.4927 | AUC: 0.8627\n",
      "[Final Train] Epoch 78 | Loss: 0.4751 | AUC: 0.8540\n",
      "[Final Train] Epoch 79 | Loss: 0.4786 | AUC: 0.8673\n",
      "[Final Train] Epoch 80 | Loss: 0.4712 | AUC: 0.8669\n",
      "[Final Train] Epoch 81 | Loss: 0.4799 | AUC: 0.8700\n",
      "[Final Train] Epoch 82 | Loss: 0.4825 | AUC: 0.8614\n",
      "[Final Train] Epoch 83 | Loss: 0.4709 | AUC: 0.8695\n",
      "[Final Train] Epoch 84 | Loss: 0.4922 | AUC: 0.8731\n",
      "[Final Train] Epoch 85 | Loss: 0.4684 | AUC: 0.8631\n",
      "[Final Train] Epoch 86 | Loss: 0.4864 | AUC: 0.8704\n",
      "[Final Train] Epoch 87 | Loss: 0.4679 | AUC: 0.8745\n",
      "[Final Train] Epoch 88 | Loss: 0.4796 | AUC: 0.8712\n",
      "[Final Train] Epoch 89 | Loss: 0.4714 | AUC: 0.8754\n",
      "[Final Train] Epoch 90 | Loss: 0.4876 | AUC: 0.8566\n",
      "[Final Train] Epoch 91 | Loss: 0.4936 | AUC: 0.8741\n",
      "[Final Train] Epoch 92 | Loss: 0.4731 | AUC: 0.8673\n",
      "[Final Train] Epoch 93 | Loss: 0.4559 | AUC: 0.8694\n",
      "[Final Train] Epoch 94 | Loss: 0.4986 | AUC: 0.8601\n",
      "[Final Train] Epoch 95 | Loss: 0.4869 | AUC: 0.8455\n",
      "[Final Train] Epoch 96 | Loss: 0.5187 | AUC: 0.8515\n",
      "[Final Train] Epoch 97 | Loss: 0.4953 | AUC: 0.8543\n",
      "[Final Train] Epoch 98 | Loss: 0.4925 | AUC: 0.8722\n",
      "[Final Train] Epoch 99 | Loss: 0.5226 | AUC: 0.8672\n",
      "[Final Train] Epoch 100 | Loss: 0.5015 | AUC: 0.8660\n",
      "\n",
      "🧪 Final Test Set Metrics:\n",
      "AUC: 0.8273\n",
      "Accuracy: 0.7961\n",
      "MCC: 0.5444\n",
      "Precision: 0.8190\n",
      "F1: 0.8473\n",
      "Kappa: 0.5415\n",
      "Brier: 0.1578\n"
     ]
    }
   ],
   "source": [
    "# combined_mpnn_pipeline_optuna_cv.py\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, accuracy_score, matthews_corrcoef,\n",
    "    cohen_kappa_score, brier_score_loss, confusion_matrix,\n",
    "    precision_score, f1_score, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "# Ensure output directory\n",
    "output_dir = 'MPNN_results'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Expanded atom features\n",
    "def atom_features(atom):\n",
    "    return torch.tensor([\n",
    "        # Basic properties\n",
    "        atom.GetAtomicNum(),                     # Atomic number\n",
    "        atom.GetDegree(),                        # Number of bonded neighbors\n",
    "        atom.GetFormalCharge(),                  # Formal charge\n",
    "        atom.GetNumRadicalElectrons(),           # Number of radical electrons\n",
    "        int(atom.GetIsAromatic()),               # Aromaticity flag\n",
    "        \n",
    "        # Extended properties\n",
    "        atom.GetExplicitValence(),               # Explicit valence\n",
    "        atom.GetImplicitValence(),               # Implicit valence\n",
    "        atom.GetTotalValence(),                  # Total valence\n",
    "        atom.GetNumImplicitHs(),                 # Number of implicit hydrogens\n",
    "        atom.GetHybridization(),                 # Hybridization state\n",
    "        atom.GetTotalNumHs(),                    # Total number of hydrogens\n",
    "        \n",
    "        # Topological properties\n",
    "        int(atom.IsInRing()),                    # Whether the atom is in a ring\n",
    "        int(atom.IsInRingSize(3)),               # Whether in 3-membered ring\n",
    "        int(atom.IsInRingSize(4)),               # Whether in 4-membered ring\n",
    "        int(atom.IsInRingSize(5)),               # Whether in 5-membered ring\n",
    "        int(atom.IsInRingSize(6)),               # Whether in 6-membered ring\n",
    "        int(atom.IsInRingSize(7)),               # Whether in 7-membered ring\n",
    "        \n",
    "        # Electronic properties\n",
    "        atom.GetChiralTag(),                     # Chirality\n",
    "        atom.GetMass(),                          # Atomic mass\n",
    "        Chem.rdMolDescriptors.CalcCrippenDescriptors(\n",
    "            Chem.MolFromSmiles(f\"[{atom.GetSymbol()}]\"))[0]  # LogP contribution\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "# Molecule to PyTorch Geometric graph\n",
    "def mol_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    atoms = [atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    if not atoms: return None\n",
    "    x = torch.stack(atoms, dim=0)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "    edge_attr = [[bond.GetBondTypeAsDouble(), bond.GetIsConjugated(), bond.IsInRing()] * 2 for bond in mol.GetBonds()]\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).reshape(-1, 3)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "# Load dataset\n",
    "def load_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]) or pd.isna(row[target_col]):\n",
    "            continue\n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "# MPNN model to replace GAT\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_encoder = torch.nn.Linear(node_dim, hidden_dim)\n",
    "        self.edge_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            nn = torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.convs.append(NNConv(hidden_dim, hidden_dim, self.edge_encoder))\n",
    "        \n",
    "        self.gru = torch.nn.GRU(hidden_dim, hidden_dim)\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim // 2, out_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Initial encoding\n",
    "        x = self.node_encoder(x)\n",
    "        h = x.unsqueeze(0)\n",
    "        \n",
    "        # Message passing layers\n",
    "        for conv in self.convs:\n",
    "            m = F.relu(conv(x, edge_index, edge_attr))\n",
    "            m = F.dropout(m, p=self.dropout, training=self.training)\n",
    "            # Use GRU to update the hidden representation\n",
    "            x = x.unsqueeze(0)\n",
    "            m = m.unsqueeze(0)\n",
    "            _, h = self.gru(m, h)\n",
    "            x = h.squeeze(0)\n",
    "        \n",
    "        # Global pooling and output\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Training and AUC\n",
    "def train(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "        loss = criterion(torch.sigmoid(out), data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def compute_auc(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_probs = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            y_probs.extend(torch.sigmoid(out).cpu().numpy())\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "    return roc_auc_score(y_true, y_probs)\n",
    "\n",
    "# Model evaluation\n",
    "def get_metrics(model, loader):\n",
    "    model.eval()\n",
    "    y_true, y_probs = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            y_probs.extend(torch.sigmoid(out).cpu().numpy())\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "    y_preds = (np.array(y_probs) > 0.5).astype(int)\n",
    "    return {\n",
    "        'AUC': roc_auc_score(y_true, y_probs),\n",
    "        'Accuracy': accuracy_score(y_true, y_preds),\n",
    "        'MCC': matthews_corrcoef(y_true, y_preds),\n",
    "        'Precision': precision_score(y_true, y_preds),\n",
    "        'F1': f1_score(y_true, y_preds),\n",
    "        'Kappa': cohen_kappa_score(y_true, y_preds),\n",
    "        'Brier': brier_score_loss(y_true, y_probs),\n",
    "    }\n",
    "\n",
    "# Globals for Optuna\n",
    "trial_train_loader = None\n",
    "trial_val_loader = None\n",
    "\n",
    "# Optuna objective\n",
    "def objective(trial):\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 32, 128)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "\n",
    "    model = MPNN(20, 3, hidden_dim, 1, num_layers, dropout)  # Using MPNN model\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    for epoch in range(10):\n",
    "        train(model, trial_train_loader, optimizer, criterion)\n",
    "\n",
    "    return compute_auc(model, trial_val_loader)\n",
    "\n",
    "def main():\n",
    "    global trial_train_loader, trial_val_loader\n",
    "\n",
    "    graphs = load_dataset(\"dataset_main.xlsx\")\n",
    "    train_data, test_data = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "    trial_train, trial_val = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "    trial_train_loader = DataLoader(trial_train, batch_size=32, shuffle=True)\n",
    "    trial_val_loader = DataLoader(trial_val, batch_size=32)\n",
    "\n",
    "    # Optuna tuning\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=30)\n",
    "    best_params = study.best_trial.params\n",
    "    json.dump(best_params, open(os.path.join(output_dir, \"study_best_params_mpnn.json\"), \"w\"), indent=4)\n",
    "\n",
    "    # 10-fold cross-validation (mean metrics only)\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    metrics_list = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train_data), start=1):\n",
    "        model = MPNN(20, 3, best_params[\"hidden_dim\"], 1, \n",
    "                   best_params[\"num_layers\"], best_params[\"dropout\"])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "        criterion = torch.nn.BCELoss()\n",
    "\n",
    "        train_fold = [train_data[i] for i in train_idx]\n",
    "        val_fold = [train_data[i] for i in val_idx]\n",
    "        loader_train = DataLoader(train_fold, batch_size=32, shuffle=True)\n",
    "        loader_val = DataLoader(val_fold, batch_size=32)\n",
    "\n",
    "        for epoch in range(30):\n",
    "            train(model, loader_train, optimizer, criterion)\n",
    "\n",
    "        metrics = get_metrics(model, loader_val)\n",
    "        metrics_list.append(metrics)\n",
    "\n",
    "    # Save and print mean of cross-validation metrics\n",
    "    df_cv = pd.DataFrame(metrics_list)\n",
    "    mean_metrics = df_cv.mean()\n",
    "    df_cv.loc['mean'] = mean_metrics\n",
    "    df_cv.tail(1).to_excel(os.path.join(output_dir, \"cv_metrics_mean.xlsx\"), index=False)\n",
    "\n",
    "    print(\"\\n📊 10-Fold Cross-Validation Mean Metrics:\")\n",
    "    for key, value in mean_metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "    # Final training on full training set\n",
    "    full_train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "    final_model = MPNN(20, 3, best_params[\"hidden_dim\"], 1, \n",
    "                      best_params[\"num_layers\"], best_params[\"dropout\"])\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(), lr=best_params[\"lr\"])\n",
    "    criterion = torch.nn.BCELoss()\n",
    "\n",
    "    losses, aucs = [], []\n",
    "    for epoch in range(1, 101):\n",
    "        loss = train(final_model, full_train_loader, optimizer, criterion)\n",
    "        auc = compute_auc(final_model, full_train_loader)\n",
    "        losses.append(loss)\n",
    "        aucs.append(auc)\n",
    "        print(f\"[Final Train] Epoch {epoch} | Loss: {loss:.4f} | AUC: {auc:.4f}\")\n",
    "\n",
    "    torch.save(final_model.state_dict(), os.path.join(output_dir, \"mpnn_best_model.pth\"))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(losses, label=\"Loss\")\n",
    "    plt.title(\"Final Training Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig(os.path.join(output_dir, \"final_training_loss.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(aucs, label=\"AUC\", color='red')\n",
    "    plt.title(\"Final Training AUC\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"AUC\")\n",
    "    plt.savefig(os.path.join(output_dir, \"final_training_auc.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Final test set evaluation\n",
    "    test_metrics = get_metrics(final_model, test_loader)\n",
    "    pd.DataFrame([test_metrics]).to_excel(os.path.join(output_dir, \"test_metrics.xlsx\"), index=False)\n",
    "\n",
    "    print(\"\\n🧪 Final Test Set Metrics:\")\n",
    "    for key, value in test_metrics.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "\n",
    "    # ROC Curve\n",
    "    model = final_model\n",
    "    model.eval()\n",
    "    y_true, y_probs = [], []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            y_probs.extend(torch.sigmoid(out).cpu().numpy())\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_probs)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {test_metrics['AUC']:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Test ROC Curve\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, \"test_roc.png\"))\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbebb58-e5aa-4e91-818a-0d5e32f89a33",
   "metadata": {},
   "source": [
    "## Confusion matrix creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d318594-0640-4451-8364-29b196793702",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd15/Desktop/Amarjit/myvenv/lib/python3.11/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n",
      "\n",
      "===== Confusion Matrix =====\n",
      "True Negative (TN): 35\n",
      "False Positive (FP): 19\n",
      "False Negative (FN): 12\n",
      "True Positive (TP): 86\n",
      "\n",
      "===== Detailed Metrics =====\n",
      "True Positive Rate (Sensitivity/Recall): 0.8776\n",
      "True Negative Rate (Specificity): 0.6481\n",
      "False Positive Rate: 0.3519\n",
      "False Negative Rate: 0.1224\n",
      "Precision: 0.8190\n",
      "F1 Score: 0.8473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from torch_geometric.data import DataLoader, Data\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "\n",
    "# Reuse the necessary functions from cell1\n",
    "def atom_features(atom):\n",
    "    return torch.tensor([\n",
    "        # Basic properties\n",
    "        atom.GetAtomicNum(),\n",
    "        atom.GetDegree(),\n",
    "        atom.GetFormalCharge(),\n",
    "        atom.GetNumRadicalElectrons(),\n",
    "        int(atom.GetIsAromatic()),\n",
    "        \n",
    "        # Extended properties\n",
    "        atom.GetExplicitValence(),\n",
    "        atom.GetImplicitValence(),\n",
    "        atom.GetTotalValence(),\n",
    "        atom.GetNumImplicitHs(),\n",
    "        atom.GetHybridization(),\n",
    "        atom.GetTotalNumHs(),\n",
    "        \n",
    "        # Topological properties\n",
    "        int(atom.IsInRing()),\n",
    "        int(atom.IsInRingSize(3)),\n",
    "        int(atom.IsInRingSize(4)),\n",
    "        int(atom.IsInRingSize(5)),\n",
    "        int(atom.IsInRingSize(6)),\n",
    "        int(atom.IsInRingSize(7)),\n",
    "        \n",
    "        # Electronic properties\n",
    "        atom.GetChiralTag(),\n",
    "        atom.GetMass(),\n",
    "        Chem.rdMolDescriptors.CalcCrippenDescriptors(\n",
    "            Chem.MolFromSmiles(f\"[{atom.GetSymbol()}]\"))[0]\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "def mol_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    atoms = [atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    if not atoms: return None\n",
    "    x = torch.stack(atoms, dim=0)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "    edge_attr = [[bond.GetBondTypeAsDouble(), bond.GetIsConjugated(), bond.IsInRing()] * 2 for bond in mol.GetBonds()]\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).reshape(-1, 3)\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "def load_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]) or pd.isna(row[target_col]):\n",
    "            continue\n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "# Use MPNN class instead of GAT\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_encoder = torch.nn.Linear(node_dim, hidden_dim)\n",
    "        self.edge_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            nn = torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.convs.append(NNConv(hidden_dim, hidden_dim, self.edge_encoder))\n",
    "        \n",
    "        self.gru = torch.nn.GRU(hidden_dim, hidden_dim)\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim // 2, out_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Initial encoding\n",
    "        x = self.node_encoder(x)\n",
    "        h = x.unsqueeze(0)\n",
    "        \n",
    "        # Message passing layers\n",
    "        for conv in self.convs:\n",
    "            m = F.relu(conv(x, edge_index, edge_attr))\n",
    "            m = F.dropout(m, p=self.dropout, training=self.training)\n",
    "            # Use GRU to update the hidden representation\n",
    "            x = x.unsqueeze(0)\n",
    "            m = m.unsqueeze(0)\n",
    "            _, h = self.gru(m, h)\n",
    "            x = h.squeeze(0)\n",
    "        \n",
    "        # Global pooling and output\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Main execution for generating confusion matrix\n",
    "def generate_confusion_matrix():\n",
    "    output_dir = 'MPNN_result'  # Changed from 'apr_4_gat' to 'apr_4_mpnn'\n",
    "    \n",
    "    # Load the best parameters\n",
    "    try:\n",
    "        with open(os.path.join(output_dir, \"study_best_params_mpnn.json\"), \"r\") as f:  # Changed filename\n",
    "            best_params = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"Best parameters file not found. Using default parameters.\")\n",
    "        best_params = {\n",
    "            \"hidden_dim\": 64,\n",
    "            \"num_layers\": 3, \n",
    "            \"dropout\": 0.3,\n",
    "            \"lr\": 0.001\n",
    "        }\n",
    "    \n",
    "    # Load dataset and create test loader\n",
    "    graphs = load_dataset(\"dataset_main.xlsx\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    _, test_data = train_test_split(graphs, test_size=0.2, random_state=42)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "    \n",
    "    # Initialize MPNN model with best parameters\n",
    "    model = MPNN(20, 3, best_params[\"hidden_dim\"], 1, \n",
    "                best_params[\"num_layers\"], best_params[\"dropout\"])\n",
    "    \n",
    "    # Load trained model weights\n",
    "    try:\n",
    "        model.load_state_dict(torch.load(os.path.join(output_dir, \"mpnn_best_model.pth\")))  # Changed filename\n",
    "        print(\"Model loaded successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model file not found. Cannot generate confusion matrix without trained model.\")\n",
    "        return\n",
    "    \n",
    "    # Generate predictions\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    y_probs = []\n",
    "    molecule_smiles = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data.x, data.edge_index, data.edge_attr, data.batch).squeeze()\n",
    "            probs = torch.sigmoid(out).cpu().numpy()\n",
    "            preds = (probs > 0.5).astype(int)\n",
    "            \n",
    "            y_probs.extend(probs)\n",
    "            y_pred.extend(preds)\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "            molecule_smiles.extend([g.smiles for g in data.to_data_list()])\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    class_names = ['Negative', 'Positive']\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
    "    plt.title('Confusion Matrix for MPNN Model')  # Changed title\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"confusion_matrix.png\"))\n",
    "    \n",
    "    # Create a prettier confusion matrix with seaborn\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix for MPNN Model')  # Changed title\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"confusion_matrix_seaborn.png\"))\n",
    "    \n",
    "    # Create a dataframe with predictions for analysis\n",
    "    results_df = pd.DataFrame({\n",
    "        'SMILES': molecule_smiles,\n",
    "        'True_Label': y_true,\n",
    "        'Predicted_Label': y_pred,\n",
    "        'Prediction_Probability': y_probs\n",
    "    })\n",
    "    \n",
    "    # Save predictions to Excel\n",
    "    results_df.to_excel(os.path.join(output_dir, \"prediction_results.xlsx\"), index=False)\n",
    "    \n",
    "    # Calculate metrics for each class\n",
    "    TN, FP, FN, TP = cm.ravel()\n",
    "    \n",
    "    # True Positive Rate (Sensitivity or Recall)\n",
    "    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # True Negative Rate (Specificity)\n",
    "    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    \n",
    "    # False Positive Rate\n",
    "    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0\n",
    "    \n",
    "    # False Negative Rate\n",
    "    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    \n",
    "    # Precision\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    \n",
    "    # F1 Score\n",
    "    f1 = 2 * TP / (2 * TP + FP + FN) if (2 * TP + FP + FN) > 0 else 0\n",
    "    \n",
    "    # Print detailed metrics\n",
    "    print(\"\\n===== Confusion Matrix =====\")\n",
    "    print(f\"True Negative (TN): {TN}\")\n",
    "    print(f\"False Positive (FP): {FP}\")\n",
    "    print(f\"False Negative (FN): {FN}\")\n",
    "    print(f\"True Positive (TP): {TP}\")\n",
    "    print(\"\\n===== Detailed Metrics =====\")\n",
    "    print(f\"True Positive Rate (Sensitivity/Recall): {TPR:.4f}\")\n",
    "    print(f\"True Negative Rate (Specificity): {TNR:.4f}\")\n",
    "    print(f\"False Positive Rate: {FPR:.4f}\")\n",
    "    print(f\"False Negative Rate: {FNR:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    # Save metrics to file\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['TN', 'FP', 'FN', 'TP', 'Sensitivity/Recall', 'Specificity', \n",
    "                  'False Positive Rate', 'False Negative Rate', 'Precision', 'F1 Score'],\n",
    "        'Value': [TN, FP, FN, TP, TPR, TNR, FPR, FNR, precision, f1]\n",
    "    })\n",
    "    metrics_df.to_excel(os.path.join(output_dir, \"detailed_metrics.xlsx\"), index=False)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Run the function\n",
    "if __name__ == \"__main__\":\n",
    "    generate_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126b6ce0-5621-4a0b-ba2e-f4a0f19d5bdf",
   "metadata": {},
   "source": [
    "# External Dataset Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a2138-e886-4c85-b813-593f98acef45",
   "metadata": {},
   "source": [
    "## Phytos_Results.xlsx\n",
    "- Predicted Results saved to excel\n",
    "- ROC plot and Confusion Matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96f4939-1c09-4ca0-8130-308d00b3c3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model layers:\n",
      "node_encoder.weight: torch.Size([99, 20])\n",
      "edge_encoder.0.weight: torch.Size([99, 3])\n",
      "edge_encoder.2.weight: torch.Size([9801, 99])\n",
      "convs.0.nn.0.weight: torch.Size([99, 3])\n",
      "convs.0.nn.2.weight: torch.Size([9801, 99])\n",
      "convs.0.lin.weight: torch.Size([99, 99])\n",
      "convs.1.nn.0.weight: torch.Size([99, 3])\n",
      "convs.1.nn.2.weight: torch.Size([9801, 99])\n",
      "convs.1.lin.weight: torch.Size([99, 99])\n",
      "convs.2.nn.0.weight: torch.Size([99, 3])\n",
      "convs.2.nn.2.weight: torch.Size([9801, 99])\n",
      "convs.2.lin.weight: torch.Size([99, 99])\n",
      "gru.weight_ih_l0: torch.Size([297, 99])\n",
      "gru.weight_hh_l0: torch.Size([297, 99])\n",
      "output.0.weight: torch.Size([49, 99])\n",
      "output.3.weight: torch.Size([1, 49])\n",
      "Detected hidden_dim: 99\n",
      "Detected num_layers: 3\n",
      "Successfully loaded model weights\n",
      "\n",
      "⚠️ Warning: Only one class is present in the dataset.\n",
      "AUC and MCC are not defined in this case and will be reported as N/A.\n",
      "\n",
      "🧪 External Dataset Metrics:\n",
      "Accuracy: 0.5461\n",
      "Precision: 1.0000\n",
      "F1: 0.7064\n",
      "Kappa: 0.0000\n",
      "Brier: 0.3051\n",
      "AUC: N/A\n",
      "MCC: N/A\n",
      "\n",
      "📊 Class Distribution in External Dataset:\n",
      "Class 0: 0 samples (0.0%)\n",
      "Class 1: 1313 samples (100.0%)\n",
      "\n",
      "💾 Predictions for 1313 molecules saved to apr_4_mpnn/external_predictions.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: External Dataset Evaluation with Fixed MPNN Model Loading\n",
    "\n",
    "# Import additional required libraries\n",
    "import seaborn as sns\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = 'MPNN_result'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# First, examine the saved model to understand its architecture\n",
    "saved_state_dict = torch.load(os.path.join(output_dir, \"mpnn_best_model.pth\"))\n",
    "\n",
    "# Print the keys to see the model structure\n",
    "print(\"Saved model layers:\")\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'weight' in key:\n",
    "        print(f\"{key}: {saved_state_dict[key].shape}\")\n",
    "\n",
    "# Function to load external dataset\n",
    "def load_external_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    molecules = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]):\n",
    "            continue\n",
    "            \n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            # If target is available, use it, otherwise set to None\n",
    "            if target_col in df.columns and not pd.isna(row[target_col]):\n",
    "                g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            else:\n",
    "                g.y = None\n",
    "                \n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "            molecules.append(row.to_dict())\n",
    "    \n",
    "    return graphs, pd.DataFrame(molecules)\n",
    "\n",
    "# Custom model class that matches the saved MPNN architecture\n",
    "class MPNNForLoading(torch.nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_encoder = torch.nn.Linear(node_dim, hidden_dim)\n",
    "        self.edge_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            nn = torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.convs.append(NNConv(hidden_dim, hidden_dim, self.edge_encoder))\n",
    "        \n",
    "        self.gru = torch.nn.GRU(hidden_dim, hidden_dim)\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim // 2, out_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Initial encoding\n",
    "        x = self.node_encoder(x)\n",
    "        h = x.unsqueeze(0)\n",
    "        \n",
    "        # Message passing layers\n",
    "        for conv in self.convs:\n",
    "            m = F.relu(conv(x, edge_index, edge_attr))\n",
    "            m = F.dropout(m, p=self.dropout, training=self.training)\n",
    "            # Use GRU to update the hidden representation\n",
    "            x = x.unsqueeze(0)\n",
    "            m = m.unsqueeze(0)\n",
    "            _, h = self.gru(m, h)\n",
    "            x = h.squeeze(0)\n",
    "        \n",
    "        # Global pooling and output\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Try to determine model architecture from saved weights\n",
    "hidden_dim = None\n",
    "num_layers = 0\n",
    "node_dim = 20  # Our atom features dimension\n",
    "edge_dim = 3   # Our edge features dimension\n",
    "\n",
    "# Analyze the saved state dict to infer parameters\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'convs.' in key and 'weight' in key:\n",
    "        # Count the number of convolution layers\n",
    "        layer_num = int(key.split('.')[1])\n",
    "        num_layers = max(num_layers, layer_num + 1)\n",
    "    \n",
    "    if 'node_encoder.weight' in key:\n",
    "        # Node encoder shape is [hidden_dim, node_dim]\n",
    "        shape = saved_state_dict[key].shape\n",
    "        if len(shape) == 2:\n",
    "            hidden_dim = shape[0]\n",
    "\n",
    "if hidden_dim is None:\n",
    "    # Default if we couldn't determine from saved state\n",
    "    hidden_dim = 64\n",
    "    print(f\"Warning: Could not determine hidden_dim from saved model. Using default: hidden_dim={hidden_dim}\")\n",
    "else:\n",
    "    print(f\"Detected hidden_dim: {hidden_dim}\")\n",
    "\n",
    "if num_layers == 0:\n",
    "    # Default number of layers\n",
    "    num_layers = 3\n",
    "    print(f\"Warning: Could not determine num_layers from saved model. Using default: num_layers={num_layers}\")\n",
    "else:\n",
    "    print(f\"Detected num_layers: {num_layers}\")\n",
    "\n",
    "# Create the model with the inferred architecture\n",
    "model = MPNNForLoading(\n",
    "    node_dim=node_dim,\n",
    "    edge_dim=edge_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    out_dim=1,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.3  # Default value, will be overridden by loaded state\n",
    ")\n",
    "\n",
    "# Try to load the saved state\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(output_dir, \"mpnn_best_model.pth\")))\n",
    "    print(\"Successfully loaded model weights\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model weights: {str(e)}\")\n",
    "    print(\"This may happen if the model architecture doesn't match the saved weights.\")\n",
    "    print(\"Make sure you've trained the model with the updated atom features first.\")\n",
    "    # Continue anyway for demonstration purposes\n",
    "    print(\"Continuing with uninitialized model for demonstration...\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load external dataset\n",
    "external_data, external_df = load_external_dataset(\"Phytos_results.xlsx\")\n",
    "# Suppress deprecation warning for DataLoader\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    external_loader = DataLoader(external_data, batch_size=32)\n",
    "\n",
    "# Get predictions\n",
    "y_true = []\n",
    "y_probs = []\n",
    "smiles_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in external_loader:\n",
    "        try:\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            # Don't squeeze - handle the dimensionality properly\n",
    "            probs = torch.sigmoid(out).cpu().numpy()\n",
    "            \n",
    "            # Handle both single-item and multi-item batches\n",
    "            if len(probs.shape) == 0:  # Single item case (0-d array)\n",
    "                probs = np.array([probs.item()])\n",
    "            \n",
    "            for i in range(len(probs)):\n",
    "                y_probs.append(probs[i])\n",
    "                \n",
    "                # Get the SMILES safely\n",
    "                if hasattr(batch, 'smiles'):\n",
    "                    if isinstance(batch.smiles, list):\n",
    "                        smiles_list.append(batch.smiles[i])\n",
    "                    else:\n",
    "                        # Handle the case where smiles might be a single string\n",
    "                        smiles_list.append(batch.smiles)\n",
    "                \n",
    "                # Get the true value if it exists\n",
    "                if hasattr(batch, 'y') and batch.y is not None:\n",
    "                    if batch.y.dim() > 0 and i < batch.y.size(0):\n",
    "                        y_true.append(batch.y[i].item())\n",
    "                    elif batch.y.dim() == 0:  # Single item\n",
    "                        y_true.append(batch.y.item())\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Save predictions to Excel\n",
    "results_df = pd.DataFrame({\n",
    "    'Smiles': smiles_list,\n",
    "    'Predicted_Probability': y_probs,\n",
    "    'Predicted_Class': [1 if p > 0.5 else 0 for p in y_probs]\n",
    "})\n",
    "\n",
    "# If we have true values, add them and calculate metrics\n",
    "if len(y_true) > 0 and len(y_true) == len(y_probs):\n",
    "    results_df['Actual'] = y_true\n",
    "    \n",
    "    # Calculate metrics\n",
    "    y_true_np = np.array(y_true)  # Convert list to numpy array\n",
    "    y_probs_np = np.array(y_probs)\n",
    "    y_preds = (y_probs_np > 0.5).astype(int)\n",
    "    \n",
    "    # Check if we have multiple classes for metrics that require it\n",
    "    unique_classes = np.unique(y_true_np)\n",
    "    has_multiple_classes = len(unique_classes) > 1\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true_np, y_preds),\n",
    "        'Precision': precision_score(y_true_np, y_preds, zero_division=0),\n",
    "        'F1': f1_score(y_true_np, y_preds, zero_division=0),\n",
    "        'Kappa': cohen_kappa_score(y_true_np, y_preds),\n",
    "        'Brier': brier_score_loss(y_true_np, y_probs_np),\n",
    "    }\n",
    "    \n",
    "    # Only calculate AUC and MCC if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        # Suppress the UndefinedMetricWarning\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            metrics['AUC'] = roc_auc_score(y_true_np, y_probs_np)\n",
    "            metrics['MCC'] = matthews_corrcoef(y_true_np, y_preds)\n",
    "    else:\n",
    "        print(\"\\n⚠️ Warning: Only one class is present in the dataset.\")\n",
    "        print(\"AUC and MCC are not defined in this case and will be reported as N/A.\")\n",
    "        metrics['AUC'] = \"N/A\"\n",
    "        metrics['MCC'] = \"N/A\"\n",
    "    \n",
    "    # Convert N/A values to NaN for Excel export\n",
    "    metrics_for_excel = {k: np.nan if v == \"N/A\" else v for k, v in metrics.items()}\n",
    "    \n",
    "    # Save metrics\n",
    "    pd.DataFrame([metrics_for_excel]).to_excel(os.path.join(output_dir, \"external_metrics.xlsx\"), index=False)\n",
    "    \n",
    "    print(\"\\n🧪 External Dataset Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, str):\n",
    "            print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    # Only generate ROC curve if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            fpr, tpr, _ = roc_curve(y_true_np, y_probs_np)\n",
    "            \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {metrics['AUC']:.2f}\" if isinstance(metrics['AUC'], float) else \"AUC = N/A\")\n",
    "        plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"External Dataset ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_dir, \"external_roc.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true_np, y_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix - External Dataset')\n",
    "    plt.savefig(os.path.join(output_dir, \"external_confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Class distribution information\n",
    "    class_counts = np.bincount(y_true_np.astype(int))\n",
    "    print(\"\\n📊 Class Distribution in External Dataset:\")\n",
    "    for i, count in enumerate(class_counts):\n",
    "        print(f\"Class {i}: {count} samples ({count/len(y_true_np)*100:.1f}%)\")\n",
    "\n",
    "# Save all predictions\n",
    "results_df.to_excel(os.path.join(output_dir, \"external_predictions.xlsx\"), index=False)\n",
    "print(f\"\\n💾 Predictions for {len(results_df)} molecules saved to {os.path.join(output_dir, 'external_predictions.xlsx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e353e864-25bc-413f-b94b-cf90118c8d48",
   "metadata": {},
   "source": [
    "## cancer_set.xlsx\n",
    "- Predicted Results saved to excel\n",
    "- ROC plot and Confusion Matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe45656-0696-464d-872b-df82acb7fc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model layers:\n",
      "node_encoder.weight: torch.Size([99, 20])\n",
      "edge_encoder.0.weight: torch.Size([99, 3])\n",
      "edge_encoder.2.weight: torch.Size([9801, 99])\n",
      "convs.0.nn.0.weight: torch.Size([99, 3])\n",
      "convs.0.nn.2.weight: torch.Size([9801, 99])\n",
      "convs.0.lin.weight: torch.Size([99, 99])\n",
      "convs.1.nn.0.weight: torch.Size([99, 3])\n",
      "convs.1.nn.2.weight: torch.Size([9801, 99])\n",
      "convs.1.lin.weight: torch.Size([99, 99])\n",
      "convs.2.nn.0.weight: torch.Size([99, 3])\n",
      "convs.2.nn.2.weight: torch.Size([9801, 99])\n",
      "convs.2.lin.weight: torch.Size([99, 99])\n",
      "gru.weight_ih_l0: torch.Size([297, 99])\n",
      "gru.weight_hh_l0: torch.Size([297, 99])\n",
      "output.0.weight: torch.Size([49, 99])\n",
      "output.3.weight: torch.Size([1, 49])\n",
      "Detected hidden_dim: 99\n",
      "Detected num_layers: 3\n",
      "Successfully loaded model weights\n",
      "\n",
      "⚠️ Warning: Only one class is present in the dataset.\n",
      "AUC and MCC are not defined in this case and will be reported as N/A.\n",
      "\n",
      "🧪 External Dataset Metrics:\n",
      "Accuracy: 0.6613\n",
      "Precision: 1.0000\n",
      "F1: 0.7961\n",
      "Kappa: 0.0000\n",
      "Brier: 0.2660\n",
      "AUC: N/A\n",
      "MCC: N/A\n",
      "\n",
      "📊 Class Distribution in External Dataset:\n",
      "Class 0: 0 samples (0.0%)\n",
      "Class 1: 248 samples (100.0%)\n",
      "\n",
      "💾 Predictions for 248 molecules saved to apr_4_mpnn/external_predictions_cancer.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: External Dataset Evaluation with Fixed MPNN Model Loading\n",
    "\n",
    "# Import additional required libraries\n",
    "import seaborn as sns\n",
    "from sklearn.exceptions import UndefinedMetricWarning\n",
    "import warnings\n",
    "\n",
    "# Ensure output directory exists\n",
    "output_dir = 'MPNN_result'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# First, examine the saved model to understand its architecture\n",
    "saved_state_dict = torch.load(os.path.join(output_dir, \"mpnn_best_model.pth\"))\n",
    "\n",
    "# Print the keys to see the model structure\n",
    "print(\"Saved model layers:\")\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'weight' in key:\n",
    "        print(f\"{key}: {saved_state_dict[key].shape}\")\n",
    "\n",
    "# Function to load external dataset\n",
    "def load_external_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    molecules = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]):\n",
    "            continue\n",
    "            \n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            # If target is available, use it, otherwise set to None\n",
    "            if target_col in df.columns and not pd.isna(row[target_col]):\n",
    "                g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            else:\n",
    "                g.y = None\n",
    "                \n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "            molecules.append(row.to_dict())\n",
    "    \n",
    "    return graphs, pd.DataFrame(molecules)\n",
    "\n",
    "# Custom model class that matches the saved MPNN architecture\n",
    "class MPNNForLoading(torch.nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_encoder = torch.nn.Linear(node_dim, hidden_dim)\n",
    "        self.edge_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            nn = torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.convs.append(NNConv(hidden_dim, hidden_dim, self.edge_encoder))\n",
    "        \n",
    "        self.gru = torch.nn.GRU(hidden_dim, hidden_dim)\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim // 2, out_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Initial encoding\n",
    "        x = self.node_encoder(x)\n",
    "        h = x.unsqueeze(0)\n",
    "        \n",
    "        # Message passing layers\n",
    "        for conv in self.convs:\n",
    "            m = F.relu(conv(x, edge_index, edge_attr))\n",
    "            m = F.dropout(m, p=self.dropout, training=self.training)\n",
    "            # Use GRU to update the hidden representation\n",
    "            x = x.unsqueeze(0)\n",
    "            m = m.unsqueeze(0)\n",
    "            _, h = self.gru(m, h)\n",
    "            x = h.squeeze(0)\n",
    "        \n",
    "        # Global pooling and output\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Try to determine model architecture from saved weights\n",
    "hidden_dim = None\n",
    "num_layers = 0\n",
    "node_dim = 20  # Our atom features dimension\n",
    "edge_dim = 3   # Our edge features dimension\n",
    "\n",
    "# Analyze the saved state dict to infer parameters\n",
    "for key in saved_state_dict.keys():\n",
    "    if 'convs.' in key and 'weight' in key:\n",
    "        # Count the number of convolution layers\n",
    "        layer_num = int(key.split('.')[1])\n",
    "        num_layers = max(num_layers, layer_num + 1)\n",
    "    \n",
    "    if 'node_encoder.weight' in key:\n",
    "        # Node encoder shape is [hidden_dim, node_dim]\n",
    "        shape = saved_state_dict[key].shape\n",
    "        if len(shape) == 2:\n",
    "            hidden_dim = shape[0]\n",
    "\n",
    "if hidden_dim is None:\n",
    "    # Default if we couldn't determine from saved state\n",
    "    hidden_dim = 64\n",
    "    print(f\"Warning: Could not determine hidden_dim from saved model. Using default: hidden_dim={hidden_dim}\")\n",
    "else:\n",
    "    print(f\"Detected hidden_dim: {hidden_dim}\")\n",
    "\n",
    "if num_layers == 0:\n",
    "    # Default number of layers\n",
    "    num_layers = 3\n",
    "    print(f\"Warning: Could not determine num_layers from saved model. Using default: num_layers={num_layers}\")\n",
    "else:\n",
    "    print(f\"Detected num_layers: {num_layers}\")\n",
    "\n",
    "# Create the model with the inferred architecture\n",
    "model = MPNNForLoading(\n",
    "    node_dim=node_dim,\n",
    "    edge_dim=edge_dim,\n",
    "    hidden_dim=hidden_dim,\n",
    "    out_dim=1,\n",
    "    num_layers=num_layers,\n",
    "    dropout=0.3  # Default value, will be overridden by loaded state\n",
    ")\n",
    "\n",
    "# Try to load the saved state\n",
    "try:\n",
    "    model.load_state_dict(torch.load(os.path.join(output_dir, \"mpnn_best_model.pth\")))\n",
    "    print(\"Successfully loaded model weights\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model weights: {str(e)}\")\n",
    "    print(\"This may happen if the model architecture doesn't match the saved weights.\")\n",
    "    print(\"Make sure you've trained the model with the updated atom features first.\")\n",
    "    # Continue anyway for demonstration purposes\n",
    "    print(\"Continuing with uninitialized model for demonstration...\")\n",
    "\n",
    "# Set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load external dataset\n",
    "external_data, external_df = load_external_dataset(\"cancer_set.xlsx\")\n",
    "# Suppress deprecation warning for DataLoader\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "    external_loader = DataLoader(external_data, batch_size=32)\n",
    "\n",
    "# Get predictions\n",
    "y_true = []\n",
    "y_probs = []\n",
    "smiles_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in external_loader:\n",
    "        try:\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr, batch.batch)\n",
    "            # Don't squeeze - handle the dimensionality properly\n",
    "            probs = torch.sigmoid(out).cpu().numpy()\n",
    "            \n",
    "            # Handle both single-item and multi-item batches\n",
    "            if len(probs.shape) == 0:  # Single item case (0-d array)\n",
    "                probs = np.array([probs.item()])\n",
    "            \n",
    "            for i in range(len(probs)):\n",
    "                y_probs.append(probs[i])\n",
    "                \n",
    "                # Get the SMILES safely\n",
    "                if hasattr(batch, 'smiles'):\n",
    "                    if isinstance(batch.smiles, list):\n",
    "                        smiles_list.append(batch.smiles[i])\n",
    "                    else:\n",
    "                        # Handle the case where smiles might be a single string\n",
    "                        smiles_list.append(batch.smiles)\n",
    "                \n",
    "                # Get the true value if it exists\n",
    "                if hasattr(batch, 'y') and batch.y is not None:\n",
    "                    if batch.y.dim() > 0 and i < batch.y.size(0):\n",
    "                        y_true.append(batch.y[i].item())\n",
    "                    elif batch.y.dim() == 0:  # Single item\n",
    "                        y_true.append(batch.y.item())\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing batch: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Save predictions to Excel\n",
    "results_df = pd.DataFrame({\n",
    "    'Smiles': smiles_list,\n",
    "    'Predicted_Probability': y_probs,\n",
    "    'Predicted_Class': [1 if p > 0.5 else 0 for p in y_probs]\n",
    "})\n",
    "\n",
    "# If we have true values, add them and calculate metrics\n",
    "if len(y_true) > 0 and len(y_true) == len(y_probs):\n",
    "    results_df['Actual'] = y_true\n",
    "    \n",
    "    # Calculate metrics\n",
    "    y_true_np = np.array(y_true)  # Convert list to numpy array\n",
    "    y_probs_np = np.array(y_probs)\n",
    "    y_preds = (y_probs_np > 0.5).astype(int)\n",
    "    \n",
    "    # Check if we have multiple classes for metrics that require it\n",
    "    unique_classes = np.unique(y_true_np)\n",
    "    has_multiple_classes = len(unique_classes) > 1\n",
    "    \n",
    "    metrics = {\n",
    "        'Accuracy': accuracy_score(y_true_np, y_preds),\n",
    "        'Precision': precision_score(y_true_np, y_preds, zero_division=0),\n",
    "        'F1': f1_score(y_true_np, y_preds, zero_division=0),\n",
    "        'Kappa': cohen_kappa_score(y_true_np, y_preds),\n",
    "        'Brier': brier_score_loss(y_true_np, y_probs_np),\n",
    "    }\n",
    "    \n",
    "    # Only calculate AUC and MCC if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        # Suppress the UndefinedMetricWarning\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            metrics['AUC'] = roc_auc_score(y_true_np, y_probs_np)\n",
    "            metrics['MCC'] = matthews_corrcoef(y_true_np, y_preds)\n",
    "    else:\n",
    "        print(\"\\n⚠️ Warning: Only one class is present in the dataset.\")\n",
    "        print(\"AUC and MCC are not defined in this case and will be reported as N/A.\")\n",
    "        metrics['AUC'] = \"N/A\"\n",
    "        metrics['MCC'] = \"N/A\"\n",
    "    \n",
    "    # Convert N/A values to NaN for Excel export\n",
    "    metrics_for_excel = {k: np.nan if v == \"N/A\" else v for k, v in metrics.items()}\n",
    "    \n",
    "    # Save metrics\n",
    "    pd.DataFrame([metrics_for_excel]).to_excel(os.path.join(output_dir, \"external_metrics_cancer.xlsx\"), index=False)\n",
    "    \n",
    "    print(\"\\n🧪 External Dataset Metrics:\")\n",
    "    for key, value in metrics.items():\n",
    "        if isinstance(value, str):\n",
    "            print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    # Only generate ROC curve if we have multiple classes\n",
    "    if has_multiple_classes:\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n",
    "            fpr, tpr, _ = roc_curve(y_true_np, y_probs_np)\n",
    "            \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(fpr, tpr, label=f\"AUC = {metrics['AUC']:.2f}\" if isinstance(metrics['AUC'], float) else \"AUC = N/A\")\n",
    "        plt.plot([0, 1], [0, 1], '--', color='gray')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(\"External Dataset ROC Curve\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_dir, \"external_roc_cancer.png\"))\n",
    "        plt.close()\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_true_np, y_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix - External Dataset')\n",
    "    plt.savefig(os.path.join(output_dir, \"external_confusion_matrix_cancer.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # Class distribution information\n",
    "    class_counts = np.bincount(y_true_np.astype(int))\n",
    "    print(\"\\n📊 Class Distribution in External Dataset:\")\n",
    "    for i, count in enumerate(class_counts):\n",
    "        print(f\"Class {i}: {count} samples ({count/len(y_true_np)*100:.1f}%)\")\n",
    "\n",
    "# Save all predictions\n",
    "results_df.to_excel(os.path.join(output_dir, \"external_predictions_cancer.xlsx\"), index=False)\n",
    "print(f\"\\n💾 Predictions for {len(results_df)} molecules saved to {os.path.join(output_dir, 'external_predictions_cancer.xlsx')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a906bbd7-3b30-4548-abcb-d5f6d61bc247",
   "metadata": {},
   "source": [
    "# Explinibilty using Integrated Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38f5064-6ba4-4ca6-95a4-b9d4f60d47a3",
   "metadata": {},
   "source": [
    "##  Dataset used dataset_main.xlsx\n",
    "- Top 40 most contributing SMILES plot\n",
    "- Feature Importance plot and saved the values in xlsx\n",
    "- Node importance vlaue saved in xlsx\n",
    "- Atom Type Importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a8465-6fd4-40f7-b90c-3d55685324d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 26 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:53] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 25 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:54] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 39 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:54] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 24 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:55] The new font size 0.8 is below the current minimum (6).\n",
      "[15:41:55] The new font size 0.8 is below the current minimum (6).                                                                                            | 4/100 [00:02<00:52,  1.84it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 22 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:55] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 23 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:56] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 45 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:56] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 31 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:56] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 21 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:57] The new font size 0.8 is below the current minimum (6).\n",
      "[15:41:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 10/100 [00:04<00:29,  3.03it/s]\n",
      "[15:41:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 11/100 [00:04<00:28,  3.17it/s]\n",
      "[15:41:57] The new font size 0.8 is below the current minimum (6).                                                                                           | 12/100 [00:05<00:26,  3.30it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 35 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:58] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 29 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:58] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 34 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:58] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 32 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:59] The new font size 0.8 is below the current minimum (6).\n",
      "[15:41:59] The new font size 0.8 is below the current minimum (6).                                                                                           | 17/100 [00:06<00:27,  3.03it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 42 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:41:59] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:00] The new font size 0.8 is below the current minimum (6).                                                                                           | 19/100 [00:07<00:27,  2.99it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 28 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:00] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 5 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:00] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:01] The new font size 0.8 is below the current minimum (6).                                                                                           | 22/100 [00:08<00:21,  3.58it/s]\n",
      "[15:42:01] The new font size 0.8 is below the current minimum (6).                                                                                           | 23/100 [00:08<00:22,  3.48it/s]\n",
      "[15:42:01] The new font size 0.8 is below the current minimum (6).                                                                                           | 24/100 [00:08<00:23,  3.17it/s]\n",
      "[15:42:02] The new font size 0.8 is below the current minimum (6).                                                                                           | 25/100 [00:09<00:23,  3.23it/s]\n",
      "[15:42:02] The new font size 0.8 is below the current minimum (6).                                                                                           | 26/100 [00:09<00:23,  3.15it/s]\n",
      "[15:42:02] The new font size 0.8 is below the current minimum (6).                                                                                           | 27/100 [00:09<00:23,  3.07it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 73 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:03] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 27 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:03] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 38 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:04] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:04] The new font size 0.8 is below the current minimum (6).█▎                                                                                         | 31/100 [00:11<00:26,  2.63it/s]\n",
      "[15:42:04] The new font size 0.8 is below the current minimum (6).██▌                                                                                        | 32/100 [00:11<00:25,  2.67it/s]\n",
      "[15:42:05] The new font size 0.8 is below the current minimum (6).███▉                                                                                       | 33/100 [00:12<00:24,  2.76it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 30 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:05] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 40 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:05] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:06] The new font size 0.8 is below the current minimum (6).███████▊                                                                                   | 36/100 [00:13<00:23,  2.69it/s]\n",
      "[15:42:06] The new font size 0.8 is below the current minimum (6).█████████                                                                                  | 37/100 [00:13<00:23,  2.64it/s]\n",
      "[15:42:06] The new font size 0.8 is below the current minimum (6).██████████▍                                                                                | 38/100 [00:14<00:23,  2.66it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 9 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:07] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:07] The new font size 0.8 is below the current minimum (6).█████████████                                                                              | 40/100 [00:14<00:19,  3.02it/s]\n",
      "[15:42:07] The new font size 0.8 is below the current minimum (6).██████████████▎                                                                            | 41/100 [00:14<00:19,  3.06it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 59 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:08] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:08] The new font size 0.8 is below the current minimum (6).████████████████▉                                                                          | 43/100 [00:15<00:22,  2.56it/s]\n",
      "[15:42:09] The new font size 0.8 is below the current minimum (6).██████████████████▏                                                                        | 44/100 [00:16<00:21,  2.59it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 55 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:09] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 46 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:10] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:10] The new font size 0.8 is below the current minimum (6).██████████████████████                                                                     | 47/100 [00:17<00:22,  2.40it/s]\n",
      "[15:42:10] The new font size 0.8 is below the current minimum (6).███████████████████████▍                                                                   | 48/100 [00:17<00:20,  2.58it/s]\n",
      "[15:42:11] The new font size 0.8 is below the current minimum (6).████████████████████████▋                                                                  | 49/100 [00:18<00:19,  2.56it/s]\n",
      "[15:42:11] The new font size 0.8 is below the current minimum (6).██████████████████████████                                                                 | 50/100 [00:18<00:19,  2.62it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 36 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:11] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:12] The new font size 0.8 is below the current minimum (6).████████████████████████████▌                                                              | 52/100 [00:19<00:16,  2.96it/s]\n",
      "[15:42:12] The new font size 0.8 is below the current minimum (6).█████████████████████████████▉                                                             | 53/100 [00:19<00:15,  2.97it/s]\n",
      "[15:42:12] The new font size 0.8 is below the current minimum (6).███████████████████████████████▏                                                           | 54/100 [00:19<00:15,  3.04it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 33 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:13] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:13] The new font size 0.8 is below the current minimum (6).█████████████████████████████████▊                                                         | 56/100 [00:20<00:14,  2.96it/s]\n",
      "[15:42:13] The new font size 0.8 is below the current minimum (6).███████████████████████████████████                                                        | 57/100 [00:20<00:15,  2.86it/s]\n",
      "[15:42:14] The new font size 0.8 is below the current minimum (6).████████████████████████████████████▍                                                      | 58/100 [00:21<00:14,  2.94it/s]\n",
      "[15:42:14] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████▋                                                     | 59/100 [00:21<00:14,  2.93it/s]\n",
      "[15:42:14] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████                                                    | 60/100 [00:21<00:14,  2.85it/s]\n",
      "[15:42:15] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████▎                                                  | 61/100 [00:22<00:13,  2.97it/s]\n",
      "[15:42:15] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████▌                                                 | 62/100 [00:22<00:12,  3.16it/s]\n",
      "[15:42:15] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████▉                                                | 63/100 [00:22<00:11,  3.13it/s]\n",
      "[15:42:15] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████▏                                              | 64/100 [00:23<00:11,  3.03it/s]\n",
      "[15:42:16] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████▌                                             | 65/100 [00:23<00:11,  3.14it/s]\n",
      "[15:42:16] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████▊                                            | 66/100 [00:23<00:10,  3.13it/s]\n",
      "[15:42:16] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████                                           | 67/100 [00:24<00:10,  3.05it/s]\n",
      "[15:42:17] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████▍                                         | 68/100 [00:24<00:10,  3.14it/s]\n",
      "[15:42:17] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████▋                                        | 69/100 [00:24<00:09,  3.13it/s]\n",
      "[15:42:17] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████                                       | 70/100 [00:24<00:09,  3.14it/s]\n",
      "[15:42:18] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████▎                                     | 71/100 [00:25<00:09,  3.20it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 41 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:18] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:18] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████▉                                   | 73/100 [00:26<00:09,  2.96it/s]\n",
      "[15:42:19] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████▏                                 | 74/100 [00:26<00:08,  2.97it/s]\n",
      "[15:42:19] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████▌                                | 75/100 [00:26<00:07,  3.23it/s]\n",
      "[15:42:19] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████▊                               | 76/100 [00:26<00:07,  3.09it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 17 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:20] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:20] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████▍                            | 78/100 [00:27<00:06,  3.49it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 43 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:20] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:21] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████                          | 80/100 [00:28<00:06,  3.12it/s]\n",
      "[15:42:21] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████▎                        | 81/100 [00:28<00:06,  3.11it/s]\n",
      "[15:42:21] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████▌                       | 82/100 [00:28<00:05,  3.10it/s]\n",
      "[15:42:22] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████▉                      | 83/100 [00:29<00:05,  3.08it/s]\n",
      "[15:42:22] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████▏                    | 84/100 [00:29<00:05,  3.12it/s]\n",
      "[15:42:22] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████▌                   | 85/100 [00:29<00:04,  3.13it/s]\n",
      "[15:42:22] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████▊                  | 86/100 [00:30<00:04,  3.28it/s]\n",
      "[15:42:23] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████████                 | 87/100 [00:30<00:03,  3.31it/s]\n",
      "[15:42:23] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████████▍               | 88/100 [00:30<00:03,  3.40it/s]\n",
      "[15:42:23] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████▋              | 89/100 [00:30<00:03,  3.40it/s]\n",
      "[15:42:24] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████████████             | 90/100 [00:31<00:02,  3.40it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 37 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:24] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:24] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████▌          | 92/100 [00:31<00:02,  3.26it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 18 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:24] The new font size 0.8 is below the current minimum (6).\n",
      "[15:42:25] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████████████████▏       | 94/100 [00:32<00:01,  3.48it/s]\n",
      "[15:42:25] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████████▌      | 95/100 [00:32<00:01,  3.29it/s]\n",
      "[15:42:26] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████████████████████████▊     | 96/100 [00:33<00:01,  3.11it/s]\n",
      "[15:42:26] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████████████████████    | 97/100 [00:33<00:01,  2.98it/s]\n",
      "[15:42:26] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████████████▍  | 98/100 [00:33<00:00,  3.12it/s]\n",
      "[15:42:27] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████████████████████████████▋ | 99/100 [00:34<00:00,  3.03it/s]\n",
      "Processing molecules: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:34<00:00,  2.90it/s]\n",
      "Analyzing feature importance: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:29<00:00,  3.39it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 5 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:42:58] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 1it [00:05,  5.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 1: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 30 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:43:04] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 32 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 2: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:04] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 9 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:43:05] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 24 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 3: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 4: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:05] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 40 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 5: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:05] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 35 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 6: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:05] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 38 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 7: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:06] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 8it [00:07,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 8: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:06] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 27 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 9: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:06] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 17 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 10: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:07] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 28 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 11: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:07] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 12it [00:08,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 12: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:07] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 13it [00:09,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 13: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:08] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 45 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 14: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:08] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 26 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 15: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:08] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 34 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 16: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:09] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 21 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 17: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:09] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 18it [00:10,  3.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 18: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:09] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 19it [00:10,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 19: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:09] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 20it [00:11,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 20: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:10] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 21it [00:11,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 21: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:10] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 22 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 22: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:10] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 23it [00:12,  3.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 23: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:11] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 31 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 24: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:11] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 29 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 25: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:11] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 26it [00:13,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 26: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:12] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 27it [00:13,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 27: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:12] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 28it [00:13,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 28: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:12] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 43 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 29: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:13] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 30it [00:14,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 30: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:13] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 31it [00:14,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 31: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:13] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 32it [00:15,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 32: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:14] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 33it [00:15,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 33: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:14] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 39 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 34: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:14] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 35it [00:16,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 35: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:15] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 25 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 36: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:15] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 37it [00:16,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 37: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:15] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 38it [00:17,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 38: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:16] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 39it [00:17,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 39: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:43:16] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 40it [00:17,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 40: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 23 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 42 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 73 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 59 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 55 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 46 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 36 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 33 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 41 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 37 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 18 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "Analyzing node types: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created color-coded Excel file: apr_4_mpnn/explainability/molecule_importances_colored_main.xlsx\n",
      "✅ Analysis complete! All results saved to apr_4_mpnn/explainability\n",
      "📊 Key files generated:\n",
      " - Molecule visualizations with SMILES filenames: apr_4_mpnn/explainability/molecule_viz_main/*.png\n",
      " - Top 40 molecules: apr_4_mpnn/explainability/top_molecules/*.png\n",
      " - Top molecules SMILES list: apr_4_mpnn/explainability/top_smiles_main.csv\n",
      " - Feature importance analysis: apr_4_mpnn/explainability/feature_importance_main.xlsx\n",
      " - Molecule importance spreadsheet: apr_4_mpnn/explainability/molecule_importances_main.xlsx\n",
      " - Atom type importance: apr_4_mpnn/explainability/atom_type_importance_main.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "import seaborn as sns\n",
    "from captum.attr import IntegratedGradients\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Create output directory\n",
    "output_dir = os.path.join('MPNN_result', 'explainability')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the MPNN model class (needed for loading the model)\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_encoder = torch.nn.Linear(node_dim, hidden_dim)\n",
    "        self.edge_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            nn = torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.convs.append(NNConv(hidden_dim, hidden_dim, self.edge_encoder))\n",
    "        \n",
    "        self.gru = torch.nn.GRU(hidden_dim, hidden_dim)\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim // 2, out_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Initial encoding\n",
    "        x = self.node_encoder(x)\n",
    "        h = x.unsqueeze(0)\n",
    "        \n",
    "        # Message passing layers\n",
    "        for conv in self.convs:\n",
    "            m = torch.nn.functional.relu(conv(x, edge_index, edge_attr))\n",
    "            m = torch.nn.functional.dropout(m, p=self.dropout, training=self.training)\n",
    "            # Use GRU to update the hidden representation\n",
    "            x = x.unsqueeze(0)\n",
    "            m = m.unsqueeze(0)\n",
    "            _, h = self.gru(m, h)\n",
    "            x = h.squeeze(0)\n",
    "        \n",
    "        # Global pooling and output\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Function to convert molecules to graph data\n",
    "def atom_features(atom):\n",
    "    return torch.tensor([\n",
    "        # Basic properties\n",
    "        atom.GetAtomicNum(),                     # Atomic number\n",
    "        atom.GetDegree(),                        # Number of bonded neighbors\n",
    "        atom.GetFormalCharge(),                  # Formal charge\n",
    "        atom.GetNumRadicalElectrons(),           # Number of radical electrons\n",
    "        int(atom.GetIsAromatic()),               # Aromaticity flag\n",
    "        \n",
    "        # Extended properties\n",
    "        atom.GetExplicitValence(),               # Explicit valence\n",
    "        atom.GetImplicitValence(),               # Implicit valence\n",
    "        atom.GetTotalValence(),                  # Total valence\n",
    "        atom.GetNumImplicitHs(),                 # Number of implicit hydrogens\n",
    "        atom.GetHybridization(),                 # Hybridization state\n",
    "        atom.GetTotalNumHs(),                    # Total number of hydrogens\n",
    "        \n",
    "        # Topological properties\n",
    "        int(atom.IsInRing()),                    # Whether the atom is in a ring\n",
    "        int(atom.IsInRingSize(3)),               # Whether in 3-membered ring\n",
    "        int(atom.IsInRingSize(4)),               # Whether in 4-membered ring\n",
    "        int(atom.IsInRingSize(5)),               # Whether in 5-membered ring\n",
    "        int(atom.IsInRingSize(6)),               # Whether in 6-membered ring\n",
    "        int(atom.IsInRingSize(7)),               # Whether in 7-membered ring\n",
    "        \n",
    "        # Electronic properties\n",
    "        atom.GetChiralTag(),                     # Chirality\n",
    "        atom.GetMass(),                          # Atomic mass\n",
    "        Chem.rdMolDescriptors.CalcCrippenDescriptors(\n",
    "            Chem.MolFromSmiles(f\"[{atom.GetSymbol()}]\"))[0]  # LogP contribution\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "def mol_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    atoms = [atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    if not atoms: return None\n",
    "    x = torch.stack(atoms, dim=0)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "    edge_attr = [[bond.GetBondTypeAsDouble(), bond.GetIsConjugated(), bond.IsInRing()] * 2 for bond in mol.GetBonds()]\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).reshape(-1, 3)\n",
    "    from torch_geometric.data import Data\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "def load_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]) or pd.isna(row[target_col]):\n",
    "            continue\n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "# Load the trained model\n",
    "def load_trained_model(model_path, input_dim=20, hidden_params_path=os.path.join('MPNN_result', 'study_best_params_mpnn.json')):\n",
    "    try:\n",
    "        with open(hidden_params_path, 'r') as f:\n",
    "            best_params = json.load(f)\n",
    "        \n",
    "        model = MPNN(\n",
    "            node_dim=input_dim,\n",
    "            edge_dim=3,\n",
    "            hidden_dim=best_params[\"hidden_dim\"],\n",
    "            out_dim=1,\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            dropout=best_params[\"dropout\"]\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        # Fallback to default parameters if file not found\n",
    "        print(f\"Parameters file not found at {hidden_params_path}. Using default parameters.\")\n",
    "        model = MPNN(\n",
    "            node_dim=input_dim,\n",
    "            edge_dim=3,\n",
    "            hidden_dim=64,\n",
    "            out_dim=1,\n",
    "            num_layers=3,\n",
    "            dropout=0.3\n",
    "        )\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load model\n",
    "model_path = os.path.join('MPNN_result', 'mpnn_best_model.pth')\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "# Load dataset\n",
    "train_data = load_dataset(\"dataset_main.xlsx\")  # Load your full dataset\n",
    "\n",
    "# Helper function to create a wrapper model for attribution methods\n",
    "class MPNNWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        return torch.sigmoid(self.model(x, edge_index, edge_attr, batch))\n",
    "\n",
    "# Initialize attribution method\n",
    "wrapper_model = MPNNWrapper(model)\n",
    "integrated_gradients = IntegratedGradients(wrapper_model)\n",
    "\n",
    "# Function to interpret molecule graph and get node/edge importance\n",
    "def interpret_molecule(graph):\n",
    "    graph_batch = graph.clone()\n",
    "    graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "    \n",
    "    # Get integrated gradients attribution\n",
    "    node_attr = integrated_gradients.attribute(\n",
    "        graph.x, \n",
    "        additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "        internal_batch_size=1\n",
    "    )\n",
    "    \n",
    "    # Sum across feature dimensions to get per-node importance\n",
    "    node_importance = torch.abs(node_attr).sum(dim=1).detach().numpy()\n",
    "    \n",
    "    # For edge importance, we'll use a simple approximation based on connected nodes\n",
    "    edge_importance = []\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        src, dst = graph.edge_index[0, i].item(), graph.edge_index[1, i].item()\n",
    "        edge_imp = (node_importance[src] + node_importance[dst]) / 2\n",
    "        edge_importance.append(edge_imp)\n",
    "    \n",
    "    return node_importance, np.array(edge_importance)\n",
    "\n",
    "# Function to create a safe filename from SMILES\n",
    "def create_safe_filename(smiles):\n",
    "    filename = f\"{smiles}_mpnn.png\"\n",
    "    # Replace characters that are problematic in filenames\n",
    "    for char in ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|']:\n",
    "        filename = filename.replace(char, '_')\n",
    "    # Ensure the filename isn't too long for the filesystem\n",
    "    if len(filename) > 200:\n",
    "        # Truncate but keep the _mpnn.png suffix\n",
    "        filename = filename[:195] + \"_mpnn.png\"\n",
    "    return filename\n",
    "\n",
    "# Function to visualize molecule with importance highlighting\n",
    "def visualize_molecule_importance(smiles, node_importance, mol=None, title=None, size=(600, 600)):\n",
    "    if mol is None:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Normalize importances for coloring\n",
    "    if len(node_importance) > 0:\n",
    "        norm = Normalize(vmin=np.min(node_importance), vmax=np.max(node_importance))\n",
    "        atom_colors = {}\n",
    "        for i, imp in enumerate(node_importance):\n",
    "            color_val = norm(imp)\n",
    "            atom_colors[i] = tuple(plt.cm.viridis(color_val)[:3])\n",
    "    else:\n",
    "        atom_colors = {}\n",
    "    \n",
    "    # Create drawing\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    drawer.SetFontSize(0.8)\n",
    "    \n",
    "    # Set up atom highlights\n",
    "    highlight_atoms = list(range(mol.GetNumAtoms()))\n",
    "    highlight_bonds = []\n",
    "    highlight_atom_colors = atom_colors\n",
    "    highlight_bond_colors = {}\n",
    "    \n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        drawer.DrawMoleculeWithHighlights(\n",
    "            mol, title, \n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    else:\n",
    "        # Draw the molecule with highlights\n",
    "        drawer.DrawMolecule(\n",
    "            mol,\n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    return drawer.GetDrawingText()\n",
    "\n",
    "# Function to analyze feature importance across the dataset\n",
    "def analyze_feature_importance(data_list, top_n=20):\n",
    "    all_attributions = []\n",
    "    \n",
    "    for graph in tqdm(data_list, desc=\"Analyzing feature importance\"):\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        \n",
    "        attr = integrated_gradients.attribute(\n",
    "            graph.x, \n",
    "            additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "            internal_batch_size=1\n",
    "        )\n",
    "        \n",
    "        # Average attribution per feature across all nodes\n",
    "        avg_attr = torch.abs(attr).mean(dim=0).detach().numpy()\n",
    "        all_attributions.append(avg_attr)\n",
    "    \n",
    "    # Average across all molecules\n",
    "    feature_importance = np.mean(all_attributions, axis=0)\n",
    "    \n",
    "    # Feature names (same as in atom_features function)\n",
    "    feature_names = [\n",
    "        'Atomic number', 'Degree', 'Formal charge', 'Radical electrons', 'Is aromatic',\n",
    "        'Explicit valence', 'Implicit valence', 'Total valence', 'Implicit Hs',\n",
    "        'Hybridization', 'Total Hs', 'In ring', 'In ring size 3', 'In ring size 4',\n",
    "        'In ring size 5', 'In ring size 6', 'In ring size 7', 'Chiral tag', 'Mass',\n",
    "        'LogP contribution'\n",
    "    ]\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Create output subfolders\n",
    "viz_dir = os.path.join(output_dir, 'molecule_viz_main')\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "top_molecules_dir = os.path.join(output_dir, 'top_molecules')\n",
    "os.makedirs(top_molecules_dir, exist_ok=True)\n",
    "\n",
    "# Process all molecules in the dataset\n",
    "molecule_importances = []\n",
    "\n",
    "# Process a subset of molecules (limit to 100 for efficiency)\n",
    "num_molecules = min(100, len(train_data))\n",
    "\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Processing molecules\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get prediction score\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        pred_score = wrapper_model(graph.x, graph.edge_index, graph.edge_attr, graph_batch.batch).item()\n",
    "        \n",
    "        # Get node and edge importance\n",
    "        node_importance, edge_importance = interpret_molecule(graph)\n",
    "        \n",
    "        # Calculate importance metrics\n",
    "        avg_importance = np.mean(node_importance)\n",
    "        max_importance = np.max(node_importance)\n",
    "        \n",
    "        # Create a safe filename from the SMILES\n",
    "        safe_filename = create_safe_filename(smiles)\n",
    "        \n",
    "        # Save molecule image with importance visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol)\n",
    "        with open(os.path.join(viz_dir, safe_filename), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "        \n",
    "        # Add to our results dataframe\n",
    "        molecule_importances.append({\n",
    "            'Index': i+1,\n",
    "            'SMILES': smiles,\n",
    "            'Prediction': pred_score,\n",
    "            'True_Label': graph.y.item(),\n",
    "            'Average_Importance': avg_importance,\n",
    "            'Max_Importance': max_importance,\n",
    "            'Most_Important_Atom_Index': np.argmax(node_importance),\n",
    "            'Filename': safe_filename\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save dataframe of molecule importances\n",
    "importance_df = pd.DataFrame(molecule_importances)\n",
    "importance_df.to_excel(os.path.join(output_dir, 'molecule_importances_main.xlsx'), index=False)\n",
    "\n",
    "# Create feature importance analysis\n",
    "feature_imp_df = analyze_feature_importance(train_data[:num_molecules])\n",
    "feature_imp_df.to_excel(os.path.join(output_dir, 'feature_importance_main.xlsx'), index=False)\n",
    "\n",
    "# Plot and save feature importance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df.head(15))\n",
    "plt.title('Top 15 Important Atom Features (MPNN Analysis)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'feature_importance_main.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Find the top 40 molecules by importance\n",
    "top_molecules_count = min(40, len(importance_df))\n",
    "top_mols = importance_df.sort_values('Average_Importance', ascending=False).head(top_molecules_count)\n",
    "\n",
    "# Create a top SMILES CSV file\n",
    "with open(os.path.join(output_dir, \"top_smiles_main.csv\"), \"w\") as f:\n",
    "    f.write(\"Rank,MoleculeIndex,SMILES,Prediction,TrueLabel,AverageImportance,Filename\\n\")\n",
    "    for j, (_, r) in enumerate(top_mols.iterrows()):\n",
    "        f.write(f\"{j+1},{r['Index']},{r['SMILES']},{r['Prediction']:.4f},{r['True_Label']:.0f},{r['Average_Importance']:.4f},{r['Filename']}\\n\")\n",
    "\n",
    "# Create a higher-quality version of the top molecules (with titles)\n",
    "for i, (_, row) in enumerate(tqdm(top_mols.iterrows(), desc=\"Creating high-quality top molecule images\")):\n",
    "    try:\n",
    "        # Get the molecule and its data\n",
    "        idx = row['Index']\n",
    "        smiles = row['SMILES']\n",
    "        pred = row['Prediction']\n",
    "        true_label = row['True_Label']\n",
    "        \n",
    "        # Get the corresponding graph data\n",
    "        graph = train_data[idx-1]  # -1 because indices start at 1 in our data\n",
    "        \n",
    "        # Re-interpret the molecule for visualization\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get node importance\n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Create a title with info\n",
    "        title = f\"#{idx}: Pred={pred:.3f}, True={true_label:.0f}, Importance={row['Average_Importance']:.3f}\"\n",
    "        \n",
    "        # Create a high-quality visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol, title=title, size=(800, 800))\n",
    "        \n",
    "        # Use the same filename as before\n",
    "        safe_filename = row['Filename']\n",
    "        \n",
    "        # Save to the top molecules directory\n",
    "        with open(os.path.join(top_molecules_dir, safe_filename), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating top molecule image for rank {i+1}: {e}\")\n",
    "\n",
    "# Create node importance analysis\n",
    "node_importances = []\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Analyzing node types\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Get atom types and their importance\n",
    "        for atom_idx, importance in enumerate(node_importance):\n",
    "            atom_symbol = mol.GetAtomWithIdx(atom_idx).GetSymbol()\n",
    "            node_importances.append({\n",
    "                'Molecule_Index': i+1,\n",
    "                'SMILES': smiles,\n",
    "                'Atom_Index': atom_idx,\n",
    "                'Atom_Symbol': atom_symbol,\n",
    "                'Importance': importance\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing node for molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save node importance dataframe\n",
    "node_imp_df = pd.DataFrame(node_importances)\n",
    "node_imp_df.to_excel(os.path.join(output_dir, 'node_importances_main.xlsx'), index=False)\n",
    "\n",
    "# Analyze importance by atom type\n",
    "atom_importance = node_imp_df.groupby('Atom_Symbol')['Importance'].mean().reset_index()\n",
    "atom_importance = atom_importance.sort_values('Importance', ascending=False)\n",
    "atom_importance.to_excel(os.path.join(output_dir, 'atom_type_importance_main.xlsx'), index=False)\n",
    "\n",
    "# Plot atom type importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Atom_Symbol', data=atom_importance)\n",
    "plt.title('Average Importance by Atom Type (MPNN Analysis)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'atom_type_importance_main.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create a color-coded Excel file with molecule importances\n",
    "try:\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.styles import PatternFill\n",
    "    from openpyxl.styles.differential import DifferentialStyle\n",
    "    from openpyxl.formatting.rule import ColorScaleRule\n",
    "    \n",
    "    color_excel_path = os.path.join(output_dir, 'molecule_importances_colored_main.xlsx')\n",
    "    importance_df.to_excel(color_excel_path, index=False)\n",
    "    \n",
    "    # Open the workbook and add color scales\n",
    "    wb = load_workbook(color_excel_path)\n",
    "    ws = wb.active\n",
    "    \n",
    "    # Add color scale to Average_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Average_Importance\") + 1  # +1 because Excel is 1-indexed\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add color scale to Max_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Max_Importance\") + 1\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Save the workbook\n",
    "    wb.save(color_excel_path)\n",
    "    print(f\"Created color-coded Excel file: {color_excel_path}\")\n",
    "except ImportError:\n",
    "    print(\"openpyxl not available - skipping colored Excel creation\")\n",
    "\n",
    "print(f\"✅ Analysis complete! All results saved to {output_dir}\")\n",
    "print(f\"📊 Key files generated:\")\n",
    "print(f\" - Molecule visualizations with SMILES filenames: {viz_dir}/*.png\")\n",
    "print(f\" - Top 40 molecules: {top_molecules_dir}/*.png\")\n",
    "print(f\" - Top molecules SMILES list: {os.path.join(output_dir, 'top_smiles_main.csv')}\")\n",
    "print(f\" - Feature importance analysis: {os.path.join(output_dir, 'feature_importance_main.xlsx')}\")\n",
    "print(f\" - Molecule importance spreadsheet: {os.path.join(output_dir, 'molecule_importances_main.xlsx')}\")\n",
    "print(f\" - Atom type importance: {os.path.join(output_dir, 'atom_type_importance_main.png')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9fff4d-5a1d-4fb5-bad9-28fc860c8b64",
   "metadata": {},
   "source": [
    "##  Dataset used cancer_set.xlsx(FDA approved)\n",
    "- Top 40 most contributing SMILES plot\n",
    "- Feature Importance plot and saved the values in xlsx\n",
    "- Node importance vlaue saved in xlsx\n",
    "- Atom Type Importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1e98bb-e47b-4271-a3fd-ffd200c2e966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 57 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:38] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 37 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:39] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 32 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:39] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 34 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:39] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 26 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:40] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 35 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:40] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 43 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:40] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 36 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:41] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 30 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:41] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 22 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:41] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 33 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:42] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 91 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:42] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:43] The new font size 0.8 is below the current minimum (6).                                                                                           | 12/100 [00:04<00:38,  2.30it/s]\n",
      "[15:46:43] The new font size 0.8 is below the current minimum (6).                                                                                           | 13/100 [00:05<00:36,  2.39it/s]\n",
      "[15:46:43] The new font size 0.8 is below the current minimum (6).                                                                                           | 14/100 [00:05<00:32,  2.65it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 23 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:44] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 29 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:44] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 27 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:44] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 28 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:45] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:45] The new font size 0.8 is below the current minimum (6).                                                                                           | 19/100 [00:06<00:27,  2.99it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 60 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:45] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:46] The new font size 0.8 is below the current minimum (6).                                                                                           | 21/100 [00:07<00:30,  2.59it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 94 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:47] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 25 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:47] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:47] The new font size 0.8 is below the current minimum (6).                                                                                           | 24/100 [00:09<00:31,  2.42it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 18 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:47] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 13 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:48] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 52 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:48] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 38 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:48] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 11 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:49] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:49] The new font size 0.8 is below the current minimum (6).                                                                                           | 30/100 [00:11<00:23,  3.04it/s]\n",
      "[15:46:49] The new font size 0.8 is below the current minimum (6).█▎                                                                                         | 31/100 [00:11<00:23,  2.94it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 24 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:50] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 14 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:50] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:50] The new font size 0.8 is below the current minimum (6).█████▏                                                                                     | 34/100 [00:12<00:18,  3.53it/s]\n",
      "[15:46:51] The new font size 0.8 is below the current minimum (6).██████▌                                                                                    | 35/100 [00:12<00:18,  3.43it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 6 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:51] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:51] The new font size 0.8 is below the current minimum (6).█████████                                                                                  | 37/100 [00:12<00:16,  3.81it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 58 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:51] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 39 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:52] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:52] The new font size 0.8 is below the current minimum (6).█████████████                                                                              | 40/100 [00:14<00:19,  3.03it/s]\n",
      "[15:46:52] The new font size 0.8 is below the current minimum (6).██████████████▎                                                                            | 41/100 [00:14<00:18,  3.20it/s]\n",
      "[15:46:53] The new font size 0.8 is below the current minimum (6).███████████████▌                                                                           | 42/100 [00:14<00:18,  3.19it/s]\n",
      "[15:46:53] The new font size 0.8 is below the current minimum (6).████████████████▉                                                                          | 43/100 [00:14<00:18,  3.15it/s]\n",
      "[15:46:53] The new font size 0.8 is below the current minimum (6).██████████████████▏                                                                        | 44/100 [00:15<00:17,  3.15it/s]\n",
      "[15:46:54] The new font size 0.8 is below the current minimum (6).███████████████████▌                                                                       | 45/100 [00:15<00:17,  3.10it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 41 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:54] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:54] The new font size 0.8 is below the current minimum (6).██████████████████████                                                                     | 47/100 [00:16<00:17,  3.05it/s]\n",
      "[15:46:55] The new font size 0.8 is below the current minimum (6).███████████████████████▍                                                                   | 48/100 [00:16<00:16,  3.09it/s]\n",
      "[15:46:55] The new font size 0.8 is below the current minimum (6).████████████████████████▋                                                                  | 49/100 [00:16<00:16,  3.10it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 20 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:55] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:55] The new font size 0.8 is below the current minimum (6).███████████████████████████▎                                                               | 51/100 [00:17<00:14,  3.46it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 68 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:56] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:56] The new font size 0.8 is below the current minimum (6).█████████████████████████████▉                                                             | 53/100 [00:18<00:15,  3.09it/s]\n",
      "[15:46:56] The new font size 0.8 is below the current minimum (6).███████████████████████████████▏                                                           | 54/100 [00:18<00:13,  3.31it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 17 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:56] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 96 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:57] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:57] The new font size 0.8 is below the current minimum (6).███████████████████████████████████                                                        | 57/100 [00:19<00:14,  2.98it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 101 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:58] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 19 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:58] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:58] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████                                                    | 60/100 [00:20<00:13,  3.02it/s]\n",
      "[15:46:59] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████▎                                                  | 61/100 [00:20<00:11,  3.42it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 31 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:59] The new font size 0.8 is below the current minimum (6).\n",
      "[15:46:59] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████▉                                                | 63/100 [00:21<00:11,  3.33it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 8 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:46:59] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:00] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████▌                                             | 65/100 [00:21<00:08,  4.16it/s]\n",
      "[15:47:00] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████▊                                            | 66/100 [00:21<00:09,  3.68it/s]\n",
      "[15:47:00] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████                                           | 67/100 [00:22<00:08,  3.70it/s]\n",
      "[15:47:00] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████▍                                         | 68/100 [00:22<00:09,  3.43it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 9 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:01] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 21 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:01] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:01] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████▎                                     | 71/100 [00:23<00:08,  3.26it/s]\n",
      "[15:47:02] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████▌                                    | 72/100 [00:23<00:08,  3.36it/s]\n",
      "[15:47:02] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████▉                                   | 73/100 [00:23<00:08,  3.24it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 12 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:02] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 51 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:03] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:03] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████▊                               | 76/100 [00:24<00:07,  3.14it/s]\n",
      "[15:47:03] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████                              | 77/100 [00:25<00:06,  3.31it/s]\n",
      "[15:47:03] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████▍                            | 78/100 [00:25<00:06,  3.30it/s]\n",
      "[15:47:04] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████▋                           | 79/100 [00:25<00:06,  3.30it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 10 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:04] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:04] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████▎                        | 81/100 [00:26<00:05,  3.55it/s]\n",
      "[15:47:05] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████▌                       | 82/100 [00:26<00:05,  3.50it/s]\n",
      "[15:47:05] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████▉                      | 83/100 [00:26<00:04,  3.75it/s]\n",
      "[15:47:05] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████▏                    | 84/100 [00:27<00:04,  3.76it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 5 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:05] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:06] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████▊                  | 86/100 [00:27<00:03,  4.00it/s]\n",
      "[15:47:06] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████████                 | 87/100 [00:27<00:03,  3.82it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 15 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:06] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 16 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:06] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:07] The new font size 0.8 is below the current minimum (6).██████████████████████████████████████████████████████████████████████████████             | 90/100 [00:28<00:02,  3.84it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 73 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:07] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:08] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████▌          | 92/100 [00:29<00:02,  2.98it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 76 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:08] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:08] The new font size 0.8 is below the current minimum (6).███████████████████████████████████████████████████████████████████████████████████▏       | 94/100 [00:30<00:02,  2.59it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 90 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:09] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:09] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████████████████████████▊     | 96/100 [00:31<00:01,  2.44it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 59 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:10] The new font size 0.8 is below the current minimum (6).\n",
      "[15:47:10] The new font size 0.8 is below the current minimum (6).████████████████████████████████████████████████████████████████████████████████████████▍  | 98/100 [00:31<00:00,  2.58it/s]\n",
      "[15:47:10] The new font size 0.8 is below the current minimum (6).█████████████████████████████████████████████████████████████████████████████████████████▋ | 99/100 [00:32<00:00,  2.82it/s]\n",
      "Processing molecules: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.08it/s]\n",
      "Analyzing feature importance: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:32<00:00,  3.12it/s]\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 8 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:43] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 10 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 1: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:43] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 6 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:43] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 14 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 2: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 3: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:44] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 5 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "[15:47:44] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 12 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 4: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n",
      "Error creating top molecule image for rank 5: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:44] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 6it [00:01,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 6: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:44] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 18 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 7: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:44] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 25 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 8: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:45] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 29 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 9: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:45] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 19 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 10: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:45] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 13 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 11: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:46] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 28 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 12: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:46] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 23 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 13: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:46] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 17 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 14: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:46] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 15 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 15: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:47] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 16it [00:03,  3.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 16: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:47] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 17it [00:04,  3.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 17: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:47] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 37 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 18: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:48] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 20 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 19: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:48] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 52 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 20: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:48] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 21it [00:05,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 21: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:48] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 22it [00:05,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 22: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:49] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 23it [00:06,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 23: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:49] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 11 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 24: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:49] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 22 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 25: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:50] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 26it [00:06,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 26: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:50] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 38 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 27: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:50] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 28it [00:07,  3.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 28: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:50] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 29it [00:07,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 29: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:51] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 30 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 30: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:51] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 9 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 31: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:51] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 24 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 32: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:52] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 33it [00:08,  3.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 33: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:52] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 27 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 34: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:52] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 26 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 35: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:53] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 33 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 36: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:53] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 41 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 37: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:53] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 35 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 38: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:54] The new font size 0.8 is below the current minimum (6).\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 31 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 39: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:47:54] The new font size 0.8 is below the current minimum (6).\n",
      "Creating high-quality top molecule images: 40it [00:11,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating top molecule image for rank 40: Python argument types in\n",
      "    MolDraw2D.DrawMoleculeWithHighlights(MolDraw2DCairo, Mol, str)\n",
      "did not match C++ signature:\n",
      "    DrawMoleculeWithHighlights(RDKit::MolDraw2D {lvalue} self, RDKit::ROMol mol, std::string legend, boost::python::api::object highlight_atom_map, boost::python::api::object highlight_bond_map, boost::python::api::object highlight_radii, boost::python::api::object highlight_linewidth_multipliers, int confId=-1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 57 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 32 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 34 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 43 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 36 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 91 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 60 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 94 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 58 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 39 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 68 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 96 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 101 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 21 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 51 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 16 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 73 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 76 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 90 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "/home/acdsd/Desktop/amar_cancer_proj/myenv/lib/python3.11/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 59 equal to the number of examples.\n",
      "  warnings.warn(\n",
      "Analyzing node types: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:31<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created color-coded Excel file: apr_4_mpnn/explainability_cancer/molecule_importances_colored_cancer.xlsx\n",
      "✅ Analysis complete! All results saved to apr_4_mpnn/explainability_cancer\n",
      "📊 Key files generated:\n",
      " - Molecule visualizations with SMILES filenames: apr_4_mpnn/explainability_cancer/molecule_viz_cancer/*.png\n",
      " - Top 40 molecules: apr_4_mpnn/explainability_cancer/top_molecules/*.png\n",
      " - Top molecules SMILES list: apr_4_mpnn/explainability_cancer/top_smiles_cancer.csv\n",
      " - Feature importance analysis: apr_4_mpnn/explainability_cancer/feature_importance_cancer.xlsx\n",
      " - Molecule importance spreadsheet: apr_4_mpnn/explainability_cancer/molecule_importances_cancer.xlsx\n",
      " - Atom type importance: apr_4_mpnn/explainability_cancer/atom_type_importance_cancer.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw, AllChem\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.nn import NNConv, global_mean_pool\n",
    "import seaborn as sns\n",
    "from captum.attr import IntegratedGradients\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Create output directory\n",
    "output_dir = os.path.join('MPNN_result', 'explainability_cancer')\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Define the MPNN model class (needed for loading the model)\n",
    "class MPNN(torch.nn.Module):\n",
    "    def __init__(self, node_dim, edge_dim, hidden_dim, out_dim, num_layers=3, dropout=0.3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.node_encoder = torch.nn.Linear(node_dim, hidden_dim)\n",
    "        self.edge_encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(edge_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim * hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            nn = torch.nn.Sequential(\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "            )\n",
    "            self.convs.append(NNConv(hidden_dim, hidden_dim, self.edge_encoder))\n",
    "        \n",
    "        self.gru = torch.nn.GRU(hidden_dim, hidden_dim)\n",
    "        self.output = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.Linear(hidden_dim // 2, out_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        # Initial encoding\n",
    "        x = self.node_encoder(x)\n",
    "        h = x.unsqueeze(0)\n",
    "        \n",
    "        # Message passing layers\n",
    "        for conv in self.convs:\n",
    "            m = torch.nn.functional.relu(conv(x, edge_index, edge_attr))\n",
    "            m = torch.nn.functional.dropout(m, p=self.dropout, training=self.training)\n",
    "            # Use GRU to update the hidden representation\n",
    "            x = x.unsqueeze(0)\n",
    "            m = m.unsqueeze(0)\n",
    "            _, h = self.gru(m, h)\n",
    "            x = h.squeeze(0)\n",
    "        \n",
    "        # Global pooling and output\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "# Function to convert molecules to graph data\n",
    "def atom_features(atom):\n",
    "    return torch.tensor([\n",
    "        # Basic properties\n",
    "        atom.GetAtomicNum(),                     # Atomic number\n",
    "        atom.GetDegree(),                        # Number of bonded neighbors\n",
    "        atom.GetFormalCharge(),                  # Formal charge\n",
    "        atom.GetNumRadicalElectrons(),           # Number of radical electrons\n",
    "        int(atom.GetIsAromatic()),               # Aromaticity flag\n",
    "        \n",
    "        # Extended properties\n",
    "        atom.GetExplicitValence(),               # Explicit valence\n",
    "        atom.GetImplicitValence(),               # Implicit valence\n",
    "        atom.GetTotalValence(),                  # Total valence\n",
    "        atom.GetNumImplicitHs(),                 # Number of implicit hydrogens\n",
    "        atom.GetHybridization(),                 # Hybridization state\n",
    "        atom.GetTotalNumHs(),                    # Total number of hydrogens\n",
    "        \n",
    "        # Topological properties\n",
    "        int(atom.IsInRing()),                    # Whether the atom is in a ring\n",
    "        int(atom.IsInRingSize(3)),               # Whether in 3-membered ring\n",
    "        int(atom.IsInRingSize(4)),               # Whether in 4-membered ring\n",
    "        int(atom.IsInRingSize(5)),               # Whether in 5-membered ring\n",
    "        int(atom.IsInRingSize(6)),               # Whether in 6-membered ring\n",
    "        int(atom.IsInRingSize(7)),               # Whether in 7-membered ring\n",
    "        \n",
    "        # Electronic properties\n",
    "        atom.GetChiralTag(),                     # Chirality\n",
    "        atom.GetMass(),                          # Atomic mass\n",
    "        Chem.rdMolDescriptors.CalcCrippenDescriptors(\n",
    "            Chem.MolFromSmiles(f\"[{atom.GetSymbol()}]\"))[0]  # LogP contribution\n",
    "    ], dtype=torch.float)\n",
    "\n",
    "def mol_to_graph(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is None: return None\n",
    "    atoms = [atom_features(atom) for atom in mol.GetAtoms()]\n",
    "    if not atoms: return None\n",
    "    x = torch.stack(atoms, dim=0)\n",
    "    edge_index = []\n",
    "    for bond in mol.GetBonds():\n",
    "        i, j = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
    "        edge_index += [[i, j], [j, i]]\n",
    "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
    "    edge_attr = [[bond.GetBondTypeAsDouble(), bond.GetIsConjugated(), bond.IsInRing()] * 2 for bond in mol.GetBonds()]\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float).reshape(-1, 3)\n",
    "    from torch_geometric.data import Data\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "def load_dataset(path, smiles_col='Smiles', target_col='Target'):\n",
    "    df = pd.read_excel(path)\n",
    "    graphs = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row[smiles_col]) or pd.isna(row[target_col]):\n",
    "            continue\n",
    "        g = mol_to_graph(str(row[smiles_col]))\n",
    "        if g is not None:\n",
    "            g.y = torch.tensor([row[target_col]], dtype=torch.float)\n",
    "            g.smiles = row[smiles_col]\n",
    "            graphs.append(g)\n",
    "    return graphs\n",
    "\n",
    "# Load the trained model\n",
    "def load_trained_model(model_path, input_dim=20, hidden_params_path=os.path.join('MPNN_result', 'study_best_params_mpnn.json')):\n",
    "    try:\n",
    "        with open(hidden_params_path, 'r') as f:\n",
    "            best_params = json.load(f)\n",
    "        \n",
    "        model = MPNN(\n",
    "            node_dim=input_dim,\n",
    "            edge_dim=3,\n",
    "            hidden_dim=best_params[\"hidden_dim\"],\n",
    "            out_dim=1,\n",
    "            num_layers=best_params[\"num_layers\"],\n",
    "            dropout=best_params[\"dropout\"]\n",
    "        )\n",
    "    except FileNotFoundError:\n",
    "        # Fallback to default parameters if file not found\n",
    "        print(f\"Parameters file not found at {hidden_params_path}. Using default parameters.\")\n",
    "        model = MPNN(\n",
    "            node_dim=input_dim,\n",
    "            edge_dim=3,\n",
    "            hidden_dim=64,\n",
    "            out_dim=1,\n",
    "            num_layers=3,\n",
    "            dropout=0.3\n",
    "        )\n",
    "    \n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Load model\n",
    "model_path = os.path.join('MPNN_result', 'mpnn_best_model.pth')\n",
    "model = load_trained_model(model_path)\n",
    "\n",
    "# Load dataset\n",
    "train_data = load_dataset(\"cancer_set.xlsx\")  # Load your full dataset\n",
    "\n",
    "# Helper function to create a wrapper model for attribution methods\n",
    "class MPNNWrapper(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr, batch):\n",
    "        return torch.sigmoid(self.model(x, edge_index, edge_attr, batch))\n",
    "\n",
    "# Initialize attribution method\n",
    "wrapper_model = MPNNWrapper(model)\n",
    "integrated_gradients = IntegratedGradients(wrapper_model)\n",
    "\n",
    "# Function to interpret molecule graph and get node/edge importance\n",
    "def interpret_molecule(graph):\n",
    "    graph_batch = graph.clone()\n",
    "    graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "    \n",
    "    # Get integrated gradients attribution\n",
    "    node_attr = integrated_gradients.attribute(\n",
    "        graph.x, \n",
    "        additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "        internal_batch_size=1\n",
    "    )\n",
    "    \n",
    "    # Sum across feature dimensions to get per-node importance\n",
    "    node_importance = torch.abs(node_attr).sum(dim=1).detach().numpy()\n",
    "    \n",
    "    # For edge importance, we'll use a simple approximation based on connected nodes\n",
    "    edge_importance = []\n",
    "    for i in range(graph.edge_index.shape[1]):\n",
    "        src, dst = graph.edge_index[0, i].item(), graph.edge_index[1, i].item()\n",
    "        edge_imp = (node_importance[src] + node_importance[dst]) / 2\n",
    "        edge_importance.append(edge_imp)\n",
    "    \n",
    "    return node_importance, np.array(edge_importance)\n",
    "\n",
    "# Function to create a safe filename from SMILES\n",
    "def create_safe_filename(smiles):\n",
    "    filename = f\"{smiles}_mpnn.png\"\n",
    "    # Replace characters that are problematic in filenames\n",
    "    for char in ['/', '\\\\', ':', '*', '?', '\"', '<', '>', '|']:\n",
    "        filename = filename.replace(char, '_')\n",
    "    # Ensure the filename isn't too long for the filesystem\n",
    "    if len(filename) > 200:\n",
    "        # Truncate but keep the _mpnn.png suffix\n",
    "        filename = filename[:195] + \"_mpnn_cancer.png\"\n",
    "    return filename\n",
    "\n",
    "# Function to visualize molecule with importance highlighting\n",
    "def visualize_molecule_importance(smiles, node_importance, mol=None, title=None, size=(600, 600)):\n",
    "    if mol is None:\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "    \n",
    "    # Normalize importances for coloring\n",
    "    if len(node_importance) > 0:\n",
    "        norm = Normalize(vmin=np.min(node_importance), vmax=np.max(node_importance))\n",
    "        atom_colors = {}\n",
    "        for i, imp in enumerate(node_importance):\n",
    "            color_val = norm(imp)\n",
    "            atom_colors[i] = tuple(plt.cm.viridis(color_val)[:3])\n",
    "    else:\n",
    "        atom_colors = {}\n",
    "    \n",
    "    # Create drawing\n",
    "    drawer = rdMolDraw2D.MolDraw2DCairo(size[0], size[1])\n",
    "    drawer.SetFontSize(0.8)\n",
    "    \n",
    "    # Set up atom highlights\n",
    "    highlight_atoms = list(range(mol.GetNumAtoms()))\n",
    "    highlight_bonds = []\n",
    "    highlight_atom_colors = atom_colors\n",
    "    highlight_bond_colors = {}\n",
    "    \n",
    "    # Add title if provided\n",
    "    if title:\n",
    "        drawer.DrawMoleculeWithHighlights(\n",
    "            mol, title, \n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    else:\n",
    "        # Draw the molecule with highlights\n",
    "        drawer.DrawMolecule(\n",
    "            mol,\n",
    "            highlightAtoms=highlight_atoms,\n",
    "            highlightAtomColors=highlight_atom_colors\n",
    "        )\n",
    "    drawer.FinishDrawing()\n",
    "    \n",
    "    return drawer.GetDrawingText()\n",
    "\n",
    "# Function to analyze feature importance across the dataset\n",
    "def analyze_feature_importance(data_list, top_n=20):\n",
    "    all_attributions = []\n",
    "    \n",
    "    for graph in tqdm(data_list, desc=\"Analyzing feature importance\"):\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        \n",
    "        attr = integrated_gradients.attribute(\n",
    "            graph.x, \n",
    "            additional_forward_args=(graph.edge_index, graph.edge_attr, graph_batch.batch),\n",
    "            internal_batch_size=1\n",
    "        )\n",
    "        \n",
    "        # Average attribution per feature across all nodes\n",
    "        avg_attr = torch.abs(attr).mean(dim=0).detach().numpy()\n",
    "        all_attributions.append(avg_attr)\n",
    "    \n",
    "    # Average across all molecules\n",
    "    feature_importance = np.mean(all_attributions, axis=0)\n",
    "    \n",
    "    # Feature names (same as in atom_features function)\n",
    "    feature_names = [\n",
    "        'Atomic number', 'Degree', 'Formal charge', 'Radical electrons', 'Is aromatic',\n",
    "        'Explicit valence', 'Implicit valence', 'Total valence', 'Implicit Hs',\n",
    "        'Hybridization', 'Total Hs', 'In ring', 'In ring size 3', 'In ring size 4',\n",
    "        'In ring size 5', 'In ring size 6', 'In ring size 7', 'Chiral tag', 'Mass',\n",
    "        'LogP contribution'\n",
    "    ]\n",
    "    \n",
    "    # Sort by importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': feature_importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "# Create output subfolders\n",
    "viz_dir = os.path.join(output_dir, 'molecule_viz_cancer')\n",
    "os.makedirs(viz_dir, exist_ok=True)\n",
    "\n",
    "top_molecules_dir = os.path.join(output_dir, 'top_molecules')\n",
    "os.makedirs(top_molecules_dir, exist_ok=True)\n",
    "\n",
    "# Process all molecules in the dataset\n",
    "molecule_importances = []\n",
    "\n",
    "# Process a subset of molecules (limit to 100 for efficiency)\n",
    "num_molecules = min(100, len(train_data))\n",
    "\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Processing molecules\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get prediction score\n",
    "        graph_batch = graph.clone()\n",
    "        graph_batch.batch = torch.zeros(graph.x.shape[0], dtype=torch.long)\n",
    "        pred_score = wrapper_model(graph.x, graph.edge_index, graph.edge_attr, graph_batch.batch).item()\n",
    "        \n",
    "        # Get node and edge importance\n",
    "        node_importance, edge_importance = interpret_molecule(graph)\n",
    "        \n",
    "        # Calculate importance metrics\n",
    "        avg_importance = np.mean(node_importance)\n",
    "        max_importance = np.max(node_importance)\n",
    "        \n",
    "        # Create a safe filename from the SMILES\n",
    "        safe_filename = create_safe_filename(smiles)\n",
    "        \n",
    "        # Save molecule image with importance visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol)\n",
    "        with open(os.path.join(viz_dir, safe_filename), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "        \n",
    "        # Add to our results dataframe\n",
    "        molecule_importances.append({\n",
    "            'Index': i+1,\n",
    "            'SMILES': smiles,\n",
    "            'Prediction': pred_score,\n",
    "            'True_Label': graph.y.item(),\n",
    "            'Average_Importance': avg_importance,\n",
    "            'Max_Importance': max_importance,\n",
    "            'Most_Important_Atom_Index': np.argmax(node_importance),\n",
    "            'Filename': safe_filename\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save dataframe of molecule importances\n",
    "importance_df = pd.DataFrame(molecule_importances)\n",
    "importance_df.to_excel(os.path.join(output_dir, 'molecule_importances_cancer.xlsx'), index=False)\n",
    "\n",
    "# Create feature importance analysis\n",
    "feature_imp_df = analyze_feature_importance(train_data[:num_molecules])\n",
    "feature_imp_df.to_excel(os.path.join(output_dir, 'feature_importance_cancer.xlsx'), index=False)\n",
    "\n",
    "# Plot and save feature importance graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_imp_df.head(15))\n",
    "plt.title('Top 15 Important Atom Features (MPNN Analysis)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'feature_importance_cancer.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Find the top 40 molecules by importance\n",
    "top_molecules_count = min(40, len(importance_df))\n",
    "top_mols = importance_df.sort_values('Average_Importance', ascending=False).head(top_molecules_count)\n",
    "\n",
    "# Create a top SMILES CSV file\n",
    "with open(os.path.join(output_dir, \"top_smiles_cancer.csv\"), \"w\") as f:\n",
    "    f.write(\"Rank,MoleculeIndex,SMILES,Prediction,TrueLabel,AverageImportance,Filename\\n\")\n",
    "    for j, (_, r) in enumerate(top_mols.iterrows()):\n",
    "        f.write(f\"{j+1},{r['Index']},{r['SMILES']},{r['Prediction']:.4f},{r['True_Label']:.0f},{r['Average_Importance']:.4f},{r['Filename']}\\n\")\n",
    "\n",
    "# Create a higher-quality version of the top molecules (with titles)\n",
    "for i, (_, row) in enumerate(tqdm(top_mols.iterrows(), desc=\"Creating high-quality top molecule images\")):\n",
    "    try:\n",
    "        # Get the molecule and its data\n",
    "        idx = row['Index']\n",
    "        smiles = row['SMILES']\n",
    "        pred = row['Prediction']\n",
    "        true_label = row['True_Label']\n",
    "        \n",
    "        # Get the corresponding graph data\n",
    "        graph = train_data[idx-1]  # -1 because indices start at 1 in our data\n",
    "        \n",
    "        # Re-interpret the molecule for visualization\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        # Get node importance\n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Create a title with info\n",
    "        title = f\"#{idx}: Pred={pred:.3f}, True={true_label:.0f}, Importance={row['Average_Importance']:.3f}\"\n",
    "        \n",
    "        # Create a high-quality visualization\n",
    "        img_data = visualize_molecule_importance(smiles, node_importance, mol, title=title, size=(800, 800))\n",
    "        \n",
    "        # Use the same filename as before\n",
    "        safe_filename = row['Filename']\n",
    "        \n",
    "        # Save to the top molecules directory\n",
    "        with open(os.path.join(top_molecules_dir, safe_filename), \"wb\") as f:\n",
    "            f.write(img_data)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating top molecule image for rank {i+1}: {e}\")\n",
    "\n",
    "# Create node importance analysis\n",
    "node_importances = []\n",
    "for i, graph in enumerate(tqdm(train_data[:num_molecules], desc=\"Analyzing node types\")):\n",
    "    try:\n",
    "        smiles = graph.smiles\n",
    "        mol = Chem.MolFromSmiles(smiles)\n",
    "        if mol is None:\n",
    "            continue\n",
    "            \n",
    "        node_importance, _ = interpret_molecule(graph)\n",
    "        \n",
    "        # Get atom types and their importance\n",
    "        for atom_idx, importance in enumerate(node_importance):\n",
    "            atom_symbol = mol.GetAtomWithIdx(atom_idx).GetSymbol()\n",
    "            node_importances.append({\n",
    "                'Molecule_Index': i+1,\n",
    "                'SMILES': smiles,\n",
    "                'Atom_Index': atom_idx,\n",
    "                'Atom_Symbol': atom_symbol,\n",
    "                'Importance': importance\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing node for molecule {i+1}: {e}\")\n",
    "\n",
    "# Create and save node importance dataframe\n",
    "node_imp_df = pd.DataFrame(node_importances)\n",
    "node_imp_df.to_excel(os.path.join(output_dir, 'node_importances_cancer.xlsx'), index=False)\n",
    "\n",
    "# Analyze importance by atom type\n",
    "atom_importance = node_imp_df.groupby('Atom_Symbol')['Importance'].mean().reset_index()\n",
    "atom_importance = atom_importance.sort_values('Importance', ascending=False)\n",
    "atom_importance.to_excel(os.path.join(output_dir, 'atom_type_importance_cancer.xlsx'), index=False)\n",
    "\n",
    "# Plot atom type importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Atom_Symbol', data=atom_importance)\n",
    "plt.title('Average Importance by Atom Type (MPNN Analysis)')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir, 'atom_type_importance_cancer.png'), dpi=300)\n",
    "plt.close()\n",
    "\n",
    "# Create a color-coded Excel file with molecule importances\n",
    "try:\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.styles import PatternFill\n",
    "    from openpyxl.styles.differential import DifferentialStyle\n",
    "    from openpyxl.formatting.rule import ColorScaleRule\n",
    "    \n",
    "    color_excel_path = os.path.join(output_dir, 'molecule_importances_colored_cancer.xlsx')\n",
    "    importance_df.to_excel(color_excel_path, index=False)\n",
    "    \n",
    "    # Open the workbook and add color scales\n",
    "    wb = load_workbook(color_excel_path)\n",
    "    ws = wb.active\n",
    "    \n",
    "    # Add color scale to Average_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Average_Importance\") + 1  # +1 because Excel is 1-indexed\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Add color scale to Max_Importance column\n",
    "    col_idx = importance_df.columns.get_loc(\"Max_Importance\") + 1\n",
    "    col_letter = ws.cell(1, col_idx).column_letter\n",
    "    \n",
    "    ws.conditional_formatting.add(\n",
    "        f\"{col_letter}2:{col_letter}{len(importance_df)+1}\",\n",
    "        ColorScaleRule(\n",
    "            start_type='min', start_color='FFFFFF',\n",
    "            mid_type='percentile', mid_value=50, mid_color='FFFF00',\n",
    "            end_type='max', end_color='FF0000'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Save the workbook\n",
    "    wb.save(color_excel_path)\n",
    "    print(f\"Created color-coded Excel file: {color_excel_path}\")\n",
    "except ImportError:\n",
    "    print(\"openpyxl not available - skipping colored Excel creation\")\n",
    "\n",
    "print(f\"✅ Analysis complete! All results saved to {output_dir}\")\n",
    "print(f\"📊 Key files generated:\")\n",
    "print(f\" - Molecule visualizations with SMILES filenames: {viz_dir}/*.png\")\n",
    "print(f\" - Top 40 molecules: {top_molecules_dir}/*.png\")\n",
    "print(f\" - Top molecules SMILES list: {os.path.join(output_dir, 'top_smiles_cancer.csv')}\")\n",
    "print(f\" - Feature importance analysis: {os.path.join(output_dir, 'feature_importance_cancer.xlsx')}\")\n",
    "print(f\" - Molecule importance spreadsheet: {os.path.join(output_dir, 'molecule_importances_cancer.xlsx')}\")\n",
    "print(f\" - Atom type importance: {os.path.join(output_dir, 'atom_type_importance_cancer.png')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f085436-eb45-4074-a041-9e4d1ad572bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
